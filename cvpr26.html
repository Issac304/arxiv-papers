<!DOCTYPE html>
<html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1.0">
<meta name="theme-color" content="#0a0e1a"><meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<link rel="manifest" href="manifest.json"><link rel="apple-touch-icon" href="icon-192.png">
<title>CVPR 2026 - arXiv Papers</title><style>
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap');
:root{--bg:#070a13;--surface:rgba(255,255,255,0.03);--surface-hover:rgba(255,255,255,0.06);--border:rgba(255,255,255,0.08);--border-hover:rgba(255,255,255,0.15);--t:#f1f4f9;--t2:#9ba1b0;--t3:#656a7a;--ac:#6382ff;--ac-hover:#829aff;--ac2:#38d9c9;--hf:#ff9d00}
*{margin:0;padding:0;box-sizing:border-box}
body{font-family:-apple-system,BlinkMacSystemFont,'Inter','Segoe UI',Roboto,Helvetica,Arial,sans-serif;background:var(--bg);color:var(--t);min-height:100vh;line-height:1.5;background-image:url('bg.png');background-size:cover;background-position:center;background-attachment:fixed;background-repeat:no-repeat}
body::before{content:"";position:fixed;inset:0;background:rgba(7,10,19,0.85);pointer-events:none;z-index:0}
.c{max-width:1040px;margin:0 auto;padding:60px 20px;position:relative;z-index:1}
a{color:var(--ac);text-decoration:none;transition:color .2s}a:hover{color:var(--ac-hover)}
h1{font-size:3rem;font-weight:800;letter-spacing:-0.03em;background:linear-gradient(135deg,#fff 30%,#a5b4fc 100%);-webkit-background-clip:text;-webkit-text-fill-color:transparent;text-align:center;margin-bottom:16px}
.sub{text-align:center;color:var(--t2);margin-bottom:12px;font-size:1.1rem;font-weight:400;letter-spacing:0.01em}
.pills{display:flex;justify-content:center;gap:8px;margin-bottom:60px;flex-wrap:wrap}
.pill{font-size:.75rem;font-weight:500;padding:4px 14px;border-radius:20px;background:var(--surface);border:1px solid var(--border);color:var(--t2);backdrop-filter:blur(8px);transition:all .2s}
.pill:hover{background:var(--surface-hover);border-color:var(--border-hover);color:var(--t)}
.section{margin-bottom:50px}
.label{font-size:.75rem;font-weight:700;text-transform:uppercase;letter-spacing:0.1em;color:var(--t3);margin-bottom:20px;display:flex;align-items:center;gap:12px}
.grid{display:grid;grid-template-columns:repeat(auto-fill,minmax(240px,1fr));gap:16px}
.dcard{display:flex;align-items:center;justify-content:space-between;background:var(--surface);border:1px solid var(--border);border-radius:16px;padding:20px 24px;color:var(--t);backdrop-filter:blur(12px);transition:all .3s cubic-bezier(0.25, 0.8, 0.25, 1);position:relative;overflow:hidden}
.dcard::before{content:"";position:absolute;top:0;left:0;width:100%;height:100%;background:linear-gradient(180deg,rgba(255,255,255,0.03) 0%,transparent 100%);opacity:0;transition:opacity .3s}
.dcard:hover{border-color:var(--border-hover);transform:translateY(-2px);box-shadow:0 12px 30px rgba(0,0,0,0.3);background:var(--surface-hover)}
.dcard:hover::before{opacity:1}
.dcard .dt{font-weight:700;font-size:1.1rem;letter-spacing:-0.01em;position:relative;z-index:1}
.src-links{display:flex;flex-direction:column;gap:6px;position:relative;z-index:1;min-width:100px;align-items:flex-end}
.src-btn{font-size:.75rem;font-weight:600;padding:6px 14px;border-radius:10px;display:inline-flex;align-items:center;gap:6px;transition:all .2s;text-decoration:none;width:110px;justify-content:center}
.src-btn span{font-weight:800;opacity:0.9}
.src-btn.hf{background:rgba(255,157,0,0.08);border:1px solid rgba(255,157,0,0.2);color:#ffb840}
.src-btn.hf:hover{background:rgba(255,157,0,0.15);border-color:rgba(255,157,0,0.3);color:#ffc860;transform:translateY(-1px)}
.src-btn.ax{background:rgba(99,130,255,0.08);border:1px solid rgba(99,130,255,0.2);color:#9db4ff}
.src-btn.ax:hover{background:rgba(99,130,255,0.15);border-color:rgba(99,130,255,0.3);color:#b0c4ff;transform:translateY(-1px)}
.dcard-refresh{position:absolute;top:10px;right:38px;width:24px;height:24px;border:none;border-radius:8px;background:transparent;color:var(--t3);font-size:1rem;cursor:pointer;display:flex;align-items:center;justify-content:center;opacity:0;transition:all .2s;z-index:2}
.dcard:hover .dcard-refresh{opacity:1}
.dcard-refresh:hover{color:var(--ac);background:rgba(99,130,255,0.15)}
@keyframes spin{from{transform:rotate(0deg)}to{transform:rotate(360deg)}}
.dcard-del{position:absolute;top:10px;right:10px;width:24px;height:24px;border:none;border-radius:8px;background:transparent;color:var(--t3);font-size:1rem;cursor:pointer;display:flex;align-items:center;justify-content:center;opacity:0;transition:all .2s;z-index:2}
.dcard:hover .dcard-del{opacity:1}
.dcard-del:hover{color:#ff6b6b;background:rgba(255,107,107,0.15)}
.topbar{position:sticky;top:0;z-index:100;background:rgba(7,10,19,0.85);backdrop-filter:blur(20px);-webkit-backdrop-filter:blur(20px);border-bottom:1px solid var(--border);padding:14px 20px}
.topbar-in{max-width:1100px;margin:0 auto;display:flex;align-items:center;gap:16px;flex-wrap:wrap}
.back{color:var(--t2);font-size:.9rem;font-weight:500;display:flex;align-items:center;gap:6px;transition:color .2s}
.back:hover{color:var(--t)}
.topbar h2{font-size:1.1rem;font-weight:700;letter-spacing:-0.01em;color:var(--t)}
.spacer{flex:1}
.search{position:relative;width:300px}
.search input{width:100%;background:var(--surface);border:1px solid var(--border);border-radius:12px;padding:10px 14px 10px 40px;color:var(--t);font-size:.9rem;font-family:inherit;outline:0;transition:all .2s;backdrop-filter:blur(8px)}
.search input:focus{border-color:var(--ac);background:var(--surface-hover);box-shadow:0 0 0 3px rgba(99,130,255,0.15)}
.search input::placeholder{color:var(--t3)}
.search svg{position:absolute;left:14px;top:50%;transform:translateY(-50%);color:var(--t2)}
.cnt{font-size:.85rem;color:var(--t3);font-weight:500;white-space:nowrap}
.filters{max-width:1100px;margin:0 auto;padding:20px 20px 0;display:flex;gap:10px;flex-wrap:wrap;align-items:center}
.fbtn{background:var(--surface);border:1px solid var(--border);border-radius:10px;padding:8px 16px;color:var(--t2);font-size:.85rem;font-weight:500;cursor:pointer;font-family:inherit;white-space:nowrap;display:inline-flex;align-items:center;gap:6px;transition:all .2s;backdrop-filter:blur(8px)}
.fbtn:hover{border-color:var(--border-hover);color:var(--t);background:var(--surface-hover);transform:translateY(-1px)}
.fbtn.on{background:var(--ac);border-color:var(--ac);color:#fff;box-shadow:0 4px 12px rgba(99,130,255,0.2)}
.fbtn.on-hf{background:var(--hf);border-color:var(--hf);color:#fff;box-shadow:0 4px 12px rgba(255,157,0,0.2)}
.fc{opacity:.8;font-size:.75rem;font-weight:600}
.cdot{width:8px;height:8px;border-radius:50%;display:inline-block}
.fsep{width:1px;height:24px;background:var(--border);margin:0 4px}
.list{max-width:1100px;margin:0 auto;padding:20px 20px 80px}
.sec-block{margin-bottom:40px}
.sec-head{display:flex;align-items:center;gap:12px;padding:0 0 16px;border-bottom:1px solid var(--border);margin-bottom:20px}
.sec-icon{width:32px;height:32px;border-radius:10px;display:flex;align-items:center;justify-content:center;color:#fff;font-size:.8rem;font-weight:800;box-shadow:0 4px 12px rgba(0,0,0,0.2)}
.sec-title{font-size:1.2rem;font-weight:700;letter-spacing:-0.01em}
.sec-cnt{font-size:.85rem;font-weight:500;color:var(--t3);margin-left:auto}
.arxiv-filters{display:flex;gap:8px;flex-wrap:wrap;margin-bottom:20px}
.card{background:var(--surface);border:1px solid var(--border);border-radius:16px;padding:24px 28px;margin-bottom:16px;transition:all .3s cubic-bezier(0.25, 0.8, 0.25, 1);backdrop-filter:blur(12px)}
.card:hover{border-color:var(--border-hover);background:var(--surface-hover);transform:translateY(-2px);box-shadow:0 12px 30px rgba(0,0,0,0.2)}
.ch{display:flex;align-items:flex-start;gap:16px}
.ci{font-size:.8rem;color:var(--t3);min-width:30px;padding-top:4px;font-weight:700;font-variant-numeric:tabular-nums}
.cb{flex:1;min-width:0}
.ct{font-size:1.15rem;font-weight:700;line-height:1.4;margin-bottom:6px;letter-spacing:-0.01em}
.ct a{color:var(--t)}.ct a:hover{color:var(--ac)}
.sum-cn{font-size:.9rem;font-weight:500;color:var(--ac2);margin-top:4px;margin-bottom:8px;line-height:1.5}
.ca{font-size:.9rem;color:var(--t2);margin-bottom:12px;line-height:1.5}
.tags{display:flex;gap:6px;flex-wrap:wrap;align-items:center}
.tag{font-size:.75rem;font-weight:600;padding:4px 10px;border-radius:6px;background:rgba(255,255,255,0.04);border:1px solid var(--border);color:var(--t2)}
.actions{display:flex;gap:6px;flex-shrink:0;align-items:flex-start;margin-left:8px}
.abtn{width:36px;height:36px;border:1px solid var(--border);border-radius:10px;background:var(--surface);color:var(--t2);font-size:1.1rem;cursor:pointer;display:flex;align-items:center;justify-content:center;transition:all .2s;font-family:inherit}
.abtn:hover{background:var(--surface-hover);border-color:var(--border-hover);color:var(--t);transform:translateY(-1px)}
.chk-btn:hover,.chk-btn.on{color:#38d9c9;border-color:rgba(56,217,201,0.3);background:rgba(56,217,201,0.08);box-shadow:0 4px 12px rgba(56,217,201,0.15)}
.card.checked{border-color:rgba(56,217,201,0.25);background:rgba(56,217,201,0.03)}
.fav-btn:hover,.fav-btn.on{color:#ff4d6a;border-color:rgba(255,77,106,0.3);background:rgba(255,77,106,0.08);box-shadow:0 4px 12px rgba(255,77,106,0.15)}
.fav-btn.on{font-size:1rem}
.del-btn:hover{color:#ff6b6b;border-color:rgba(255,107,107,0.3);background:rgba(255,107,107,0.08)}
.card.deleted{opacity:0;transform:scale(0.95);pointer-events:none;max-height:0;padding:0;margin:0;border:0;overflow:hidden;transition:all .3s cubic-bezier(0.25, 0.8, 0.25, 1)}
.links{display:flex;gap:6px;flex-shrink:0;align-items:flex-start;margin-left:8px}
.links a{font-size:.8rem;font-weight:600;color:var(--ac);padding:8px 14px;border:1px solid rgba(99,130,255,0.2);border-radius:10px;background:rgba(99,130,255,0.05);transition:all .2s}
.links a:hover{background:rgba(99,130,255,0.15);border-color:rgba(99,130,255,0.3);transform:translateY(-1px)}
.abs{margin-top:16px;margin-left:46px;font-size:.95rem;line-height:1.7;color:var(--t2);background:rgba(0,0,0,0.2);padding:16px 20px;border-radius:12px;border:1px solid var(--border)}
.toggle{margin-top:12px;margin-left:46px;font-size:.85rem;font-weight:600;color:var(--ac);cursor:pointer;user-select:none;padding:6px 12px;display:inline-flex;align-items:center;gap:6px;border-radius:8px;background:var(--surface);border:1px solid var(--border);transition:all .2s}
.toggle:hover{background:var(--surface-hover);border-color:var(--ac);color:var(--ac-hover);transform:translateY(-1px)}
.nr{text-align:center;padding:80px 20px;color:var(--t3);font-size:1rem}
.stop{position:fixed;bottom:30px;right:30px;width:48px;height:48px;background:var(--ac);border:1px solid rgba(255,255,255,0.1);border-radius:14px;color:#fff;font-size:1.3rem;cursor:pointer;opacity:0;transition:all .3s cubic-bezier(0.25, 0.8, 0.25, 1);z-index:99;box-shadow:0 8px 24px rgba(99,130,255,0.25);transform:translateY(20px)}
.stop.v{opacity:1;transform:translateY(0)}
.stop:hover{background:var(--ac-hover);transform:translateY(-3px);box-shadow:0 12px 30px rgba(99,130,255,0.35)}
.fetch-panel{display:flex;align-items:center;gap:12px;margin-bottom:20px;flex-wrap:wrap;background:var(--surface);padding:16px 20px;border-radius:16px;border:1px solid var(--border);backdrop-filter:blur(12px)}
.fetch-date{background:rgba(0,0,0,0.2);border:1px solid var(--border);border-radius:10px;padding:8px 14px;color:var(--t);font-size:.9rem;font-weight:500;font-family:inherit;outline:0;color-scheme:dark;transition:all .2s}
.fetch-date:focus{border-color:var(--ac);box-shadow:0 0 0 3px rgba(99,130,255,0.15)}
.rbtn{font-size:.85rem;font-weight:600;padding:8px 18px;border-radius:10px;background:var(--ac);color:#fff;text-transform:none;letter-spacing:0;text-decoration:none;transition:all .2s;display:inline-flex;align-items:center;gap:6px;border:1px solid rgba(255,255,255,0.1);cursor:pointer;font-family:inherit;box-shadow:0 4px 12px rgba(99,130,255,0.2)}
.rbtn:hover{background:var(--ac-hover);color:#fff;transform:translateY(-1px);box-shadow:0 6px 16px rgba(99,130,255,0.3)}
.stop-btn{background:var(--surface);color:var(--t2);border:1px solid var(--border);box-shadow:none}.stop-btn:hover{background:var(--surface-hover);color:var(--t);border-color:var(--border-hover)}
.fetch-status{font-size:.85rem;color:var(--t2);font-weight:500;margin-left:4px}
footer{text-align:center;padding:40px 0;color:var(--t3);font-size:.85rem;margin-top:40px;border-top:1px solid var(--border)}
.chat-btn{position:fixed;bottom:30px;left:30px;width:52px;height:52px;background:var(--ac);border:1px solid rgba(255,255,255,0.1);border-radius:50%;color:#fff;font-size:1.5rem;cursor:pointer;display:flex;align-items:center;justify-content:center;z-index:200;box-shadow:0 8px 24px rgba(99,130,255,0.3);transition:all .3s}
.chat-btn:hover{transform:scale(1.1);box-shadow:0 12px 30px rgba(99,130,255,0.4)}
.chat-box{position:fixed;bottom:90px;left:20px;width:380px;max-width:calc(100vw - 40px);height:500px;max-height:calc(100vh - 120px);background:rgba(7,10,19,0.95);border:1px solid var(--border);border-radius:20px;z-index:200;display:none;flex-direction:column;backdrop-filter:blur(20px);box-shadow:0 20px 60px rgba(0,0,0,0.5)}
.chat-box.open{display:flex}
.chat-header{padding:16px 20px;border-bottom:1px solid var(--border);display:flex;align-items:center;justify-content:space-between;flex-shrink:0}
.chat-header span{font-weight:700;font-size:1rem}
.chat-close{background:none;border:none;color:var(--t3);font-size:1.3rem;cursor:pointer;padding:4px}
.chat-close:hover{color:var(--t)}
.chat-msgs{flex:1;overflow-y:auto;padding:16px 20px;display:flex;flex-direction:column;gap:12px}
.chat-msg{max-width:85%;padding:12px 16px;border-radius:14px;font-size:.9rem;line-height:1.6;word-break:break-word}
.chat-msg.user{align-self:flex-end;background:var(--ac);color:#fff;border-bottom-right-radius:4px}
.chat-msg.bot{align-self:flex-start;background:var(--surface-hover);color:var(--t);border:1px solid var(--border);border-bottom-left-radius:4px}
.chat-msg.loading{color:var(--t3);font-style:italic}
.chat-input{display:flex;gap:8px;padding:12px 16px;border-top:1px solid var(--border);flex-shrink:0}
.chat-input input{flex:1;background:var(--surface);border:1px solid var(--border);border-radius:12px;padding:10px 14px;color:var(--t);font-size:.9rem;font-family:inherit;outline:0}
.chat-input input:focus{border-color:var(--ac)}
.chat-input button{background:var(--ac);border:none;border-radius:12px;color:#fff;padding:10px 16px;cursor:pointer;font-family:inherit;font-weight:600;font-size:.9rem;transition:all .2s}
.chat-input button:hover{background:var(--ac-hover)}
.fav-card{background:var(--surface);border:1px solid var(--border);border-radius:16px;padding:20px 24px;margin-bottom:12px;display:flex;align-items:center;gap:20px;transition:all .3s cubic-bezier(0.25, 0.8, 0.25, 1);backdrop-filter:blur(12px)}
.fav-card:hover{border-color:var(--border-hover);background:var(--surface-hover);transform:translateY(-2px);box-shadow:0 12px 30px rgba(0,0,0,0.2)}
.fav-heart{color:#ff4d6a;font-size:1.4rem;flex-shrink:0;text-shadow:0 0 12px rgba(255,77,106,0.3)}
.fav-info{flex:1;min-width:0}
.fav-title{font-size:1.1rem;font-weight:700;line-height:1.4;margin-bottom:6px;letter-spacing:-0.01em}
.fav-title a{color:var(--t)}.fav-title a:hover{color:var(--ac)}
.fav-links{display:flex;gap:8px;flex-shrink:0}
.fav-links a{font-size:.8rem;font-weight:600;color:var(--ac);padding:6px 14px;border:1px solid rgba(99,130,255,0.2);border-radius:10px;background:rgba(99,130,255,0.05);transition:all .2s}
.fav-links a:hover{background:rgba(99,130,255,0.15);border-color:rgba(99,130,255,0.3);transform:translateY(-1px)}
.rm-btn{width:36px;height:36px;border:1px solid var(--border);border-radius:10px;background:var(--surface);color:var(--t3);font-size:1.2rem;cursor:pointer;display:flex;align-items:center;justify-content:center;transition:all .2s;flex-shrink:0}
.rm-btn:hover{color:#ff6b6b;border-color:rgba(255,107,107,0.3);background:rgba(255,107,107,0.08);transform:translateY(-1px)}
.clear-btn{font-size:.85rem;font-weight:600;padding:8px 16px;border-radius:10px;background:rgba(255,107,107,0.1);border:1px solid rgba(255,107,107,0.2);color:#ff6b6b;cursor:pointer;font-family:inherit;transition:all .2s}
.clear-btn:hover{background:rgba(255,107,107,0.2);border-color:rgba(255,107,107,0.4);transform:translateY(-1px)}
@media(max-width:768px){
  h1{font-size:2rem}
  .c{padding:30px 16px}
  .search{width:100%;order:10}
  .links{display:none}
  .ci{display:none}
  .abs{margin-left:0;padding:12px 16px}
  .toggle{margin-left:0}
  .ch{gap:12px;flex-direction:column}
  .actions{margin-left:0;margin-top:12px;width:100%;justify-content:flex-start}
  .card{padding:20px}
  .fav-card{flex-direction:column;align-items:flex-start;gap:12px;padding:16px}
  .fav-links{width:100%}
  .rm-btn{position:absolute;top:16px;right:16px}
}
</style></head><body>
<div class="topbar"><div class="topbar-in">
<a class="back" href="index.html">&#8592; 首页</a>
<h2>CVPR 2026</h2><span class="spacer"></span>
<button class="rbtn" onclick="doFetchCvpr()">&#x21bb; 更新抓取</button>
<span class="fetch-status" id="fs" style="font-size:.8rem;color:var(--t3)"></span>
<div class="search"><svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2.5"><circle cx="11" cy="11" r="7"/><path d="M21 21l-4.35-4.35"/></svg>
<input id="si" type="text" placeholder="搜索标题、作者..." oninput="filter()"></div>
<span class="cnt" id="cnt"></span></div></div>
<div class="list" id="pl"></div>
<button class="stop" id="st" onclick="window.scrollTo({top:0,behavior:'smooth'})">&#8593;</button>
<script>
const ALL=`<div class="card" data-pid="2602.23361v1"><div class="ch">
<span class="ci">1</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.23361v1" target="_blank">VGG-T$^3$: Offline Feed-Forward 3D Reconstruction at Scale</a></div>
<div class="sum-cn">研究问题：解决离线前馈方法在计算和内存需求上随输入图像数量呈二次增长的问题。方法：基于关键洞察，即瓶颈源于输入图像数量的变化。核心创新点：提出可扩展的3D重建模型。实验结果：模型有效降低了计算和内存需求。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.23361v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.23361v1','VGG-T$^3$: Offline Feed-Forward 3D Reconstruction at Scale','http://arxiv.org/abs/2602.23361v1','http://arxiv.org/pdf/2602.23361v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.23361v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.23361v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.23361v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.23359v1"><div class="ch">
<span class="ci">2</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.23359v1" target="_blank">SeeThrough3D: Occlusion Aware 3D Control in Text-to-Image Generation</a></div>
<div class="sum-cn">研究问题：识别遮挡推理作为3D布局条件生成的基础但被忽视的方面。方法：强调生成部分遮挡物体时深度一致几何和比例的重要性。核心创新点：提出遮挡推理方法。实验结果：生成具有深度一致几何和比例的物体。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.23359v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.23359v1','SeeThrough3D: Occlusion Aware 3D Control in Text-to-Image Generation','http://arxiv.org/abs/2602.23359v1','http://arxiv.org/pdf/2602.23359v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.23359v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.23359v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.23359v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.23191v1"><div class="ch">
<span class="ci">3</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.23191v1" target="_blank">Uni-Animator: Towards Unified Visual Colorization</a></div>
<div class="sum-cn">研究问题：统一图像和视频草图着色。方法：提出基于扩散Transformer（DiT）的Uni-Animator框架。核心创新点：实现图像和视频任务的统一着色。实验结果：提高了着色精度和保真度。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.23191v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.23191v1','Uni-Animator: Towards Unified Visual Colorization','http://arxiv.org/abs/2602.23191v1','http://arxiv.org/pdf/2602.23191v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.23191v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.23191v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.23191v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.23153v1"><div class="ch">
<span class="ci">4</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.23153v1" target="_blank">Efficient Encoder-Free Fourier-based 3D Large Multimodal Model</a></div>
<div class="sum-cn">研究问题：将2D大型多模态模型（LMMs）扩展到3D数据。方法：提出轻量级视觉编码器以提取几何特征。核心创新点：解决3D数据无序性的挑战。实验结果：提高了3D数据处理的效率。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.23153v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.23153v1','Efficient Encoder-Free Fourier-based 3D Large Multimodal Model','http://arxiv.org/abs/2602.23153v1','http://arxiv.org/pdf/2602.23153v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.23153v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.23153v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.23153v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.23120v1"><div class="ch">
<span class="ci">5</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.23120v1" target="_blank">TriLite: Efficient Weakly Supervised Object Localization with Universal Visual Features and Tri-Region Disentanglement</a></div>
<div class="sum-cn">研究问题：降低弱监督目标定位（WSOL）的训练成本。方法：提出基于图像级标签的WSOL方法。核心创新点：减少多阶段管道和大型骨干网络的依赖。实验结果：降低了训练成本。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.23120v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.23120v1','TriLite: Efficient Weakly Supervised Object Localization with Universal Visual Features and Tri-Region Disentanglement','http://arxiv.org/abs/2602.23120v1','http://arxiv.org/pdf/2602.23120v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.23120v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.23120v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.23120v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.23058v1"><div class="ch">
<span class="ci">6</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.23058v1" target="_blank">GeoWorld: Geometric World Models</a></div>
<div class="sum-cn">研究问题：解决基于能量预测的视觉世界模型在欧几里得空间中学习潜在表示的挑战。方法：提出在非欧几里得空间中学习潜在表示。核心创新点：改进了多步视觉规划。实验结果：提高了规划性能。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.23058v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.23058v1','GeoWorld: Geometric World Models','http://arxiv.org/abs/2602.23058v1','http://arxiv.org/pdf/2602.23058v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.23058v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.23058v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.23058v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.23040v1"><div class="ch">
<span class="ci">7</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.23040v1" target="_blank">PackUV: Packed Gaussian UV Maps for 4D Volumetric Video</a></div>
<div class="sum-cn">研究问题：解决体量视频的重建、存储和流式传输问题。方法：提出基于体素的视频重建方法。核心创新点：解决长序列、时间不一致性和大运动下的重建问题。实验结果：提高了视频重建质量。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.23040v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.23040v1','PackUV: Packed Gaussian UV Maps for 4D Volumetric Video','http://arxiv.org/abs/2602.23040v1','http://arxiv.org/pdf/2602.23040v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.23040v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.23040v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.23040v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.23022v1"><div class="ch">
<span class="ci">8</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.23022v1" target="_blank">DMAligner: Enhancing Image Alignment via Diffusion Model Based View Synthesis</a></div>
<div class="sum-cn">研究问题：改进图像对齐方法，解决遮挡和光照变化等问题。方法：提出基于深度学习的图像对齐方法。核心创新点：提高对齐精度和鲁棒性。实验结果：提高了图像对齐质量。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.23022v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.23022v1','DMAligner: Enhancing Image Alignment via Diffusion Model Based View Synthesis','http://arxiv.org/abs/2602.23022v1','http://arxiv.org/pdf/2602.23022v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.23022v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.23022v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.23022v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.23013v1"><div class="ch">
<span class="ci">9</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.23013v1" target="_blank">SubspaceAD: Training-Free Few-Shot Anomaly Detection via Subspace Modeling</a></div>
<div class="sum-cn">研究问题：降低工业检测中视觉异常检测的样本数量。方法：提出基于基础模型特征的少样本方法。核心创新点：减少对记忆库、辅助数据集和多模态调优的依赖。实验结果：提高了检测性能。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.23013v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.23013v1','SubspaceAD: Training-Free Few-Shot Anomaly Detection via Subspace Modeling','http://arxiv.org/abs/2602.23013v1','http://arxiv.org/pdf/2602.23013v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.23013v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.23013v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.23013v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.22949v1"><div class="ch">
<span class="ci">10</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.22949v1" target="_blank">OpenFS: Multi-Hand-Capable Fingerspelling Recognition with Implicit Signing-Hand Detection and Frame-Wise Letter-Conditioned Synthesis</a></div>
<div class="sum-cn">研究问题：自动识别手语中的手指拼写。方法：提出基于深度学习的手指拼写识别方法。核心创新点：解决手语识别中的挑战。实验结果：提高了手指拼写识别的准确性。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.22949v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.22949v1','OpenFS: Multi-Hand-Capable Fingerspelling Recognition with Implicit Signing-Hand Detection and Frame-Wise Letter-Conditioned Synthesis','http://arxiv.org/abs/2602.22949v1','http://arxiv.org/pdf/2602.22949v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.22949v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.22949v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.22949v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.22917v1"><div class="ch">
<span class="ci">11</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.22917v1" target="_blank">Towards Multimodal Domain Generalization with Few Labels</a></div>
<div class="sum-cn">研究问题：如何从多源数据中学习鲁棒的多模态模型，同时保持数据效率以降低标注成本。方法：提出半监督多模态域泛化（SSMDG）问题。创新点：学习跨域泛化的多模态模型。结果：模型在未见过的领域上表现良好。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.22917v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.22917v1','Towards Multimodal Domain Generalization with Few Labels','http://arxiv.org/abs/2602.22917v1','http://arxiv.org/pdf/2602.22917v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.22917v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.22917v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.22917v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.22862v1"><div class="ch">
<span class="ci">12</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.22862v1" target="_blank">GraspLDP: Towards Generalizable Grasping Policy via Latent Diffusion</a></div>
<div class="sum-cn">研究问题：如何提高通过模仿学习学习的操作策略的抓取精度和泛化能力。方法：采用基于扩散的政策学习方法。创新点：优化抓取策略。结果：抓取精度和泛化能力显著提升。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.22862v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.22862v1','GraspLDP: Towards Generalizable Grasping Policy via Latent Diffusion','http://arxiv.org/abs/2602.22862v1','http://arxiv.org/pdf/2602.22862v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.22862v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.22862v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.22862v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.22819v1"><div class="ch">
<span class="ci">13</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.22819v1" target="_blank">Face Time Traveller : Travel Through Ages Without Losing Identity</a></div>
<div class="sum-cn">研究问题：如何实现逼真的面部年龄变换，同时保留身份和视觉真实性。方法：提出新的年龄变换方法。创新点：考虑环境因素和遗传因素。结果：年龄变换效果逼真。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.22819v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.22819v1','Face Time Traveller : Travel Through Ages Without Losing Identity','http://arxiv.org/abs/2602.22819v1','http://arxiv.org/pdf/2602.22819v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.22819v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.22819v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.22819v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.22779v1"><div class="ch">
<span class="ci">14</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.22779v1" target="_blank">TrajTok: Learning Trajectory Tokens enables better Video Understanding</a></div>
<div class="sum-cn">研究问题：如何提高视频模型的效率和解耦视频时长与标记数量。方法：采用基于轨迹的标记器。创新点：减少冗余标记。结果：视频效率和解耦效果显著。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.22779v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.22779v1','TrajTok: Learning Trajectory Tokens enables better Video Understanding','http://arxiv.org/abs/2602.22779v1','http://arxiv.org/pdf/2602.22779v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.22779v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.22779v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.22779v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.22727v1"><div class="ch">
<span class="ci">15</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.22727v1" target="_blank">HulluEdit: Single-Pass Evidence-Consistent Subspace Editing for Mitigating Hallucinations in Large Vision-Language Models</a></div>
<div class="sum-cn">研究问题：如何解决大型视觉语言模型（LVLMs）中的对象幻觉问题。方法：提出新的方法平衡效率和准确性。创新点：降低模型复杂度。结果：模型部署更加可靠。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.22727v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.22727v1','HulluEdit: Single-Pass Evidence-Consistent Subspace Editing for Mitigating Hallucinations in Large Vision-Language Models','http://arxiv.org/abs/2602.22727v1','http://arxiv.org/pdf/2602.22727v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.22727v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.22727v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.22727v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.22716v1"><div class="ch">
<span class="ci">16</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.22716v1" target="_blank">SoPE: Spherical Coordinate-Based Positional Embedding for Enhancing Spatial Perception of 3D LVLMs</a></div>
<div class="sum-cn">研究问题：如何优化3D LVLMs中的位置依赖建模机制。方法：提出新的3D多模态理解框架。创新点：改进RoPE机制。结果：3D多模态理解能力提升。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.22716v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.22716v1','SoPE: Spherical Coordinate-Based Positional Embedding for Enhancing Spatial Perception of 3D LVLMs','http://arxiv.org/abs/2602.22716v1','http://arxiv.org/pdf/2602.22716v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.22716v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.22716v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.22716v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.22654v1"><div class="ch">
<span class="ci">17</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.22654v1" target="_blank">Denoising as Path Planning: Training-Free Acceleration of Diffusion Models with DPCache</a></div>
<div class="sum-cn">研究问题：如何降低扩散模型在图像和视频生成中的计算开销。方法：采用基于缓存的加速策略。创新点：无需训练。结果：生成效率提高。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.22654v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.22654v1','Denoising as Path Planning: Training-Free Acceleration of Diffusion Models with DPCache','http://arxiv.org/abs/2602.22654v1','http://arxiv.org/pdf/2602.22654v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.22654v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.22654v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.22654v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.22639v1"><div class="ch">
<span class="ci">18</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.22639v1" target="_blank">QuadSync: Quadrifocal Tensor Synchronization via Tucker Decomposition</a></div>
<div class="sum-cn">研究问题：如何提高结构从运动中的四焦点张量恢复能力。方法：提供新的框架。创新点：挑战传统观点。结果：恢复能力显著提升。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.22639v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.22639v1','QuadSync: Quadrifocal Tensor Synchronization via Tucker Decomposition','http://arxiv.org/abs/2602.22639v1','http://arxiv.org/pdf/2602.22639v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.22639v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.22639v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.22639v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.22625v1"><div class="ch">
<span class="ci">19</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.22625v1" target="_blank">DiffBMP: Differentiable Rendering with Bitmap Primitives</a></div>
<div class="sum-cn">研究问题：如何为位图图像提供可扩展和高效的可微分渲染引擎。方法：提出DiffBMP。创新点：支持位图图像。结果：渲染效率提高。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.22625v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.22625v1','DiffBMP: Differentiable Rendering with Bitmap Primitives','http://arxiv.org/abs/2602.22625v1','http://arxiv.org/pdf/2602.22625v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.22625v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.22625v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.22625v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.22620v1"><div class="ch">
<span class="ci">20</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.22620v1" target="_blank">Coded-E2LF: Coded Aperture Light Field Imaging from Events</a></div>
<div class="sum-cn">研究问题：如何使用编码事件和静止事件相机获取4D光场。方法：提出Coded-E2LF方法。创新点：采用编码孔径。结果：获取4D光场效果良好。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.22620v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.22620v1','Coded-E2LF: Coded Aperture Light Field Imaging from Events','http://arxiv.org/abs/2602.22620v1','http://arxiv.org/pdf/2602.22620v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.22620v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.22620v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.22620v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.22594v1"><div class="ch">
<span class="ci">21</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.22594v1" target="_blank">Causal Motion Diffusion Models for Autoregressive Motion Generation</a></div>
<div class="sum-cn">研究问题：现有运动扩散模型在实时性和时间因果性方面存在限制。方法：提出一种新的自回归模型，结合时间因果性和实时性。创新点：自回归模型结合了时间因果性和实时性。结果：模型在保持实时性的同时提高了运动合成的真实感。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.22594v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.22594v1','Causal Motion Diffusion Models for Autoregressive Motion Generation','http://arxiv.org/abs/2602.22594v1','http://arxiv.org/pdf/2602.22594v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.22594v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.22594v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.22594v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.23141v1"><div class="ch">
<span class="ci">22</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.23141v1" target="_blank">No Labels, No Look-Ahead: Unsupervised Online Video Stabilization with Classical Priors</a></div>
<div class="sum-cn">研究问题：现有视频稳定方法依赖深度学习，需要大量数据。方法：提出一种无监督框架，采用经典稳定流程和多线程缓冲机制。创新点：无监督框架和高效的多线程缓冲机制。结果：方法无需配对数据集，提高了在线视频稳定效果。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.23141v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.23141v1','No Labels, No Look-Ahead: Unsupervised Online Video Stabilization with Classical Priors','http://arxiv.org/abs/2602.23141v1','http://arxiv.org/pdf/2602.23141v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.23141v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.23141v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.23141v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.22932v1"><div class="ch">
<span class="ci">23</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.22932v1" target="_blank">MSJoE: Jointly Evolving MLLM and Sampler for Efficient Long-Form Video Understanding</a></div>
<div class="sum-cn">研究问题：长视频理解对多模态大型语言模型（MLLMs）是一个挑战。方法：提出MSJoE框架，联合进化MLLM和轻量级关键帧采样器。创新点：联合进化MLLM和关键帧采样器。结果：提高了长视频理解效率。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.22932v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.22932v1','MSJoE: Jointly Evolving MLLM and Sampler for Efficient Long-Form Video Understanding','http://arxiv.org/abs/2602.22932v1','http://arxiv.org/pdf/2602.22932v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.22932v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.22932v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.22932v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.22667v1"><div class="ch">
<span class="ci">24</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.22667v1" target="_blank">Monocular Open Vocabulary Occupancy Prediction for Indoor Scenes</a></div>
<div class="sum-cn">研究问题：开放词汇3D占用对具身智能体至关重要。方法：探索开放词汇占用在室内环境中的应用。创新点：将开放词汇占用应用于室内环境。结果：提高了智能体对复杂室内环境的理解能力。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.22667v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.22667v1','Monocular Open Vocabulary Occupancy Prediction for Indoor Scenes','http://arxiv.org/abs/2602.22667v1','http://arxiv.org/pdf/2602.22667v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.22667v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.22667v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.22667v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.22601v1"><div class="ch">
<span class="ci">25</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.22601v1" target="_blank">$φ$-DPO: Fairness Direct Preference Optimization Approach to Continual Learning in Large Multimodal Models</a></div>
<div class="sum-cn">研究问题：大型多模态模型（LMMs）的持续学习公平性是一个挑战。方法：研究不平衡数据分布下的持续学习公平性。创新点：关注不平衡数据分布下的持续学习公平性。结果：提高了LMMs的持续学习公平性。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.22601v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.22601v1','$φ$-DPO: Fairness Direct Preference Optimization Approach to Continual Learning in Large Multimodal Models','http://arxiv.org/abs/2602.22601v1','http://arxiv.org/pdf/2602.22601v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.22601v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.22601v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.22601v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.22695v1"><div class="ch">
<span class="ci">26</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.22695v1" target="_blank">GFRRN: Explore the Gaps in Single Image Reflection Removal</a></div>
<div class="sum-cn">研究问题：现有双流方法在单图像反射去除（SIRR）中存在局限性。方法：提出一种新的方法，解决语义理解差距和特征交互问题。创新点：解决语义理解差距和特征交互问题。结果：提高了SIRR的性能。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.22695v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.22695v1','GFRRN: Explore the Gaps in Single Image Reflection Removal','http://arxiv.org/abs/2602.22695v1','http://arxiv.org/pdf/2602.22695v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.22695v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.22695v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.22695v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.22419v1"><div class="ch">
<span class="ci">27</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.22419v1" target="_blank">CLIP Is Shortsighted: Paying Attention Beyond the First Sentence</a></div>
<div class="sum-cn">研究问题：CLIP模型的预训练存在局限性。方法：研究CLIP模型的预训练问题。创新点：关注CLIP模型的预训练问题。结果：提高了CLIP模型的多模态特征学习效果。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.22419v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.22419v1','CLIP Is Shortsighted: Paying Attention Beyond the First Sentence','http://arxiv.org/abs/2602.22419v1','http://arxiv.org/pdf/2602.22419v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.22419v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.22419v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.22419v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.22394v1"><div class="ch">
<span class="ci">28</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.22394v1" target="_blank">Vision Transformers Need More Than Registers</a></div>
<div class="sum-cn">研究问题：Vision Transformers（ViTs）在下游任务中存在缺陷。方法：分析ViTs中的缺陷。创新点：系统分析ViTs中的缺陷。结果：提高了ViTs在下游任务中的性能。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.22394v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.22394v1','Vision Transformers Need More Than Registers','http://arxiv.org/abs/2602.22394v1','http://arxiv.org/pdf/2602.22394v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.22394v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.22394v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.22394v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.22376v1"><div class="ch">
<span class="ci">29</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.22376v1" target="_blank">AeroDGS: Physically Consistent Dynamic Gaussian Splatting for Single-Sequence Aerial 4D Reconstruction</a></div>
<div class="sum-cn">研究问题：现有4D场景重建方法在空中条件下存在局限性。方法：提出一种新的方法，解决空中条件下的4D场景重建问题。创新点：解决空中条件下的4D场景重建问题。结果：提高了4D场景重建效果。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.22376v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.22376v1','AeroDGS: Physically Consistent Dynamic Gaussian Splatting for Single-Sequence Aerial 4D Reconstruction','http://arxiv.org/abs/2602.22376v1','http://arxiv.org/pdf/2602.22376v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.22376v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.22376v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.22376v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.22212v1"><div class="ch">
<span class="ci">30</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.22212v1" target="_blank">Neu-PiG: Neural Preconditioned Grids for Fast Dynamic Surface Reconstruction on Long Sequences</a></div>
<div class="sum-cn">研究问题：动态3D物体表面重建存在挑战。方法：提出一种新的方法，解决长序列表面重建问题。创新点：解决长序列表面重建问题。结果：提高了动态3D物体表面重建效果。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.22212v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.22212v1','Neu-PiG: Neural Preconditioned Grids for Fast Dynamic Surface Reconstruction on Long Sequences','http://arxiv.org/abs/2602.22212v1','http://arxiv.org/pdf/2602.22212v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.22212v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.22212v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.22212v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.22142v1"><div class="ch">
<span class="ci">31</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.22142v1" target="_blank">WeaveTime: Stream from Earlier Frames into Emergent Memory in VideoLLMs</a></div>
<div class="sum-cn">研究问题：多模态大型语言模型在流式场景中的适用性问题；方法：提出了一种新的诊断方法；创新点：针对流式场景优化了模型；结果：提高了模型在流式场景中的性能。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.22142v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.22142v1','WeaveTime: Stream from Earlier Frames into Emergent Memory in VideoLLMs','http://arxiv.org/abs/2602.22142v1','http://arxiv.org/pdf/2602.22142v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.22142v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.22142v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.22142v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.22140v1"><div class="ch">
<span class="ci">32</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.22140v1" target="_blank">Lumosaic: Hyperspectral Video via Active Illumination and Coded-Exposure Pixels</a></div>
<div class="sum-cn">研究问题：实时捕捉动态场景的紧凑型高光谱视频系统；方法：结合窄带LED阵列和CEP相机；创新点：实现像素级曝光控制；结果：提高了场景信息编码的效率。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.22140v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.22140v1','Lumosaic: Hyperspectral Video via Active Illumination and Coded-Exposure Pixels','http://arxiv.org/abs/2602.22140v1','http://arxiv.org/pdf/2602.22140v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.22140v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.22140v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.22140v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.22091v1"><div class="ch">
<span class="ci">33</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.22091v1" target="_blank">Learning to Drive is a Free Gift: Large-Scale Label-Free Autonomy Pretraining from Unposed In-The-Wild Videos</a></div>
<div class="sum-cn">研究问题：自动驾驶中，如何从无标注的ego-centric驾驶视频中学习语义结构和3D几何；方法：利用大型前馈空间模型；创新点：结合语义结构和3D几何信息；结果：提高了自动驾驶视频的识别精度。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.22091v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.22091v1','Learning to Drive is a Free Gift: Large-Scale Label-Free Autonomy Pretraining from Unposed In-The-Wild Videos','http://arxiv.org/abs/2602.22091v1','http://arxiv.org/pdf/2602.22091v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.22091v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.22091v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.22091v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.22059v1"><div class="ch">
<span class="ci">34</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.22059v1" target="_blank">NESTOR: A Nested MOE-based Neural Operator for Large-Scale PDE Pre-Training</a></div>
<div class="sum-cn">研究问题：神经算子解决PDEs的效率问题；方法：提出了一种新的神经算子；创新点：适用于多种PDE系统；结果：提高了计算效率。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.22059v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.22059v1','NESTOR: A Nested MOE-based Neural Operator for Large-Scale PDE Pre-Training','http://arxiv.org/abs/2602.22059v1','http://arxiv.org/pdf/2602.22059v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.22059v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.22059v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.22059v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.21963v1"><div class="ch">
<span class="ci">35</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.21963v1" target="_blank">Global-Aware Edge Prioritization for Pose Graph Initialization</a></div>
<div class="sum-cn">研究问题：SfM中初始化的重要性；方法：提出了一种新的初始化方法；创新点：基于几何验证；结果：提高了SfM的精度。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.21963v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.21963v1','Global-Aware Edge Prioritization for Pose Graph Initialization','http://arxiv.org/abs/2602.21963v1','http://arxiv.org/pdf/2602.21963v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.21963v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.21963v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.21963v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.21929v1"><div class="ch">
<span class="ci">36</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.21929v1" target="_blank">Geometry-as-context: Modulating Explicit 3D in Scene-consistent Video Generation to Geometry Context</a></div>
<div class="sum-cn">研究问题：场景一致的视频生成；方法：提出了一种新的视频生成模型；创新点：基于3D场景和相机轨迹；结果：提高了视频生成的质量。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.21929v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.21929v1','Geometry-as-context: Modulating Explicit 3D in Scene-consistent Video Generation to Geometry Context','http://arxiv.org/abs/2602.21929v1','http://arxiv.org/pdf/2602.21929v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.21929v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.21929v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.21929v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.21877v1"><div class="ch">
<span class="ci">37</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.21877v1" target="_blank">How to Take a Memorable Picture? Empowering Users with Actionable Feedback</a></div>
<div class="sum-cn">研究问题：图像记忆性研究；方法：提出了一种新的图像记忆性预测方法；创新点：结合被动预测和生成方法；结果：提高了图像记忆性预测的准确性。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.21877v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.21877v1','How to Take a Memorable Picture? Empowering Users with Actionable Feedback','http://arxiv.org/abs/2602.21877v1','http://arxiv.org/pdf/2602.21877v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.21877v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.21877v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.21877v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.21864v1"><div class="ch">
<span class="ci">38</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.21864v1" target="_blank">DynamicGTR: Leveraging Graph Topology Representation Preferences to Boost VLM Capabilities on Graph QAs</a></div>
<div class="sum-cn">研究问题：VLM在零样本问答中的挑战；方法：提出了一种新的VLM；创新点：结合结构化图和问答；结果：提高了VLM在问答中的性能。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.21864v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.21864v1','DynamicGTR: Leveraging Graph Topology Representation Preferences to Boost VLM Capabilities on Graph QAs','http://arxiv.org/abs/2602.21864v1','http://arxiv.org/pdf/2602.21864v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.21864v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.21864v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.21864v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.21779v1"><div class="ch">
<span class="ci">39</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.21779v1" target="_blank">Beyond Static Artifacts: A Forensic Benchmark for Video Deepfake Reasoning in Vision Language Models</a></div>
<div class="sum-cn">研究问题：深伪视频检测中的时间不一致性问题；方法：提出了一种新的深伪视频检测方法；创新点：结合时间信息；结果：提高了深伪视频检测的准确性。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.21779v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.21779v1','Beyond Static Artifacts: A Forensic Benchmark for Video Deepfake Reasoning in Vision Language Models','http://arxiv.org/abs/2602.21779v1','http://arxiv.org/pdf/2602.21779v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.21779v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.21779v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.21779v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.21754v1"><div class="ch">
<span class="ci">40</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.21754v1" target="_blank">LiREC-Net: A Target-Free and Learning-Based Network for LiDAR, RGB, and Event Calibration</a></div>
<div class="sum-cn">研究问题：多传感器融合中的标定问题；方法：提出了一种新的标定方法；创新点：基于自然驾驶场景；结果：提高了多传感器融合的精度。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.21754v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.21754v1','LiREC-Net: A Target-Free and Learning-Based Network for LiDAR, RGB, and Event Calibration','http://arxiv.org/abs/2602.21754v1','http://arxiv.org/pdf/2602.21754v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.21754v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.21754v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.21754v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.21698v1"><div class="ch">
<span class="ci">41</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.21698v1" target="_blank">E-comIQ-ZH: A Human-Aligned Dataset and Benchmark for Fine-Grained Evaluation of E-commerce Posters with Chain-of-Thought</a></div>
<div class="sum-cn">研究问题：生成式AI在商业海报制作中的应用，但现有模型缺乏对电子商务设计所需的功能性评估。方法：提出一种结合功能性评估的生成式AI模型。创新点：强调功能性评估，解决现有模型忽视的问题。实验结果：模型在功能性评估上表现优于现有模型。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.21698v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.21698v1','E-comIQ-ZH: A Human-Aligned Dataset and Benchmark for Fine-Grained Evaluation of E-commerce Posters with Chain-of-Thought','http://arxiv.org/abs/2602.21698v1','http://arxiv.org/pdf/2602.21698v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.21698v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.21698v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.21698v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.21655v1"><div class="ch">
<span class="ci">42</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.21655v1" target="_blank">CCCaption: Dual-Reward Reinforcement Learning for Complete and Correct Image Captioning</a></div>
<div class="sum-cn">研究问题：图像字幕生成依赖人工标注，存在主观性和不完整性。方法：提出一种基于深度学习的自动标注方法。创新点：利用深度学习技术自动生成标注，提高标注效率和准确性。实验结果：自动标注方法在准确性和效率上优于人工标注。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.21655v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.21655v1','CCCaption: Dual-Reward Reinforcement Learning for Complete and Correct Image Captioning','http://arxiv.org/abs/2602.21655v1','http://arxiv.org/pdf/2602.21655v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.21655v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.21655v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.21655v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.21499v1"><div class="ch">
<span class="ci">43</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.21499v1" target="_blank">Easy3E: Feed-Forward 3D Asset Editing via Rectified Voxel Flow</a></div>
<div class="sum-cn">研究问题：现有3D编辑方法计算量大，存在多视图不一致问题。方法：提出一种基于TRELLIS生成骨干的3D编辑框架。创新点：实现单次编辑即可修改3D模型，提高效率。实验结果：框架在编辑效果和效率上优于现有方法。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.21499v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.21499v1','Easy3E: Feed-Forward 3D Asset Editing via Rectified Voxel Flow','http://arxiv.org/abs/2602.21499v1','http://arxiv.org/pdf/2602.21499v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.21499v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.21499v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.21499v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.22150v2"><div class="ch">
<span class="ci">44</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.22150v2" target="_blank">CoLoGen: Progressive Learning of Concept-Localization Duality for Unified Image Generation</a></div>
<div class="sum-cn">研究问题：统一条件图像生成困难，不同任务依赖不同内部表示。方法：提出一种适用于不同任务的统一条件图像生成方法。创新点：针对不同任务的特点，设计相应的生成策略。实验结果：方法在多种任务上均取得良好效果。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.22150v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.22150v2','CoLoGen: Progressive Learning of Concept-Localization Duality for Unified Image Generation','http://arxiv.org/abs/2602.22150v2','http://arxiv.org/pdf/2602.22150v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.22150v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.22150v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.22150v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.22013v1"><div class="ch">
<span class="ci">45</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.22013v1" target="_blank">RobustVisRAG: Causality-Aware Vision-Based Retrieval-Augmented Generation under Visual Degradations</a></div>
<div class="sum-cn">研究问题：基于视觉的检索增强生成（VisRAG）模型在视觉输入扭曲时性能下降。方法：提出一种鲁棒的VisRAG模型。创新点：增强模型对视觉输入扭曲的鲁棒性。实验结果：模型在扭曲输入下仍保持较高性能。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.22013v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.22013v1','RobustVisRAG: Causality-Aware Vision-Based Retrieval-Augmented Generation under Visual Degradations','http://arxiv.org/abs/2602.22013v1','http://arxiv.org/pdf/2602.22013v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.22013v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.22013v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.22013v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.21952v1"><div class="ch">
<span class="ci">46</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.21952v1" target="_blank">MindDriver: Introducing Progressive Multimodal Reasoning for Autonomous Driving</a></div>
<div class="sum-cn">研究问题：视觉语言模型（VLM）的推理策略Chain-of-Thought（CoT）存在语义空间和轨迹空间差距。方法：提出一种改进的CoT方法。创新点：缩小语义空间和轨迹空间差距，提高推理准确性。实验结果：改进方法在推理准确性上优于现有方法。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.21952v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.21952v1','MindDriver: Introducing Progressive Multimodal Reasoning for Autonomous Driving','http://arxiv.org/abs/2602.21952v1','http://arxiv.org/pdf/2602.21952v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.21952v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.21952v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.21952v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.22286v1"><div class="ch">
<span class="ci">47</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.22286v1" target="_blank">OmniZip: Learning a Unified and Lightweight Lossless Compressor for Multi-Modal Data</a></div>
<div class="sum-cn">研究问题：现有无损压缩器针对单一模态，导致多模态设置下冗余部署。方法：设计一种统一的跨模态无损压缩器。创新点：实现多模态数据的高效压缩。实验结果：压缩器在压缩效果和效率上优于现有方法。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.22286v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.22286v1','OmniZip: Learning a Unified and Lightweight Lossless Compressor for Multi-Modal Data','http://arxiv.org/abs/2602.22286v1','http://arxiv.org/pdf/2602.22286v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.22286v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.22286v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.22286v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.21736v1"><div class="ch">
<span class="ci">48</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.21736v1" target="_blank">Joint-Aligned Latent Action: Towards Scalable VLA Pretraining in the Wild</a></div>
<div class="sum-cn">研究问题：视觉-语言-动作模型（VLAs）受限于大规模、多样化的机器人数据。方法：提出一种基于人类操作视频的VLAs学习方法。创新点：利用人类操作视频数据，提高模型性能。实验结果：方法在机器人任务上取得良好效果。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.21736v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.21736v1','Joint-Aligned Latent Action: Towards Scalable VLA Pretraining in the Wild','http://arxiv.org/abs/2602.21736v1','http://arxiv.org/pdf/2602.21736v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.21736v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.21736v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.21736v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.21591v1"><div class="ch">
<span class="ci">49</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.21591v1" target="_blank">CADC: Content Adaptive Diffusion-Based Generative Image Compression</a></div>
<div class="sum-cn">研究问题：基于扩散的生成图像压缩在超低比特率下重建效果有限。方法：提出一种内容自适应的压缩方法。创新点：确保编码器表示和解码器表示的一致性。实验结果：方法在重建效果和效率上优于现有方法。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.21591v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.21591v1','CADC: Content Adaptive Diffusion-Based Generative Image Compression','http://arxiv.org/abs/2602.21591v1','http://arxiv.org/pdf/2602.21591v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.21591v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.21591v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.21591v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.21552v1"><div class="ch">
<span class="ci">50</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.21552v1" target="_blank">Generalizing Visual Geometry Priors to Sparse Gaussian Occupancy Prediction</a></div>
<div class="sum-cn">研究问题：现有3D场景理解方法主要依赖深度先验，限制性能。方法：提出一种基于3D线索的3D场景理解方法。创新点：充分利用3D线索，提高性能。实验结果：方法在3D场景理解任务上取得良好效果。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.21552v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.21552v1','Generalizing Visual Geometry Priors to Sparse Gaussian Occupancy Prediction','http://arxiv.org/abs/2602.21552v1','http://arxiv.org/pdf/2602.21552v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.21552v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.21552v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.21552v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.21497v1"><div class="ch">
<span class="ci">51</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.21497v1" target="_blank">See It, Say It, Sorted: An Iterative Training-Free Framework for Visually-Grounded Multimodal Reasoning in LVLMs</a></div>
<div class="sum-cn">研究问题：多模态视觉语言模型在推理过程中易受视觉幻觉影响。方法：提出一种新的视觉语言模型，通过限制推理步骤的连贯性来减少幻觉传播。创新点：引入连贯性约束，提高推理的鲁棒性。实验结果：模型在多模态推理任务中表现优于现有方法。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.21497v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.21497v1','See It, Say It, Sorted: An Iterative Training-Free Framework for Visually-Grounded Multimodal Reasoning in LVLMs','http://arxiv.org/abs/2602.21497v1','http://arxiv.org/pdf/2602.21497v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.21497v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.21497v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.21497v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.21461v1"><div class="ch">
<span class="ci">52</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.21461v1" target="_blank">VecGlypher: Unified Vector Glyph Generation with Language Models</a></div>
<div class="sum-cn">研究问题：基于学习的方法在数字字体生成中依赖人工标注和后处理，限制了可访问性和可编辑性。方法：提出VecGlypher，一个单模态语言模型，生成高质量的矢量图形。创新点：实现矢量图形的自动生成，提高可访问性和可编辑性。实验结果：VecGlypher生成的矢量图形质量优于现有方法。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.21461v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.21461v1','VecGlypher: Unified Vector Glyph Generation with Language Models','http://arxiv.org/abs/2602.21461v1','http://arxiv.org/pdf/2602.21461v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.21461v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.21461v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.21461v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.21917v1"><div class="ch">
<span class="ci">53</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.21917v1" target="_blank">Scan Clusters, Not Pixels: A Cluster-Centric Paradigm for Efficient Ultra-high-definition Image Restoration</a></div>
<div class="sum-cn">研究问题：超高清图像修复面临计算效率问题。方法：提出一种基于状态空间模型（SSM）的UHD图像修复方法，降低计算复杂度。创新点：利用SSM实现线性复杂度，提高计算效率。实验结果：该方法在UHD图像修复任务中优于现有方法。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.21917v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.21917v1','Scan Clusters, Not Pixels: A Cluster-Centric Paradigm for Efficient Ultra-high-definition Image Restoration','http://arxiv.org/abs/2602.21917v1','http://arxiv.org/pdf/2602.21917v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.21917v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.21917v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.21917v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.21399v1"><div class="ch">
<span class="ci">54</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.21399v1" target="_blank">FedVG: Gradient-Guided Aggregation for Enhanced Federated Learning</a></div>
<div class="sum-cn">研究问题：联邦学习中的数据异质性导致模型泛化性能下降。方法：提出一种新的联邦学习算法，通过数据重采样和模型正则化来缓解数据异质性。创新点：结合数据重采样和模型正则化，提高模型泛化性能。实验结果：该方法在联邦学习任务中优于现有方法。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.21399v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.21399v1','FedVG: Gradient-Guided Aggregation for Enhanced Federated Learning','http://arxiv.org/abs/2602.21399v1','http://arxiv.org/pdf/2602.21399v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.21399v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.21399v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.21399v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.21395v1"><div class="ch">
<span class="ci">55</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.21395v1" target="_blank">Momentum Memory for Knowledge Distillation in Computational Pathology</a></div>
<div class="sum-cn">研究问题：基因组学和病理学多模态学习在癌症诊断中的应用受限于数据可用性。方法：提出一种基于知识蒸馏的方法，通过转移基因组信息来提高诊断性能。创新点：利用知识蒸馏技术，提高癌症诊断的准确性。实验结果：该方法在癌症诊断任务中优于现有方法。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.21395v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.21395v1','Momentum Memory for Knowledge Distillation in Computational Pathology','http://arxiv.org/abs/2602.21395v1','http://arxiv.org/pdf/2602.21395v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.21395v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.21395v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.21395v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.21172v2"><div class="ch">
<span class="ci">56</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.21172v2" target="_blank">NoRD: A Data-Efficient Vision-Language-Action Model that Drives without Reasoning</a></div>
<div class="sum-cn">研究问题：视觉语言动作（VLA）模型在自动驾驶中面临数据收集和标注成本高的问题。方法：提出一种新的VLA模型，通过数据增强和注意力机制来降低成本。创新点：实现数据增强和注意力机制，降低VLA模型的成本。实验结果：该方法在自动驾驶任务中优于现有方法。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.21172v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.21172v2','NoRD: A Data-Efficient Vision-Language-Action Model that Drives without Reasoning','http://arxiv.org/abs/2602.21172v2','http://arxiv.org/pdf/2602.21172v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.21172v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.21172v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.21172v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.21105v1"><div class="ch">
<span class="ci">57</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.21105v1" target="_blank">BrepGaussian: CAD reconstruction from Multi-View Images with Gaussian Splatting</a></div>
<div class="sum-cn">研究问题：从非结构化数据中恢复边界表示（B-rep）是一个具有挑战性的任务。方法：提出一种基于深度学习的B-rep恢复方法，提高恢复精度。创新点：利用深度学习技术，实现B-rep的高精度恢复。实验结果：该方法在B-rep恢复任务中优于现有方法。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.21105v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.21105v1','BrepGaussian: CAD reconstruction from Multi-View Images with Gaussian Splatting','http://arxiv.org/abs/2602.21105v1','http://arxiv.org/pdf/2602.21105v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.21105v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.21105v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.21105v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.21078v1"><div class="ch">
<span class="ci">58</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.21078v1" target="_blank">ProxyFL: A Proxy-Guided Framework for Federated Semi-Supervised Learning</a></div>
<div class="sum-cn">研究问题：联邦半监督学习（FSSL）中数据异质性导致模型性能下降。方法：提出一种新的FSSL算法，通过数据重采样和模型正则化来缓解数据异质性。创新点：结合数据重采样和模型正则化，提高FSSL模型的性能。实验结果：该方法在FSSL任务中优于现有方法。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.21078v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.21078v1','ProxyFL: A Proxy-Guided Framework for Federated Semi-Supervised Learning','http://arxiv.org/abs/2602.21078v1','http://arxiv.org/pdf/2602.21078v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.21078v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.21078v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.21078v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.22025v1"><div class="ch">
<span class="ci">59</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.22025v1" target="_blank">Olbedo: An Albedo and Shading Aerial Dataset for Large-Scale Outdoor Environments</a></div>
<div class="sum-cn">研究问题：户外场景的内在图像分解（IID）受限于缺乏可靠数据集。方法：提出Olbedo，一个大规模空中数据集，用于户外场景IID。创新点：构建Olbedo数据集，为IID研究提供可靠数据。实验结果：Olbedo数据集在IID任务中具有较高价值。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.22025v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.22025v1','Olbedo: An Albedo and Shading Aerial Dataset for Large-Scale Outdoor Environments','http://arxiv.org/abs/2602.22025v1','http://arxiv.org/pdf/2602.22025v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.22025v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.22025v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.22025v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.20989v1"><div class="ch">
<span class="ci">60</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.20989v1" target="_blank">Cycle-Consistent Tuning for Layered Image Decomposition</a></div>
<div class="sum-cn">研究问题：从真实图像中分离视觉层是一个具有挑战性的任务。方法：提出一种基于上下文的图像分解框架，实现视觉层的分离。创新点：利用上下文信息，提高视觉层分离的准确性。实验结果：该方法在图像分解任务中优于现有方法。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.20989v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.20989v1','Cycle-Consistent Tuning for Layered Image Decomposition','http://arxiv.org/abs/2602.20989v1','http://arxiv.org/pdf/2602.20989v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.20989v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.20989v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.20989v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.20985v1"><div class="ch">
<span class="ci">61</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.20985v1" target="_blank">EW-DETR: Evolving World Object Detection via Incremental Low-Rank DEtection TRansformer</a></div>
<div class="sum-cn">研究问题：在动态环境中进行无数据依赖的实时物体检测。方法：提出EWOD，结合增量学习和领域自适应。创新点：无需访问先验数据，适应新类别和领域变化。结果：有效识别未知物体。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.20985v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.20985v1','EW-DETR: Evolving World Object Detection via Incremental Low-Rank DEtection TRansformer','http://arxiv.org/abs/2602.20985v1','http://arxiv.org/pdf/2602.20985v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.20985v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.20985v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.20985v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.20981v2"><div class="ch">
<span class="ci">62</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.20981v2" target="_blank">Echoes Over Time: Unlocking Length Generalization in Video-to-Audio Generation Models</a></div>
<div class="sum-cn">研究问题：解决视频和音频多模态对齐的扩展性问题。方法：研究小数据集上模型训练的有效性。创新点：探索模型在小数据集上的性能。结果：提高多模态到音频生成的性能。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.20981v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.20981v2','Echoes Over Time: Unlocking Length Generalization in Video-to-Audio Generation Models','http://arxiv.org/abs/2602.20981v2','http://arxiv.org/pdf/2602.20981v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.20981v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.20981v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.20981v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.20933v1"><div class="ch">
<span class="ci">63</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.20933v1" target="_blank">Dropping Anchor and Spherical Harmonics for Sparse-view Gaussian Splatting</a></div>
<div class="sum-cn">研究问题：分析3D Gaussian Splatting Dropout方法中的邻域补偿效应。方法：识别并分析邻域补偿效应。创新点：揭示邻域补偿效应的存在。结果：改进3DGS Dropout方法。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.20933v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.20933v1','Dropping Anchor and Spherical Harmonics for Sparse-view Gaussian Splatting','http://arxiv.org/abs/2602.20933v1','http://arxiv.org/pdf/2602.20933v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.20933v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.20933v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.20933v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.20913v1"><div class="ch">
<span class="ci">64</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.20913v1" target="_blank">LongVideo-R1: Smart Navigation for Low-cost Long Video Understanding</a></div>
<div class="sum-cn">研究问题：在低计算预算下实现长视频理解。方法：提出LongVideo-R1，一个推理型多模态大语言模型。创新点：高效导航视频上下文，避免冗余。结果：提高长视频理解能力。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.20913v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.20913v1','LongVideo-R1: Smart Navigation for Low-cost Long Video Understanding','http://arxiv.org/abs/2602.20913v1','http://arxiv.org/pdf/2602.20913v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.20913v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.20913v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.20913v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.20903v3"><div class="ch">
<span class="ci">65</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.20903v3" target="_blank">TextPecker: Rewarding Structural Anomaly Quantification for Enhancing Visual Text Rendering</a></div>
<div class="sum-cn">研究问题：解决视觉文本渲染中的结构异常问题。方法：分析MLLM和OCR模型在感知文本结构异常方面的不足。创新点：揭示模型在感知结构异常方面的局限性。结果：改进视觉文本渲染质量。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.20903v3')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.20903v3','TextPecker: Rewarding Structural Anomaly Quantification for Enhancing Visual Text Rendering','http://arxiv.org/abs/2602.20903v3','http://arxiv.org/pdf/2602.20903v3')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.20903v3')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.20903v3" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.20903v3" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.20901v1"><div class="ch">
<span class="ci">66</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.20901v1" target="_blank">SpatiaLQA: A Benchmark for Evaluating Spatial Logical Reasoning in Vision-Language Models</a></div>
<div class="sum-cn">研究问题：提升视觉语言模型在复杂场景下的能力。方法：研究VLM在视觉问答和逻辑推理中的应用。创新点：探索VLM在复杂场景下的潜力。结果：提高VLM在复杂场景下的性能。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.20901v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.20901v1','SpatiaLQA: A Benchmark for Evaluating Spatial Logical Reasoning in Vision-Language Models','http://arxiv.org/abs/2602.20901v1','http://arxiv.org/pdf/2602.20901v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.20901v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.20901v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.20901v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.20880v2"><div class="ch">
<span class="ci">67</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.20880v2" target="_blank">When Safety Collides: Resolving Multi-Category Harmful Conflicts in Text-to-Image Diffusion via Adaptive Safety Guidance</a></div>
<div class="sum-cn">研究问题：解决文本到图像扩散模型中潜在的有害内容生成问题。方法：提出基于安全指导的方法。创新点：引导生成过程，避免有害内容。结果：降低有害内容生成的风险。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.20880v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.20880v2','When Safety Collides: Resolving Multi-Category Harmful Conflicts in Text-to-Image Diffusion via Adaptive Safety Guidance','http://arxiv.org/abs/2602.20880v2','http://arxiv.org/pdf/2602.20880v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.20880v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.20880v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.20880v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.20873v1"><div class="ch">
<span class="ci">68</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.20873v1" target="_blank">MUSE: Harnessing Precise and Diverse Semantics for Few-Shot Whole Slide Image Classification</a></div>
<div class="sum-cn">研究问题：解决计算病理学中少样本全切片图像分类问题。方法：结合视觉语言方法，将文本语义作为先验。创新点：将文本语义作为动态先验。结果：提高少样本分类性能。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.20873v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.20873v1','MUSE: Harnessing Precise and Diverse Semantics for Few-Shot Whole Slide Image Classification','http://arxiv.org/abs/2602.20873v1','http://arxiv.org/pdf/2602.20873v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.20873v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.20873v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.20873v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.20871v2"><div class="ch">
<span class="ci">69</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.20871v2" target="_blank">GeCo-SRT: Geometry-aware Continual Adaptation for Robotic Cross-Task Sim-to-Real Transfer</a></div>
<div class="sum-cn">研究问题：解决模拟数据到真实机器人系统迁移的sim-to-real差距问题。方法：提出跨域迁移方法。创新点：利用先前迁移经验，降低迁移成本。结果：提高模拟数据到真实系统的迁移效果。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.20871v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.20871v2','GeCo-SRT: Geometry-aware Continual Adaptation for Robotic Cross-Task Sim-to-Real Transfer','http://arxiv.org/abs/2602.20871v2','http://arxiv.org/pdf/2602.20871v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.20871v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.20871v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.20871v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.20794v1"><div class="ch">
<span class="ci">70</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.20794v1" target="_blank">VGGDrive: Empowering Vision-Language Models with Cross-View Geometric Grounding for Autonomous Driving</a></div>
<div class="sum-cn">研究问题：提升视觉语言模型在3D几何建模方面的能力。方法：研究VLM在3D几何建模中的应用。创新点：探索VLM在3D几何建模方面的潜力。结果：提高VLM在3D几何建模方面的性能。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.20794v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.20794v1','VGGDrive: Empowering Vision-Language Models with Cross-View Geometric Grounding for Autonomous Driving','http://arxiv.org/abs/2602.20794v1','http://arxiv.org/pdf/2602.20794v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.20794v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.20794v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.20794v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.20792v1"><div class="ch">
<span class="ci">71</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.20792v1" target="_blank">SIMSPINE: A Biomechanics-Aware Simulation Framework for 3D Spine Motion Annotation and Benchmarking</a></div>
<div class="sum-cn">研究问题：如何模拟脊柱运动，解决计算机视觉中脊柱复杂多关节运动学和缺乏大规模3D标注的问题。方法：提出一个生物力学感知的关键点模拟框架。创新点：结合生物力学知识进行关键点模拟。结果：提高了脊柱运动模拟的准确性。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.20792v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.20792v1','SIMSPINE: A Biomechanics-Aware Simulation Framework for 3D Spine Motion Annotation and Benchmarking','http://arxiv.org/abs/2602.20792v1','http://arxiv.org/pdf/2602.20792v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.20792v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.20792v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.20792v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.20689v1"><div class="ch">
<span class="ci">72</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.20689v1" target="_blank">MatchED: Crisp Edge Detection Using End-to-End, Matching-based Supervision</a></div>
<div class="sum-cn">研究问题：如何生成清晰的一像素宽边缘图，解决边缘检测中的基本挑战。方法：提出一种基于深度学习的边缘检测方法。创新点：结合NMS和边缘平滑算法。结果：提高了边缘检测的清晰度。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.20689v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.20689v1','MatchED: Crisp Edge Detection Using End-to-End, Matching-based Supervision','http://arxiv.org/abs/2602.20689v1','http://arxiv.org/pdf/2602.20689v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.20689v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.20689v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.20689v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.20685v2"><div class="ch">
<span class="ci">73</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.20685v2" target="_blank">RAYNOVA: Scale-Temporal Autoregressive World Modeling in Ray Space</a></div>
<div class="sum-cn">研究问题：如何模拟真实世界中的物理行为。方法：提出RAYNOVA，一种几何无关的多视图世界模型。创新点：采用双因果结构。结果：提高了驾驶场景模拟的准确性。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.20685v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.20685v2','RAYNOVA: Scale-Temporal Autoregressive World Modeling in Ray Space','http://arxiv.org/abs/2602.20685v2','http://arxiv.org/pdf/2602.20685v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.20685v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.20685v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.20685v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.20618v1"><div class="ch">
<span class="ci">74</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.20618v1" target="_blank">RecoverMark: Robust Watermarking for Localization and Recovery of Manipulated Faces</a></div>
<div class="sum-cn">研究问题：如何应对AI生成内容中的面部操纵问题。方法：利用脆弱水印进行检测、定位或恢复。创新点：提出一种基于脆弱水印的主动防御方法。结果：提高了知识产权保护的效果。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.20618v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.20618v1','RecoverMark: Robust Watermarking for Localization and Recovery of Manipulated Faces','http://arxiv.org/abs/2602.20618v1','http://arxiv.org/pdf/2602.20618v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.20618v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.20618v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.20618v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.20537v1"><div class="ch">
<span class="ci">75</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.20537v1" target="_blank">PFGNet: A Fully Convolutional Frequency-Guided Peripheral Gating Network for Efficient Spatiotemporal Predictive Learning</a></div>
<div class="sum-cn">研究问题：如何从过去观察中预测未来帧。方法：提出一种基于纯卷积模型的时空预测学习方法。创新点：提高效率并实现全并行。结果：提高了预测的准确性。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.20537v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.20537v1','PFGNet: A Fully Convolutional Frequency-Guided Peripheral Gating Network for Efficient Spatiotemporal Predictive Learning','http://arxiv.org/abs/2602.20537v1','http://arxiv.org/pdf/2602.20537v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.20537v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.20537v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.20537v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.20501v1"><div class="ch">
<span class="ci">76</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.20501v1" target="_blank">Probing and Bridging Geometry-Interaction Cues for Affordance Reasoning in Vision Foundation Models</a></div>
<div class="sum-cn">研究问题：如何理解视觉系统中的可及性。方法：提出几何感知和交互感知两种互补能力。创新点：从几何和交互两个角度理解可及性。结果：提高了对可及性的理解。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.20501v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.20501v1','Probing and Bridging Geometry-Interaction Cues for Affordance Reasoning in Vision Foundation Models','http://arxiv.org/abs/2602.20501v1','http://arxiv.org/pdf/2602.20501v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.20501v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.20501v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.20501v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.20496v1"><div class="ch">
<span class="ci">77</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.20496v1" target="_blank">Pip-Stereo: Progressive Iterations Pruner for Iterative Optimization based Stereo Matching</a></div>
<div class="sum-cn">研究问题：如何提高迭代立体匹配的准确性。方法：分析迭代细化过程，揭示差异更新具有空间稀疏性和时间冗余性。创新点：提出一种基于稀疏性和冗余性的迭代立体匹配方法。结果：提高了匹配的准确性。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.20496v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.20496v1','Pip-Stereo: Progressive Iterations Pruner for Iterative Optimization based Stereo Matching','http://arxiv.org/abs/2602.20496v1','http://arxiv.org/pdf/2602.20496v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.20496v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.20496v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.20496v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.21273v1"><div class="ch">
<span class="ci">78</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.21273v1" target="_blank">StoryTailor:A Zero-Shot Pipeline for Action-Rich Multi-Subject Visual Narratives</a></div>
<div class="sum-cn">研究问题：如何生成多帧、动作丰富的视觉叙事，同时保持动作文本、主体身份和背景连续性。方法：提出StoryTailor，一种零样本管道。创新点：在单个RTX 4090上运行。结果：提高了视觉叙事的生成质量。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.21273v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.21273v1','StoryTailor:A Zero-Shot Pipeline for Action-Rich Multi-Subject Visual Narratives','http://arxiv.org/abs/2602.21273v1','http://arxiv.org/pdf/2602.21273v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.21273v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.21273v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.21273v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.20423v1"><div class="ch">
<span class="ci">79</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.20423v1" target="_blank">MedCLIPSeg: Probabilistic Vision-Language Adaptation for Data-Efficient and Generalizable Medical Image Segmentation</a></div>
<div class="sum-cn">研究问题：如何进行医学图像分割。方法：利用CLIP等视觉语言模型进行密集文本引导的医学图像分割。创新点：提出一种基于CLIP的医学图像分割方法。结果：提高了医学图像分割的准确性。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.20423v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.20423v1','MedCLIPSeg: Probabilistic Vision-Language Adaptation for Data-Efficient and Generalizable Medical Image Segmentation','http://arxiv.org/abs/2602.20423v1','http://arxiv.org/pdf/2602.20423v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.20423v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.20423v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.20423v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.20417v1"><div class="ch">
<span class="ci">80</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.20417v1" target="_blank">gQIR: Generative Quanta Image Reconstruction</a></div>
<div class="sum-cn">研究问题：如何从少量检测到的光子中捕获高质量图像。方法：利用单光子雪崩二极管（SPAD）传感器。创新点：提出一种基于SPAD的图像重建方法。结果：提高了图像重建的准确性。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.20417v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.20417v1','gQIR: Generative Quanta Image Reconstruction','http://arxiv.org/abs/2602.20417v1','http://arxiv.org/pdf/2602.20417v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.20417v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.20417v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.20417v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.20412v1"><div class="ch">
<span class="ci">81</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.20412v1" target="_blank">SimLBR: Learning to Detect Fake Images by Learning to Detect Real Images</a></div>
<div class="sum-cn">研究问题：AI生成图像检测方法过拟合，导致在真实数据上性能下降。方法：提出改进的检测方法。创新点：针对过拟合问题，采用新的训练策略。结果：检测准确率显著提高。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.20412v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.20412v1','SimLBR: Learning to Detect Fake Images by Learning to Detect Real Images','http://arxiv.org/abs/2602.20412v1','http://arxiv.org/pdf/2602.20412v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.20412v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.20412v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.20412v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.20409v1"><div class="ch">
<span class="ci">82</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.20409v1" target="_blank">CLIPoint3D: Language-Grounded Few-Shot Unsupervised 3D Point Cloud Domain Adaptation</a></div>
<div class="sum-cn">研究问题：VLMs在领域迁移中脆弱，特别是从合成到真实点云。方法：提出3D领域自适应方法。创新点：结合合成和真实数据，提高模型鲁棒性。结果：模型在真实数据上表现良好。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.20409v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.20409v1','CLIPoint3D: Language-Grounded Few-Shot Unsupervised 3D Point Cloud Domain Adaptation','http://arxiv.org/abs/2602.20409v1','http://arxiv.org/pdf/2602.20409v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.20409v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.20409v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.20409v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.20330v1"><div class="ch">
<span class="ci">83</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.20330v1" target="_blank">Circuit Tracing in Vision-Language Models: Understanding the Internal Mechanisms of Multimodal Thinking</a></div>
<div class="sum-cn">研究问题：VLMs黑盒问题。方法：提出透明电路追踪框架。创新点：分析多模态推理过程。结果：揭示VLMs的推理机制。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.20330v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.20330v1','Circuit Tracing in Vision-Language Models: Understanding the Internal Mechanisms of Multimodal Thinking','http://arxiv.org/abs/2602.20330v1','http://arxiv.org/pdf/2602.20330v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.20330v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.20330v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.20330v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.20160v1"><div class="ch">
<span class="ci">84</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.20160v1" target="_blank">tttLRM: Test-Time Training for Long Context and Autoregressive 3D Reconstruction</a></div>
<div class="sum-cn">研究问题：3D重建模型计算复杂度高。方法：提出tttLRM模型。创新点：引入TTT层，实现线性复杂度。结果：模型在重建精度和效率上均有提升。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.20160v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.20160v1','tttLRM: Test-Time Training for Long Context and Autoregressive 3D Reconstruction','http://arxiv.org/abs/2602.20160v1','http://arxiv.org/pdf/2602.20160v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.20160v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.20160v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.20160v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.20157v1"><div class="ch">
<span class="ci">85</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.20157v1" target="_blank">Flow3r: Factored Flow Prediction for Scalable Visual Geometry Learning</a></div>
<div class="sum-cn">研究问题：3D/4D重建系统依赖密集几何和姿态监督。方法：提出Flow3r框架。创新点：结合2D对应关系作为监督信号。结果：提高重建精度和鲁棒性。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.20157v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.20157v1','Flow3r: Factored Flow Prediction for Scalable Visual Geometry Learning','http://arxiv.org/abs/2602.20157v1','http://arxiv.org/pdf/2602.20157v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.20157v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.20157v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.20157v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.20089v2"><div class="ch">
<span class="ci">86</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.20089v2" target="_blank">StruXLIP: Enhancing Vision-language Models with Multimodal Structural Cues</a></div>
<div class="sum-cn">研究问题：边缘表示在视觉理解中的重要性。方法：将边缘表示应用于视觉-语言对齐。创新点：跨模态结构对齐。结果：提高模型微调性能。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.20089v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.20089v2','StruXLIP: Enhancing Vision-language Models with Multimodal Structural Cues','http://arxiv.org/abs/2602.20089v2','http://arxiv.org/pdf/2602.20089v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.20089v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.20089v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.20089v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.20053v1"><div class="ch">
<span class="ci">87</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.20053v1" target="_blank">Decoupling Defense Strategies for Robust Image Watermarking</a></div>
<div class="sum-cn">研究问题：深度学习图像水印易受攻击。方法：提出改进的水印方法。创新点：优化编码器和解码器，提高鲁棒性。结果：水印对攻击更具抵抗力。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.20053v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.20053v1','Decoupling Defense Strategies for Robust Image Watermarking','http://arxiv.org/abs/2602.20053v1','http://arxiv.org/pdf/2602.20053v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.20053v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.20053v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.20053v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19944v1"><div class="ch">
<span class="ci">88</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19944v1" target="_blank">Discover, Segment, and Select: A Progressive Mechanism for Zero-shot Camouflaged Object Segmentation</a></div>
<div class="sum-cn">研究问题：Camouflaged Object Segmentation方法定位不准确。方法：改进两阶段管道。创新点：结合MLLMs和SAM分割。结果：提高定位精度。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19944v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19944v1','Discover, Segment, and Select: A Progressive Mechanism for Zero-shot Camouflaged Object Segmentation','http://arxiv.org/abs/2602.19944v1','http://arxiv.org/pdf/2602.19944v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19944v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19944v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19944v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19910v1"><div class="ch">
<span class="ci">89</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19910v1" target="_blank">Multi-Modal Representation Learning via Semi-Supervised Rate Reduction for Generalized Category Discovery</a></div>
<div class="sum-cn">研究问题：GCD任务中，已知类别标签不完整。方法：提出基于多模态表示学习的GCD方法。创新点：利用部分标签识别未知类别。结果：提高识别准确率。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19910v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19910v1','Multi-Modal Representation Learning via Semi-Supervised Rate Reduction for Generalized Category Discovery','http://arxiv.org/abs/2602.19910v1','http://arxiv.org/pdf/2602.19910v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19910v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19910v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19910v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19900v1"><div class="ch">
<span class="ci">90</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19900v1" target="_blank">ExpPortrait: Expressive Portrait Generation via Personalized Representation</a></div>
<div class="sum-cn">研究问题：扩散模型在生成电影肖像视频方面存在挑战。方法：提出改进的扩散模型。创新点：结合中间信号，提高生成视频质量。结果：生成视频更具表现力和可控性。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19900v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19900v1','ExpPortrait: Expressive Portrait Generation via Personalized Representation','http://arxiv.org/abs/2602.19900v1','http://arxiv.org/pdf/2602.19900v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19900v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19900v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19900v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19863v2"><div class="ch">
<span class="ci">91</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19863v2" target="_blank">Brewing Stronger Features: Dual-Teacher Distillation for Multispectral Earth Observation</a></div>
<div class="sum-cn">研究问题：地球观测（EO）中，多种传感器和模态的多样性使得单一通用模型不现实，如何实现不同模态间的高效知识迁移。方法：提出多种专业EO基础模型（EOFMs）。创新点：强调EOFMs间的知识迁移。结果：提高了不同模态间知识迁移的效率。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19863v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19863v2','Brewing Stronger Features: Dual-Teacher Distillation for Multispectral Earth Observation','http://arxiv.org/abs/2602.19863v2','http://arxiv.org/pdf/2602.19863v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19863v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19863v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19863v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.20223v2"><div class="ch">
<span class="ci">92</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.20223v2" target="_blank">MultiModalPFN: Extending Prior-Data Fitted Networks for Multimodal Tabular Learning</a></div>
<div class="sum-cn">研究问题：TabPFN作为表格数据基础模型存在难以整合异构模态（如图像和文本）的问题。方法：提出多模态融合方法。创新点：解决异构模态融合问题。结果：提高了TabPFN在多模态数据上的应用能力。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.20223v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.20223v2','MultiModalPFN: Extending Prior-Data Fitted Networks for Multimodal Tabular Learning','http://arxiv.org/abs/2602.20223v2','http://arxiv.org/pdf/2602.20223v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.20223v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.20223v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.20223v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19753v1"><div class="ch">
<span class="ci">93</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19753v1" target="_blank">RAP: Fast Feedforward Rendering-Free Attribute-Guided Primitive Importance Score Prediction for Efficient 3D Gaussian Splatting Processing</a></div>
<div class="sum-cn">研究问题：3D Gaussian Splatting（3DGS）在3D场景重建中存在大量原始元素，导致重建效果差异较大。方法：优化3DGS算法。创新点：减少原始元素数量，提高重建质量。结果：提高了3D场景重建的质量。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19753v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19753v1','RAP: Fast Feedforward Rendering-Free Attribute-Guided Primitive Importance Score Prediction for Efficient 3D Gaussian Splatting Processing','http://arxiv.org/abs/2602.19753v1','http://arxiv.org/pdf/2602.19753v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19753v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19753v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19753v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19715v1"><div class="ch">
<span class="ci">94</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19715v1" target="_blank">Pixels Don&#x27;t Lie (But Your Detector Might): Bootstrapping MLLM-as-a-Judge for Trustworthy Deepfake Detection and Reasoning Supervision</a></div>
<div class="sum-cn">研究问题：Deepfake检测模型生成的自然语言解释缺乏视觉证据支持，导致可靠性不足。方法：提出DeepfakeJudge框架。创新点：评估推理的可靠性。结果：提高了Deepfake检测模型的可靠性。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19715v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19715v1','Pixels Don&#x27;t Lie (But Your Detector Might): Bootstrapping MLLM-as-a-Judge for Trustworthy Deepfake Detection and Reasoning Supervision','http://arxiv.org/abs/2602.19715v1','http://arxiv.org/pdf/2602.19715v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19715v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19715v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19715v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19679v1"><div class="ch">
<span class="ci">95</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19679v1" target="_blank">TeHOR: Text-Guided 3D Human and Object Reconstruction with Textures</a></div>
<div class="sum-cn">研究问题：从单张图像中联合重建3D人类和物体存在重建依赖物理假设和缺乏深度信息的问题。方法：提出改进的重建方法。创新点：减少对物理假设的依赖，提高重建质量。结果：提高了3D重建的质量。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19679v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19679v1','TeHOR: Text-Guided 3D Human and Object Reconstruction with Textures','http://arxiv.org/abs/2602.19679v1','http://arxiv.org/pdf/2602.19679v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19679v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19679v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19679v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19615v1"><div class="ch">
<span class="ci">96</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19615v1" target="_blank">Seeing Clearly, Reasoning Confidently: Plug-and-Play Remedies for Vision Language Model Blindness</a></div>
<div class="sum-cn">研究问题：视觉语言模型（VLMs）在处理罕见物体时存在困难。方法：通过检索额外数据或改进训练方法。创新点：缓解罕见物体推理问题。结果：提高了VLMs在罕见物体上的推理能力。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19615v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19615v1','Seeing Clearly, Reasoning Confidently: Plug-and-Play Remedies for Vision Language Model Blindness','http://arxiv.org/abs/2602.19615v1','http://arxiv.org/pdf/2602.19615v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19615v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19615v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19615v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19611v1"><div class="ch">
<span class="ci">97</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19611v1" target="_blank">RAID: Retrieval-Augmented Anomaly Detection</a></div>
<div class="sum-cn">研究问题：无监督异常检测（UAD）方法在匹配测试图像和正常模板时存在挑战。方法：提出基于深度学习的UAD方法。创新点：提高匹配精度。结果：提高了UAD的检测精度。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19611v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19611v1','RAID: Retrieval-Augmented Anomaly Detection','http://arxiv.org/abs/2602.19611v1','http://arxiv.org/pdf/2602.19611v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19611v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19611v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19611v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19605v1"><div class="ch">
<span class="ci">98</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19605v1" target="_blank">CLCR: Cross-Level Semantic Collaborative Representation for Multimodal Learning</a></div>
<div class="sum-cn">研究问题：现有多模态学习方法忽视多模态数据的异步、多层次语义结构。方法：提出基于层次语义结构的多模态学习方法。创新点：考虑多模态数据的语义结构。结果：提高了多模态学习的性能。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19605v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19605v1','CLCR: Cross-Level Semantic Collaborative Representation for Multimodal Learning','http://arxiv.org/abs/2602.19605v1','http://arxiv.org/pdf/2602.19605v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19605v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19605v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19605v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19585v1"><div class="ch">
<span class="ci">99</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19585v1" target="_blank">Tri-Subspaces Disentanglement for Multimodal Sentiment Analysis</a></div>
<div class="sum-cn">研究问题：多模态情感分析（MSA）方法忽视某些模态对间的共享信号。方法：提出考虑模态对共享信号的方法。创新点：提高MSA的准确性。结果：提高了MSA的准确性。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19585v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19585v1','Tri-Subspaces Disentanglement for Multimodal Sentiment Analysis','http://arxiv.org/abs/2602.19585v1','http://arxiv.org/pdf/2602.19585v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19585v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19585v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19585v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19575v1"><div class="ch">
<span class="ci">100</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19575v1" target="_blank">ConceptPrism: Concept Disentanglement in Personalized Diffusion Models via Residual Token Optimization</a></div>
<div class="sum-cn">研究问题：个性化文本到图像生成存在概念纠缠问题。方法：提出基于解纠缠的方法。创新点：利用手动引导解决概念纠缠问题。结果：提高了文本到图像生成的质量。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19575v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19575v1','ConceptPrism: Concept Disentanglement in Personalized Diffusion Models via Residual Token Optimization','http://arxiv.org/abs/2602.19575v1','http://arxiv.org/pdf/2602.19575v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19575v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19575v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19575v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19542v1"><div class="ch">
<span class="ci">101</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19542v1" target="_blank">Vinedresser3D: Agentic Text-guided 3D Editing</a></div>
<div class="sum-cn">研究问题：3D编辑中理解复杂指令、自动定位编辑和保留未编辑内容的挑战。方法：提出Vinedresser3D，一个用于高质量文本引导的代理框架。创新点：联合理解复杂指令，自动定位编辑，并保留未编辑内容。结果：Vinedresser3D在3D编辑任务中表现出色。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19542v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19542v1','Vinedresser3D: Agentic Text-guided 3D Editing','http://arxiv.org/abs/2602.19542v1','http://arxiv.org/pdf/2602.19542v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19542v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19542v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19542v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.20208v1"><div class="ch">
<span class="ci">102</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.20208v1" target="_blank">Model Merging in the Essential Subspace</a></div>
<div class="sum-cn">研究问题：模型合并中任务干扰问题。方法：提出一种无需额外训练将多个任务特定微调模型集成到单一多任务模型中的方法。创新点：解决任务干扰问题，提高合并模型性能。结果：合并模型在多个任务上均表现出色。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.20208v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.20208v1','Model Merging in the Essential Subspace','http://arxiv.org/abs/2602.20208v1','http://arxiv.org/pdf/2602.20208v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.20208v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.20208v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.20208v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.20309v2"><div class="ch">
<span class="ci">103</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.20309v2" target="_blank">QuantVLA: Scale-Calibrated Post-Training Quantization for Vision-Language-Action Models</a></div>
<div class="sum-cn">研究问题：VLA模型在部署中计算和内存需求增加的挑战。方法：提出一种解决瓶颈问题的方法。创新点：降低计算和内存需求，提高模型部署效率。结果：模型在更长时间和更大骨干上表现良好。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.20309v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.20309v2','QuantVLA: Scale-Calibrated Post-Training Quantization for Vision-Language-Action Models','http://arxiv.org/abs/2602.20309v2','http://arxiv.org/pdf/2602.20309v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.20309v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.20309v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.20309v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19870v1"><div class="ch">
<span class="ci">104</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19870v1" target="_blank">ApET: Approximation-Error Guided Token Compression for Efficient VLMs</a></div>
<div class="sum-cn">研究问题：VLMs中冗余视觉标记导致的计算开销和推理效率下降问题。方法：提出一种基于[CLS]注意力或文本-视觉交叉注意力的方法。创新点：减少冗余视觉标记，提高推理效率。结果：模型在多模态理解能力上表现出色。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19870v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19870v1','ApET: Approximation-Error Guided Token Compression for Efficient VLMs','http://arxiv.org/abs/2602.19870v1','http://arxiv.org/pdf/2602.19870v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19870v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19870v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19870v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19516v1"><div class="ch">
<span class="ci">105</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19516v1" target="_blank">Pixel2Phys: Distilling Governing Laws from Visual Dynamics</a></div>
<div class="sum-cn">研究问题：从高维视觉数据中发现物理定律的挑战。方法：提出一种解决这一问题的方法。创新点：利用低维物理知识解决高维视觉数据中的问题。结果：在科学智能领域取得突破。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19516v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19516v1','Pixel2Phys: Distilling Governing Laws from Visual Dynamics','http://arxiv.org/abs/2602.19516v1','http://arxiv.org/pdf/2602.19516v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19516v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19516v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19516v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19497v1"><div class="ch">
<span class="ci">106</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19497v1" target="_blank">MICON-Bench: Benchmarking and Enhancing Multi-Image Context Image Generation in Unified Multimodal Models</a></div>
<div class="sum-cn">研究问题：UMMs在多图像推理上的挑战。方法：提出一种解决这一问题的方法。创新点：提高UMMs在多图像推理上的能力。结果：模型在多图像推理任务上表现出色。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19497v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19497v1','MICON-Bench: Benchmarking and Enhancing Multi-Image Context Image Generation in Unified Multimodal Models','http://arxiv.org/abs/2602.19497v1','http://arxiv.org/pdf/2602.19497v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19497v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19497v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19497v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19449v1"><div class="ch">
<span class="ci">107</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19449v1" target="_blank">Decoupling Vision and Language: Codebook Anchored Visual Adaptation</a></div>
<div class="sum-cn">研究问题：LVLMs在特定视觉任务中的性能问题。方法：提出一种改进视觉编码器的方法。创新点：提高LVLMs在特定视觉任务中的性能。结果：模型在医学图像诊断和细粒度分类任务上表现出色。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19449v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19449v1','Decoupling Vision and Language: Codebook Anchored Visual Adaptation','http://arxiv.org/abs/2602.19449v1','http://arxiv.org/pdf/2602.19449v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19449v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19449v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19449v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19596v1"><div class="ch">
<span class="ci">108</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19596v1" target="_blank">Learning Mutual View Information Graph for Adaptive Adversarial Collaborative Perception</a></div>
<div class="sum-cn">研究问题：CP系统易受对抗攻击的挑战。方法：提出一种基于特征级扰动的防御系统。创新点：提高CP系统的安全性。结果：防御系统在对抗攻击中表现出色。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19596v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19596v1','Learning Mutual View Information Graph for Adaptive Adversarial Collaborative Perception','http://arxiv.org/abs/2602.19596v1','http://arxiv.org/pdf/2602.19596v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19596v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19596v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19596v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.20328v1"><div class="ch">
<span class="ci">109</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.20328v1" target="_blank">GSNR: Graph Smooth Null-Space Representation for Inverse Problems</a></div>
<div class="sum-cn">研究问题：成像中逆问题求解的挑战。方法：提出一种基于图像先验的方法。创新点：提高逆问题求解的准确性。结果：在图像重建任务中取得突破。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.20328v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.20328v1','GSNR: Graph Smooth Null-Space Representation for Inverse Problems','http://arxiv.org/abs/2602.20328v1','http://arxiv.org/pdf/2602.20328v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.20328v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.20328v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.20328v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19285v1"><div class="ch">
<span class="ci">110</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19285v1" target="_blank">MRI Contrast Enhancement Kinetics World Model</a></div>
<div class="sum-cn">研究问题：临床MRI对比度采集效率低下的问题。方法：提出一种基于世界模型的方法。创新点：提高临床MRI对比度采集效率。结果：在临床MRI对比度采集中取得突破。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19285v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19285v1','MRI Contrast Enhancement Kinetics World Model','http://arxiv.org/abs/2602.19285v1','http://arxiv.org/pdf/2602.19285v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19285v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19285v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19285v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19248v1"><div class="ch">
<span class="ci">111</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19248v1" target="_blank">No Need For Real Anomaly: MLLM Empowered Zero-Shot Video Anomaly Detection</a></div>
<div class="sum-cn">研究问题：视频异常检测在开放场景下的性能不足，原因包括数据集多样性有限和时空稀缺性。方法：提出了一种新的视频异常检测方法。创新点：通过引入数据增强和改进的模型结构来提高检测性能。结果：在多个数据集上实现了显著的性能提升。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19248v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19248v1','No Need For Real Anomaly: MLLM Empowered Zero-Shot Video Anomaly Detection','http://arxiv.org/abs/2602.19248v1','http://arxiv.org/pdf/2602.19248v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19248v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19248v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19248v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19206v2"><div class="ch">
<span class="ci">112</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19206v2" target="_blank">GS-CLIP: Zero-shot 3D Anomaly Detection by Geometry-Aware Prompt and Synergistic View Representation Learning</a></div>
<div class="sum-cn">研究问题：零样本3D异常检测在样本稀缺和数据隐私受限场景下的挑战。方法：通过将CLIP模型应用于3D点云投影。创新点：提出了一种新的3D异常检测方法，无需目标训练数据。结果：在多个数据集上取得了较好的性能。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19206v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19206v2','GS-CLIP: Zero-shot 3D Anomaly Detection by Geometry-Aware Prompt and Synergistic View Representation Learning','http://arxiv.org/abs/2602.19206v2','http://arxiv.org/pdf/2602.19206v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19206v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19206v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19206v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19180v1"><div class="ch">
<span class="ci">113</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19180v1" target="_blank">VLM-Guided Group Preference Alignment for Diffusion-based Human Mesh Recovery</a></div>
<div class="sum-cn">研究问题：从单张RGB图像中恢复人体网格的模糊性。方法：采用基于扩散的方法生成多种假设。创新点：提出了一种新的方法，在保持准确性的同时生成合理的预测。结果：在多个数据集上取得了较好的性能。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19180v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19180v1','VLM-Guided Group Preference Alignment for Diffusion-based Human Mesh Recovery','http://arxiv.org/abs/2602.19180v1','http://arxiv.org/pdf/2602.19180v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19180v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19180v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19180v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19170v1"><div class="ch">
<span class="ci">114</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19170v1" target="_blank">BriMA: Bridged Modality Adaptation for Multi-Modal Continual Action Quality Assessment</a></div>
<div class="sum-cn">研究问题：动作质量评估在多模态融合中的挑战。方法：利用视觉和运动学线索进行多模态融合。创新点：提出了一种新的多模态融合方法，提高了评估的准确性。结果：在多个数据集上取得了显著的性能提升。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19170v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19170v1','BriMA: Bridged Modality Adaptation for Multi-Modal Continual Action Quality Assessment','http://arxiv.org/abs/2602.19170v1','http://arxiv.org/pdf/2602.19170v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19170v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19170v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19170v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19140v1"><div class="ch">
<span class="ci">115</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19140v1" target="_blank">CaReFlow: Cyclic Adaptive Rectified Flow for Multimodal Fusion</a></div>
<div class="sum-cn">研究问题：模态差距限制了多模态融合的有效性。方法：采用扩散模型和对抗学习技术。创新点：提出了一种新的方法，同时关注一对一对齐和源模态数据点的暴露。结果：在多个数据集上实现了更好的融合效果。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19140v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19140v1','CaReFlow: Cyclic Adaptive Rectified Flow for Multimodal Fusion','http://arxiv.org/abs/2602.19140v1','http://arxiv.org/pdf/2602.19140v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19140v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19140v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19140v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19112v2"><div class="ch">
<span class="ci">116</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19112v2" target="_blank">Universal 3D Shape Matching via Coarse-to-Fine Language Guidance</a></div>
<div class="sum-cn">研究问题：形状之间建立密集对应关系。方法：基于近等距假设和同质主题类型。创新点：提出了一种新的方法，适用于跨类别对象。结果：在多个数据集上取得了较好的性能。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19112v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19112v2','Universal 3D Shape Matching via Coarse-to-Fine Language Guidance','http://arxiv.org/abs/2602.19112v2','http://arxiv.org/pdf/2602.19112v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19112v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19112v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19112v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19096v1"><div class="ch">
<span class="ci">117</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19096v1" target="_blank">The Power of Decaying Steps: Enhancing Attack Stability and Transferability for Sign-based Optimizers</a></div>
<div class="sum-cn">研究问题：对抗样本生成作为优化问题。方法：采用基于符号的优化器。创新点：提出了一种新的方法，解决了理论基础和实践可靠性问题。结果：在多个数据集上取得了较好的性能。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19096v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19096v1','The Power of Decaying Steps: Enhancing Attack Stability and Transferability for Sign-based Optimizers','http://arxiv.org/abs/2602.19096v1','http://arxiv.org/pdf/2602.19096v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19096v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19096v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19096v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19089v1"><div class="ch">
<span class="ci">118</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19089v1" target="_blank">Ani3DHuman: Photorealistic 3D Human Animation with Self-guided Stochastic Sampling</a></div>
<div class="sum-cn">研究问题：3D人体动画方法难以实现逼真效果。方法：结合动力学和视频扩散先验。创新点：提出了一种新的方法，克服了质量伪影和身份损失问题。结果：在多个数据集上取得了较好的性能。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19089v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19089v1','Ani3DHuman: Photorealistic 3D Human Animation with Self-guided Stochastic Sampling','http://arxiv.org/abs/2602.19089v1','http://arxiv.org/pdf/2602.19089v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19089v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19089v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19089v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19083v1"><div class="ch">
<span class="ci">119</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19083v1" target="_blank">ChordEdit: One-Step Low-Energy Transport for Image Editing</a></div>
<div class="sum-cn">研究问题：一步式文本到图像（T2I）模型在文本引导图像编辑中的应用受限。方法：改进现有训练无编辑器。创新点：提出了一种新的方法，提高了编辑速度和准确性。结果：在多个数据集上取得了较好的性能。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19083v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19083v1','ChordEdit: One-Step Low-Energy Transport for Image Editing','http://arxiv.org/abs/2602.19083v1','http://arxiv.org/pdf/2602.19083v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19083v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19083v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19083v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19064v1"><div class="ch">
<span class="ci">120</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19064v1" target="_blank">L3DR: 3D-aware LiDAR Diffusion and Rectification</a></div>
<div class="sum-cn">研究问题：基于范围视图（RV）的LiDAR扩散在2D照片真实感方面取得了巨大进展。方法：设计了一种3D感知的LiDAR扩散和校正框架。创新点：提出了一种新的方法，提高了3D几何真实感和减少了RV伪影。结果：在多个数据集上取得了较好的性能。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19064v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19064v1','L3DR: 3D-aware LiDAR Diffusion and Rectification','http://arxiv.org/abs/2602.19064v1','http://arxiv.org/pdf/2602.19064v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19064v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19064v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19064v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19063v1"><div class="ch">
<span class="ci">121</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19063v1" target="_blank">Direction-aware 3D Large Multimodal Models</a></div>
<div class="sum-cn">研究问题：3D LMMs在缺乏ego poses的情况下难以进行方向问答和空间推理。方法：构建包含ego poses的点云基准。创新点：提出包含ego poses的点云基准。结果：提高了3D LMMs的性能。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19063v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19063v1','Direction-aware 3D Large Multimodal Models','http://arxiv.org/abs/2602.19063v1','http://arxiv.org/pdf/2602.19063v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19063v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19063v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19063v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19053v1"><div class="ch">
<span class="ci">122</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19053v1" target="_blank">TeFlow: Enabling Multi-frame Supervision for Self-Supervised Feed-forward Scene Flow Estimation</a></div>
<div class="sum-cn">研究问题：自监督场景流估计方法在遮挡情况下可靠性差。方法：引入多帧监督。创新点：多帧监督提高稳定性。结果：提高了场景流估计的可靠性。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19053v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19053v1','TeFlow: Enabling Multi-frame Supervision for Self-Supervised Feed-forward Scene Flow Estimation','http://arxiv.org/abs/2602.19053v1','http://arxiv.org/pdf/2602.19053v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19053v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19053v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19053v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19035v1"><div class="ch">
<span class="ci">123</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19035v1" target="_blank">OpenVO: Open-World Visual Odometry with Temporal Dynamics Awareness</a></div>
<div class="sum-cn">研究问题：在有限输入条件下，如何进行Open-world Visual Odometry。方法：提出OpenVO框架。创新点：有效估计真实尺度ego-motion。结果：提高了OpenVO的鲁棒性。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19035v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19035v1','OpenVO: Open-World Visual Odometry with Temporal Dynamics Awareness','http://arxiv.org/abs/2602.19035v1','http://arxiv.org/pdf/2602.19035v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19035v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19035v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19035v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19024v1"><div class="ch">
<span class="ci">124</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19024v1" target="_blank">Towards Calibrating Prompt Tuning of Vision-Language Models</a></div>
<div class="sum-cn">研究问题：Prompt tuning大视觉语言模型时，如何提高置信度校准和预测不确定性。方法：提出校准框架。创新点：增强置信度校准和预测不确定性。结果：提高了模型性能。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19024v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19024v1','Towards Calibrating Prompt Tuning of Vision-Language Models','http://arxiv.org/abs/2602.19024v1','http://arxiv.org/pdf/2602.19024v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19024v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19024v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19024v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.18996v1"><div class="ch">
<span class="ci">125</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.18996v1" target="_blank">Learning Cross-View Object Correspondence via Cycle-Consistent Mask Prediction</a></div>
<div class="sum-cn">研究问题：在视频中进行不同视角下的物体级视觉对应。方法：提出基于条件二值分割的框架。创新点：简单有效的对应方法。结果：提高了对应精度。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.18996v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.18996v1','Learning Cross-View Object Correspondence via Cycle-Consistent Mask Prediction','http://arxiv.org/abs/2602.18996v1','http://arxiv.org/pdf/2602.18996v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.18996v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.18996v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.18996v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.18993v1"><div class="ch">
<span class="ci">126</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.18993v1" target="_blank">SeaCache: Spectral-Evolution-Aware Cache for Accelerating Diffusion Models</a></div>
<div class="sum-cn">研究问题：加速扩散模型采样。方法：基于特征距离缓存和重用中间输出。创新点：改进缓存策略。结果：提高了采样速度。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.18993v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.18993v1','SeaCache: Spectral-Evolution-Aware Cache for Accelerating Diffusion Models','http://arxiv.org/abs/2602.18993v1','http://arxiv.org/pdf/2602.18993v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.18993v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.18993v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.18993v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.20205v2"><div class="ch">
<span class="ci">127</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.20205v2" target="_blank">OTPrune: Distribution-Aligned Visual Token Pruning via Optimal Transport</a></div>
<div class="sum-cn">研究问题：降低多模态大语言模型的推理成本。方法：提出视觉token剪枝。创新点：考虑分布结构。结果：降低了推理成本。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.20205v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.20205v2','OTPrune: Distribution-Aligned Visual Token Pruning via Optimal Transport','http://arxiv.org/abs/2602.20205v2','http://arxiv.org/pdf/2602.20205v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.20205v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.20205v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.20205v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.19004v1"><div class="ch">
<span class="ci">128</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.19004v1" target="_blank">MoBind: Motion Binding for Fine-Grained IMU-Video Pose Alignment</a></div>
<div class="sum-cn">研究问题：学习IMU信号和2D姿态序列的联合表示。方法：提出MoBind框架。创新点：实现跨模态检索和动作识别。结果：提高了跨模态检索和动作识别的准确性。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.19004v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.19004v1','MoBind: Motion Binding for Fine-Grained IMU-Video Pose Alignment','http://arxiv.org/abs/2602.19004v1','http://arxiv.org/pdf/2602.19004v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.19004v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.19004v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.19004v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.18977v1"><div class="ch">
<span class="ci">129</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.18977v1" target="_blank">Frame2Freq: Spectral Adapters for Fine-Grained Video Understanding</a></div>
<div class="sum-cn">研究问题：将图像预训练的backbones应用于视频。方法：提出多时间尺度适配器。创新点：捕捉多时间尺度动态。结果：提高了视频处理性能。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.18977v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.18977v1','Frame2Freq: Spectral Adapters for Fine-Grained Video Understanding','http://arxiv.org/abs/2602.18977v1','http://arxiv.org/pdf/2602.18977v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.18977v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.18977v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.18977v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.18887v1"><div class="ch">
<span class="ci">130</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.18887v1" target="_blank">SafeDrive: Fine-Grained Safety Reasoning for End-to-End Driving in a Sparse World</a></div>
<div class="sum-cn">研究问题：确保端到端驾驶决策框架的安全性。方法：提出安全保证方法。创新点：提高安全性。结果：提高了驾驶决策框架的安全性。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.18887v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.18887v1','SafeDrive: Fine-Grained Safety Reasoning for End-to-End Driving in a Sparse World','http://arxiv.org/abs/2602.18887v1','http://arxiv.org/pdf/2602.18887v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.18887v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.18887v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.18887v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.18873v1"><div class="ch">
<span class="ci">131</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.18873v1" target="_blank">BiMotion: B-spline Motion for Text-guided Dynamic 3D Character Generation</a></div>
<div class="sum-cn">研究问题：如何生成高质量、符合丰富文本描述的运动。方法：提出动态3D角色生成方法，解决固定长度时间输入和离散帧的问题。创新点：动态调整动作序列，实现连贯运动。结果：生成运动更符合文本描述，质量更高。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.18873v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.18873v1','BiMotion: B-spline Motion for Text-guided Dynamic 3D Character Generation','http://arxiv.org/abs/2602.18873v1','http://arxiv.org/pdf/2602.18873v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.18873v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.18873v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.18873v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.18867v1"><div class="ch">
<span class="ci">132</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.18867v1" target="_blank">Similarity-as-Evidence: Calibrating Overconfident VLMs for Interpretable and Label-Efficient Medical Active Learning</a></div>
<div class="sum-cn">研究问题：如何解决医学图像标注中的冷启动问题。方法：结合主动学习和视觉语言模型，实现零样本预测。创新点：利用未标记数据提高标注效率。结果：降低标注成本，提高标注质量。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.18867v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.18867v1','Similarity-as-Evidence: Calibrating Overconfident VLMs for Interpretable and Label-Efficient Medical Active Learning','http://arxiv.org/abs/2602.18867v1','http://arxiv.org/pdf/2602.18867v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.18867v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.18867v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.18867v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.18863v1"><div class="ch">
<span class="ci">133</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.18863v1" target="_blank">TIACam: Text-Anchored Invariant Feature Learning with Auto-Augmentation for Camera-Robust Zero-Watermarking</a></div>
<div class="sum-cn">研究问题：如何提高相机鲁棒性。方法：提出TIACam，结合文本锚定和自动增强。创新点：学习相机鲁棒性特征。结果：提高水印系统对光学退化鲁棒性。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.18863v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.18863v1','TIACam: Text-Anchored Invariant Feature Learning with Auto-Augmentation for Camera-Robust Zero-Watermarking','http://arxiv.org/abs/2602.18863v1','http://arxiv.org/pdf/2602.18863v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.18863v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.18863v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.18863v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.18858v2"><div class="ch">
<span class="ci">134</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.18858v2" target="_blank">Hyperbolic Busemann Neural Networks</a></div>
<div class="sum-cn">研究问题：如何利用双曲空间表示树状结构数据。方法：提出在双曲空间中操作的神经网络组件。创新点：实现高效的双曲空间计算。结果：提高神经网络在双曲空间中的性能。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.18858v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.18858v2','Hyperbolic Busemann Neural Networks','http://arxiv.org/abs/2602.18858v2','http://arxiv.org/pdf/2602.18858v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.18858v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.18858v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.18858v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.18846v1"><div class="ch">
<span class="ci">135</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.18846v1" target="_blank">DUET-VLM: Dual stage Unified Efficient Token reduction for VLM Training and Inference</a></div>
<div class="sum-cn">研究问题：如何提高视觉语言模型的效率。方法：提出稀疏视觉token化方法。创新点：降低视觉token化密度。结果：提高模型推理速度，降低计算成本。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.18846v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.18846v1','DUET-VLM: Dual stage Unified Efficient Token reduction for VLM Training and Inference','http://arxiv.org/abs/2602.18846v1','http://arxiv.org/pdf/2602.18846v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.18846v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.18846v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.18846v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.18845v1"><div class="ch">
<span class="ci">136</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.18845v1" target="_blank">Echoes of Ownership: Adversarial-Guided Dual Injection for Copyright Protection in MLLMs</a></div>
<div class="sum-cn">研究问题：如何解决多模态大型语言模型版本归属和所有权问题。方法：提出版本归属和所有权框架。创新点：实现模型版本追踪。结果：提高知识产权保护水平。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.18845v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.18845v1','Echoes of Ownership: Adversarial-Guided Dual Injection for Copyright Protection in MLLMs','http://arxiv.org/abs/2602.18845v1','http://arxiv.org/pdf/2602.18845v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.18845v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.18845v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.18845v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.18842v1"><div class="ch">
<span class="ci">137</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.18842v1" target="_blank">Detecting AI-Generated Forgeries via Iterative Manifold Deviation Amplification</a></div>
<div class="sum-cn">研究问题：如何定位AI生成图像中的篡改区域。方法：学习特定伪造的判别模式。创新点：提高对新型篡改的识别能力。结果：实现精确的像素级定位。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.18842v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.18842v1','Detecting AI-Generated Forgeries via Iterative Manifold Deviation Amplification','http://arxiv.org/abs/2602.18842v1','http://arxiv.org/pdf/2602.18842v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.18842v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.18842v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.18842v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.18831v1"><div class="ch">
<span class="ci">138</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.18831v1" target="_blank">IDperturb: Enhancing Variation in Synthetic Face Generation via Angular Perturbation</a></div>
<div class="sum-cn">研究问题：如何利用合成数据训练人脸识别系统。方法：提出基于身份条件的扩散模型。创新点：生成具有特定身份的人脸图像。结果：提高人脸识别系统的性能。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.18831v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.18831v1','IDperturb: Enhancing Variation in Synthetic Face Generation via Angular Perturbation','http://arxiv.org/abs/2602.18831v1','http://arxiv.org/pdf/2602.18831v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.18831v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.18831v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.18831v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.18811v1"><div class="ch">
<span class="ci">139</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.18811v1" target="_blank">Learning Multi-Modal Prototypes for Cross-Domain Few-Shot Object Detection</a></div>
<div class="sum-cn">研究问题：如何实现跨域少量样本目标检测。方法：结合视觉语言模型和文本提示。创新点：提高模型对未知领域的适应性。结果：提高跨域目标检测性能。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.18811v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.18811v1','Learning Multi-Modal Prototypes for Cross-Domain Few-Shot Object Detection','http://arxiv.org/abs/2602.18811v1','http://arxiv.org/pdf/2602.18811v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.18811v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.18811v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.18811v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.18853v1"><div class="ch">
<span class="ci">140</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.18853v1" target="_blank">Open-Vocabulary Domain Generalization in Urban-Scene Segmentation</a></div>
<div class="sum-cn">研究问题：如何提高语义分割模型在未知环境中的鲁棒性。方法：提出开放世界场景下的域泛化方法。创新点：扩展已知类别范围。结果：提高模型在未知环境中的性能。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.18853v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.18853v1','Open-Vocabulary Domain Generalization in Urban-Scene Segmentation','http://arxiv.org/abs/2602.18853v1','http://arxiv.org/pdf/2602.18853v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.18853v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.18853v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.18853v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.18792v1"><div class="ch">
<span class="ci">141</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.18792v1" target="_blank">MaskDiME: Adaptive Masked Diffusion for Precise and Efficient Visual Counterfactual Explanations</a></div>
<div class="sum-cn">研究问题：现有基于扩散的对抗生成方法计算成本高。方法：提出一种新的视觉对抗解释方法。创新点：降低计算成本，提供因果和可解释的洞察。结果：有效揭示模型预测的微小语义修改。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.18792v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.18792v1','MaskDiME: Adaptive Masked Diffusion for Precise and Efficient Visual Counterfactual Explanations','http://arxiv.org/abs/2602.18792v1','http://arxiv.org/pdf/2602.18792v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.18792v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.18792v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.18792v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.18735v1"><div class="ch">
<span class="ci">142</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.18735v1" target="_blank">LaS-Comp: Zero-shot 3D Completion with Latent-Spatial Consistency</a></div>
<div class="sum-cn">研究问题：3D形状补全在多种类型的不完整观察中存在挑战。方法：引入LaS-Comp，利用3D基础模型的几何先验。创新点：零样本和类别无关，实现跨类型补全。结果：提高3D形状补全的准确性。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.18735v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.18735v1','LaS-Comp: Zero-shot 3D Completion with Latent-Spatial Consistency','http://arxiv.org/abs/2602.18735v1','http://arxiv.org/pdf/2602.18735v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.18735v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.18735v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.18735v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.16412v2"><div class="ch">
<span class="ci">143</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.16412v2" target="_blank">ReMoRa: Multimodal Large Language Model based on Refined Motion Representation for Long-Video Understanding</a></div>
<div class="sum-cn">研究问题：长视频理解是MLLMs的挑战。方法：关注MLLMs的视频理解。创新点：处理RGB帧流，实现视频理解。结果：提高视频理解性能。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.16412v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.16412v2','ReMoRa: Multimodal Large Language Model based on Refined Motion Representation for Long-Video Understanding','http://arxiv.org/abs/2602.16412v2','http://arxiv.org/pdf/2602.16412v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.16412v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.16412v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.16412v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2602.05449v2"><div class="ch">
<span class="ci">144</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2602.05449v2" target="_blank">DisCa: Accelerating Video Diffusion Transformers with Distillation-Compatible Learnable Feature Caching</a></div>
<div class="sum-cn">研究问题：扩散模型计算负担重。方法：采用特征缓存加速。创新点：无需训练，显著提高速度。结果：降低视频生成计算成本。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2602.05449v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2602.05449v2','DisCa: Accelerating Video Diffusion Transformers with Distillation-Compatible Learnable Feature Caching','http://arxiv.org/abs/2602.05449v2','http://arxiv.org/pdf/2602.05449v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2602.05449v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2602.05449v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2602.05449v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2601.16788v1"><div class="ch">
<span class="ci">145</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2601.16788v1" target="_blank">REL-SF4PASS: Panoramic Semantic Segmentation with REL Depth Representation and Spherical Fusion</a></div>
<div class="sum-cn">研究问题：全景语义分割方法存在局限性。方法：提出基于球面几何和深度信息的PASS方法。创新点：提高场景感知能力。结果：实现更精确的全景语义分割。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2601.16788v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2601.16788v1','REL-SF4PASS: Panoramic Semantic Segmentation with REL Depth Representation and Spherical Fusion','http://arxiv.org/abs/2601.16788v1','http://arxiv.org/pdf/2601.16788v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2601.16788v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2601.16788v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2601.16788v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2601.16672v1"><div class="ch">
<span class="ci">146</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2601.16672v1" target="_blank">ReWeaver: Towards Simulation-Ready and Topology-Accurate Garment Reconstruction</a></div>
<div class="sum-cn">研究问题：3D服装重建方法依赖非结构化表示。方法：提出基于3D Gaussian Splats的服装重建方法。创新点：提高重建质量。结果：实现高质量的3D服装重建。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2601.16672v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2601.16672v1','ReWeaver: Towards Simulation-Ready and Topology-Accurate Garment Reconstruction','http://arxiv.org/abs/2601.16672v1','http://arxiv.org/pdf/2601.16672v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2601.16672v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2601.16672v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2601.16672v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2601.13401v1"><div class="ch">
<span class="ci">147</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2601.13401v1" target="_blank">Reasoning with Pixel-level Precision: QVLM Architecture and SQuID Dataset for Quantitative Geospatial Analytics</a></div>
<div class="sum-cn">研究问题：VLMs在定量空间推理方面表现不佳。方法：改进VLMs架构，保留像素级信息。创新点：提高计数和测量的准确性。结果：增强VLMs的定量空间推理能力。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2601.13401v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2601.13401v1','Reasoning with Pixel-level Precision: QVLM Architecture and SQuID Dataset for Quantitative Geospatial Analytics','http://arxiv.org/abs/2601.13401v1','http://arxiv.org/pdf/2601.13401v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2601.13401v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2601.13401v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2601.13401v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2601.09823v2"><div class="ch">
<span class="ci">148</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2601.09823v2" target="_blank">NanoSD: Edge Efficient Foundation Model for Real Time Image Restoration</a></div>
<div class="sum-cn">研究问题：Latent扩散模型在边缘设备上部署困难。方法：提出轻量级变体。创新点：降低计算成本，提高部署效率。结果：实现Latent扩散模型在边缘设备上的高效应用。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2601.09823v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2601.09823v2','NanoSD: Edge Efficient Foundation Model for Real Time Image Restoration','http://arxiv.org/abs/2601.09823v2','http://arxiv.org/pdf/2601.09823v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2601.09823v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2601.09823v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2601.09823v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2601.09708v2"><div class="ch">
<span class="ci">149</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2601.09708v2" target="_blank">Fast-ThinkAct: Efficient Vision-Language-Action Reasoning via Verbalizable Latent Planning</a></div>
<div class="sum-cn">研究问题：VLA推理存在延迟问题。方法：引入Object-WIPER框架。创新点：去除动态对象，实现视频修复。结果：提高VLA推理的效率和准确性。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2601.09708v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2601.09708v2','Fast-ThinkAct: Efficient Vision-Language-Action Reasoning via Verbalizable Latent Planning','http://arxiv.org/abs/2601.09708v2','http://arxiv.org/pdf/2601.09708v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2601.09708v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2601.09708v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2601.09708v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2601.06391v2"><div class="ch">
<span class="ci">150</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2601.06391v2" target="_blank">Object-WIPER : Training-Free Object and Associated Effect Removal in Videos</a></div>
<div class="sum-cn">研究问题：动态视频处理存在挑战。方法：提出Object-WIPER框架。创新点：去除动态对象，实现视频修复。结果：提高视频处理效率和视觉效果。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2601.06391v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2601.06391v2','Object-WIPER : Training-Free Object and Associated Effect Removal in Videos','http://arxiv.org/abs/2601.06391v2','http://arxiv.org/pdf/2601.06391v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2601.06391v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2601.06391v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2601.06391v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2601.01695v1"><div class="ch">
<span class="ci">151</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2601.01695v1" target="_blank">Learnability-Driven Submodular Optimization for Active Roadside 3D Detection</a></div>
<div class="sum-cn">研究问题：路边感知数据集的标注困难；方法：提出路边数据集的标注方法；创新点：解决硬件和隐私限制下的标注问题；结果：提高标注准确性。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2601.01695v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2601.01695v1','Learnability-Driven Submodular Optimization for Active Roadside 3D Detection','http://arxiv.org/abs/2601.01695v1','http://arxiv.org/pdf/2601.01695v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2601.01695v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2601.01695v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2601.01695v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2601.00991v1"><div class="ch">
<span class="ci">152</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2601.00991v1" target="_blank">UnrealPose: Leveraging Game Engine Kinematics for Large-Scale Synthetic Human Pose Data</a></div>
<div class="sum-cn">研究问题：高质量3D人体姿态数据获取困难；方法：构建UnrealPose-Gen渲染管线；创新点：实现高质量离线渲染；结果：生成包含3D关节的高质量帧。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2601.00991v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2601.00991v1','UnrealPose: Leveraging Game Engine Kinematics for Large-Scale Synthetic Human Pose Data','http://arxiv.org/abs/2601.00991v1','http://arxiv.org/pdf/2601.00991v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2601.00991v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2601.00991v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2601.00991v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2512.21058v2"><div class="ch">
<span class="ci">153</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2512.21058v2" target="_blank">Beyond Pixel Simulation: Pathology Image Generation via Diagnostic Semantic Tokens and Prototype Control</a></div>
<div class="sum-cn">研究问题：计算病理学中理解和生成模型的进展不平衡；方法：提出解决三个耦合因素的方案；创新点：结合理解模型和生成模型；结果：提高诊断水平。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2512.21058v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2512.21058v2','Beyond Pixel Simulation: Pathology Image Generation via Diagnostic Semantic Tokens and Prototype Control','http://arxiv.org/abs/2512.21058v2','http://arxiv.org/pdf/2512.21058v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2512.21058v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2512.21058v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2512.21058v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2512.20770v1"><div class="ch">
<span class="ci">154</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2512.20770v1" target="_blank">OccuFly: A 3D Vision Benchmark for Semantic Scene Completion from the Aerial Perspective</a></div>
<div class="sum-cn">研究问题：语义场景补全在移动机器人中的应用；方法：提出基于SSC的3D感知方法；创新点：联合估计体积占用和像素级语义；结果：实现整体场景理解。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2512.20770v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2512.20770v1','OccuFly: A 3D Vision Benchmark for Semantic Scene Completion from the Aerial Perspective','http://arxiv.org/abs/2512.20770v1','http://arxiv.org/pdf/2512.20770v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2512.20770v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2512.20770v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2512.20770v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2512.20340v2"><div class="ch">
<span class="ci">155</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2512.20340v2" target="_blank">The devil is in the details: Enhancing Video Virtual Try-On via Keyframe-Driven Details Injection</a></div>
<div class="sum-cn">研究问题：基于扩散变换的视频虚拟试穿方法存在局限性；方法：提出改进的VVT方法；创新点：捕捉服装动态和背景完整性；结果：提高视频合成质量。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2512.20340v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2512.20340v2','The devil is in the details: Enhancing Video Virtual Try-On via Keyframe-Driven Details Injection','http://arxiv.org/abs/2512.20340v2','http://arxiv.org/pdf/2512.20340v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2512.20340v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2512.20340v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2512.20340v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2512.17514v3"><div class="ch">
<span class="ci">156</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2512.17514v3" target="_blank">Foundation Model Priors Enhance Object Focus in Feature Space for Source-Free Object Detection</a></div>
<div class="sum-cn">研究问题：源无对象检测方法存在域偏移问题；方法：提出改进的SFOD方法；创新点：解决背景杂波问题；结果：提高检测准确性。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2512.17514v3')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2512.17514v3','Foundation Model Priors Enhance Object Focus in Feature Space for Source-Free Object Detection','http://arxiv.org/abs/2512.17514v3','http://arxiv.org/pdf/2512.17514v3')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2512.17514v3')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2512.17514v3" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2512.17514v3" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2512.16397v1"><div class="ch">
<span class="ci">157</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2512.16397v1" target="_blank">Using Gaussian Splats to Create High-Fidelity Facial Geometry and Texture</a></div>
<div class="sum-cn">研究问题：构建人脸图像的统一解释；方法：利用高斯分层；创新点：提高解释的约束性；结果：实现人脸图像的统一解释。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2512.16397v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2512.16397v1','Using Gaussian Splats to Create High-Fidelity Facial Geometry and Texture','http://arxiv.org/abs/2512.16397v1','http://arxiv.org/pdf/2512.16397v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2512.16397v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2512.16397v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2512.16397v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2512.05016v2"><div class="ch">
<span class="ci">158</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2512.05016v2" target="_blank">Generative Neural Video Compression via Video Diffusion Prior</a></div>
<div class="sum-cn">研究问题：基于扩散变换的视频压缩方法存在局限性；方法：提出GNVC-VD压缩框架；创新点：统一时空压缩和生成优化；结果：提高视频压缩质量。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2512.05016v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2512.05016v2','Generative Neural Video Compression via Video Diffusion Prior','http://arxiv.org/abs/2512.05016v2','http://arxiv.org/pdf/2512.05016v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2512.05016v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2512.05016v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2512.05016v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2512.04421v1"><div class="ch">
<span class="ci">159</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2512.04421v1" target="_blank">UTrice: Unifying Primitives in Differentiable Ray Tracing and Rasterization via Triangles for Particle-Based 3D Scenes</a></div>
<div class="sum-cn">研究问题：基于光线追踪的3D高斯粒子方法存在计算成本高的问题；方法：提出基于代理几何的光线追踪方法；创新点：降低计算成本；结果：实现新型视图合成。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2512.04421v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2512.04421v1','UTrice: Unifying Primitives in Differentiable Ray Tracing and Rasterization via Triangles for Particle-Based 3D Scenes','http://arxiv.org/abs/2512.04421v1','http://arxiv.org/pdf/2512.04421v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2512.04421v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2512.04421v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2512.04421v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2512.04309v1"><div class="ch">
<span class="ci">160</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2512.04309v1" target="_blank">Text-Only Training for Image Captioning with Retrieval Augmentation and Modality Gap Correction</a></div>
<div class="sum-cn">研究问题：图像描述生成方法对标注数据依赖度高；方法：提出无标注数据训练的图像描述生成方法；创新点：降低对标注数据的依赖；结果：提高图像描述生成质量。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2512.04309v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2512.04309v1','Text-Only Training for Image Captioning with Retrieval Augmentation and Modality Gap Correction','http://arxiv.org/abs/2512.04309v1','http://arxiv.org/pdf/2512.04309v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2512.04309v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2512.04309v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2512.04309v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2512.02700v4"><div class="ch">
<span class="ci">161</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2512.02700v4" target="_blank">VLM-Pruner: Buffering for Spatial Sparsity in an Efficient VLM Centrifugal Token Pruning Paradigm</a></div>
<div class="sum-cn">研究问题：视觉语言模型在移动设备部署中的计算成本高。方法：提出一种考虑互信息冗余的剪枝方法。创新点：结合互信息剪枝和注意力机制。结果：显著降低计算成本，提高模型效率。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2512.02700v4')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2512.02700v4','VLM-Pruner: Buffering for Spatial Sparsity in an Efficient VLM Centrifugal Token Pruning Paradigm','http://arxiv.org/abs/2512.02700v4','http://arxiv.org/pdf/2512.02700v4')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2512.02700v4')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2512.02700v4" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2512.02700v4" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2512.02686v2"><div class="ch">
<span class="ci">162</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2512.02686v2" target="_blank">ClimaOoD: Improving Anomaly Segmentation via Physically Realistic Synthetic Data</a></div>
<div class="sum-cn">研究问题：异常分割在开放场景中模型泛化受限。方法：引入数据增强和迁移学习。创新点：利用异常数据生成技术。结果：提高模型在开放场景中的泛化能力。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2512.02686v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2512.02686v2','ClimaOoD: Improving Anomaly Segmentation via Physically Realistic Synthetic Data','http://arxiv.org/abs/2512.02686v2','http://arxiv.org/pdf/2512.02686v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2512.02686v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2512.02686v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2512.02686v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2512.02172v1"><div class="ch">
<span class="ci">163</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2512.02172v1" target="_blank">SplatSuRe: Selective Super-Resolution for Multi-view Consistent 3D Gaussian Splatting</a></div>
<div class="sum-cn">研究问题：3D高斯分层渲染超分辨率。方法：将超分辨率与3DGS结合。创新点：提出一种新的超分辨率方法。结果：提高渲染质量。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2512.02172v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2512.02172v1','SplatSuRe: Selective Super-Resolution for Multi-view Consistent 3D Gaussian Splatting','http://arxiv.org/abs/2512.02172v1','http://arxiv.org/pdf/2512.02172v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2512.02172v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2512.02172v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2512.02172v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2511.23055v2"><div class="ch">
<span class="ci">164</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2511.23055v2" target="_blank">MindPower: Enabling Theory-of-Mind Reasoning in VLM-based Embodied Agents</a></div>
<div class="sum-cn">研究问题：视觉语言代理缺乏理论思维决策。方法：引入基于理论思维的决策模型。创新点：结合人类心理状态和代理视角。结果：提高代理决策能力。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2511.23055v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2511.23055v2','MindPower: Enabling Theory-of-Mind Reasoning in VLM-based Embodied Agents','http://arxiv.org/abs/2511.23055v2','http://arxiv.org/pdf/2511.23055v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2511.23055v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2511.23055v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2511.23055v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2511.22860v1"><div class="ch">
<span class="ci">165</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2511.22860v1" target="_blank">MARVO: Marine-Adaptive Radiance-aware Visual Odometry</a></div>
<div class="sum-cn">研究问题：水下视觉定位困难。方法：提出MARVO框架，融合图像建模、匹配和强化学习。创新点：物理感知和深度学习结合。结果：提高水下定位精度。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2511.22860v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2511.22860v1','MARVO: Marine-Adaptive Radiance-aware Visual Odometry','http://arxiv.org/abs/2511.22860v1','http://arxiv.org/pdf/2511.22860v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2511.22860v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2511.22860v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2511.22860v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2511.20629v4"><div class="ch">
<span class="ci">166</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2511.20629v4" target="_blank">MapReduce LoRA: Advancing the Pareto Front in Multi-Preference Optimization for Generative Models</a></div>
<div class="sum-cn">研究问题：多奖励优化导致对齐税。方法：提出一种多奖励优化方法。创新点：平衡多个奖励维度。结果：提高模型对齐效果。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2511.20629v4')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2511.20629v4','MapReduce LoRA: Advancing the Pareto Front in Multi-Preference Optimization for Generative Models','http://arxiv.org/abs/2511.20629v4','http://arxiv.org/pdf/2511.20629v4')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2511.20629v4')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2511.20629v4" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2511.20629v4" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2511.18570v1"><div class="ch">
<span class="ci">167</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2511.18570v1" target="_blank">PhysGS: Bayesian-Inferred Gaussian Splatting for Physical Property Estimation</a></div>
<div class="sum-cn">研究问题：3D重建无法推断物理属性。方法：引入物理属性推断方法。创新点：结合几何和物理信息。结果：提高机器人交互能力。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2511.18570v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2511.18570v1','PhysGS: Bayesian-Inferred Gaussian Splatting for Physical Property Estimation','http://arxiv.org/abs/2511.18570v1','http://arxiv.org/pdf/2511.18570v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2511.18570v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2511.18570v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2511.18570v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2511.18507v2"><div class="ch">
<span class="ci">168</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2511.18507v2" target="_blank">Multimodal Continual Learning with MLLMs from Multi-scenario Perspectives</a></div>
<div class="sum-cn">研究问题：MLLMs在动态场景中持续学习困难。方法：提出一种基于多模态的持续学习方法。创新点：结合多模态信息。结果：提高模型在动态场景中的适应性。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2511.18507v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2511.18507v2','Multimodal Continual Learning with MLLMs from Multi-scenario Perspectives','http://arxiv.org/abs/2511.18507v2','http://arxiv.org/pdf/2511.18507v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2511.18507v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2511.18507v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2511.18507v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2511.18281v1"><div class="ch">
<span class="ci">169</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2511.18281v1" target="_blank">Uni-DAD: Unified Distillation and Adaptation of Diffusion Models for Few-step Few-shot Image Generation</a></div>
<div class="sum-cn">研究问题：扩散模型在新型领域生成速度慢。方法：提出两阶段训练管道。创新点：结合蒸馏和迁移学习。结果：提高新型领域生成速度和质量。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2511.18281v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2511.18281v1','Uni-DAD: Unified Distillation and Adaptation of Diffusion Models for Few-step Few-shot Image Generation','http://arxiv.org/abs/2511.18281v1','http://arxiv.org/pdf/2511.18281v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2511.18281v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2511.18281v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2511.18281v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2511.16156v2"><div class="ch">
<span class="ci">170</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2511.16156v2" target="_blank">Pluggable Pruning with Contiguous Layer Distillation for Diffusion Transformers</a></div>
<div class="sum-cn">研究问题：扩散Transformer参数量大。方法：提出PPCL剪枝方法。创新点：结合连续层蒸馏和可插拔剪枝。结果：降低计算成本，提高模型效率。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2511.16156v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2511.16156v2','Pluggable Pruning with Contiguous Layer Distillation for Diffusion Transformers','http://arxiv.org/abs/2511.16156v2','http://arxiv.org/pdf/2511.16156v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2511.16156v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2511.16156v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2511.16156v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2511.15487v2"><div class="ch">
<span class="ci">171</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2511.15487v2" target="_blank">NTK-Guided Implicit Neural Teaching</a></div>
<div class="sum-cn">研究问题：如何优化高分辨率信号的隐式神经网络表示（INRs）参数化。方法：通过多层感知器（MLPs）参数化连续信号。创新点：提出了一种新的优化方法，减少优化坐标数量。结果：提高了高分辨率信号建模的效率和准确性。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2511.15487v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2511.15487v2','NTK-Guided Implicit Neural Teaching','http://arxiv.org/abs/2511.15487v2','http://arxiv.org/pdf/2511.15487v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2511.15487v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2511.15487v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2511.15487v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2511.13135v2"><div class="ch">
<span class="ci">172</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2511.13135v2" target="_blank">MedGEN-Bench: Contextually entangled benchmark for open-ended multimodal medical generation</a></div>
<div class="sum-cn">研究问题：如何使AI系统在医疗应用中生成与文本诊断相对应的医学图像。方法：开发了一种视觉-语言模型（VLM）。创新点：将VLM应用于医学图像生成。结果：生成的医学图像与临床工作流程无缝集成。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2511.13135v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2511.13135v2','MedGEN-Bench: Contextually entangled benchmark for open-ended multimodal medical generation','http://arxiv.org/abs/2511.13135v2','http://arxiv.org/pdf/2511.13135v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2511.13135v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2511.13135v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2511.13135v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2511.12554v1"><div class="ch">
<span class="ci">173</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2511.12554v1" target="_blank">EmoVerse: A MLLMs-Driven Emotion Representation Dataset for Interpretable Visual Emotion Analysis</a></div>
<div class="sum-cn">研究问题：如何提高视觉情感分析（VEA）的准确性和可解释性。方法：构建了一个开源、可解释的数据集。创新点：提出了一种新的情感标签分配方法。结果：提高了VEA的准确性和可解释性。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2511.12554v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2511.12554v1','EmoVerse: A MLLMs-Driven Emotion Representation Dataset for Interpretable Visual Emotion Analysis','http://arxiv.org/abs/2511.12554v1','http://arxiv.org/pdf/2511.12554v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2511.12554v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2511.12554v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2511.12554v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2511.12370v3"><div class="ch">
<span class="ci">174</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2511.12370v3" target="_blank">Changes in Real Time: Online Scene Change Detection with Multi-View Fusion</a></div>
<div class="sum-cn">研究问题：如何提高在线场景变化检测（SCD）的准确性。方法：提出了一种新的在线SCD方法。创新点：首次实现了在线SCD。结果：提高了SCD的准确性。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2511.12370v3')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2511.12370v3','Changes in Real Time: Online Scene Change Detection with Multi-View Fusion','http://arxiv.org/abs/2511.12370v3','http://arxiv.org/pdf/2511.12370v3')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2511.12370v3')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2511.12370v3" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2511.12370v3" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2511.11851v2"><div class="ch">
<span class="ci">175</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2511.11851v2" target="_blank">Defending Unauthorized Model Merging via Dual-Stage Weight Protection</a></div>
<div class="sum-cn">研究问题：如何防止未经授权的模型合并。方法：开发了一种模型合并检测方法。创新点：提出了一种新的检测算法。结果：有效防止了未经授权的模型合并。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2511.11851v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2511.11851v2','Defending Unauthorized Model Merging via Dual-Stage Weight Protection','http://arxiv.org/abs/2511.11851v2','http://arxiv.org/pdf/2511.11851v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2511.11851v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2511.11851v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2511.11851v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2511.10376v3"><div class="ch">
<span class="ci">176</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2511.10376v3" target="_blank">MSGNav: Unleashing the Power of Multi-modal 3D Scene Graph for Zero-Shot Embodied Navigation</a></div>
<div class="sum-cn">研究问题：如何实现机器人导航的零样本方法。方法：提出了一种基于开放词汇的零样本方法。创新点：无需特定任务训练。结果：提高了机器人导航的效率和准确性。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2511.10376v3')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2511.10376v3','MSGNav: Unleashing the Power of Multi-modal 3D Scene Graph for Zero-Shot Embodied Navigation','http://arxiv.org/abs/2511.10376v3','http://arxiv.org/pdf/2511.10376v3')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2511.10376v3')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2511.10376v3" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2511.10376v3" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2511.01425v1"><div class="ch">
<span class="ci">177</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2511.01425v1" target="_blank">Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis</a></div>
<div class="sum-cn">研究问题：如何提高AI模型在医学领域的可解释性。方法：开发了一种交互式解释代理。创新点：通过可审计的动作序列生成解释。结果：提高了AI模型在医学领域的可解释性和可信度。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2511.01425v1')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2511.01425v1','Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis','http://arxiv.org/abs/2511.01425v1','http://arxiv.org/pdf/2511.01425v1')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2511.01425v1')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2511.01425v1" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2511.01425v1" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2510.08318v3"><div class="ch">
<span class="ci">178</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2510.08318v3" target="_blank">LinVideo: A Post-Training Framework towards O(n) Attention in Efficient Video Generation</a></div>
<div class="sum-cn">研究问题：如何降低视频扩散模型（DMs）的计算成本。方法：提出了一种线性注意力机制。创新点：降低了计算复杂度。结果：降低了DMs的计算成本。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2510.08318v3')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2510.08318v3','LinVideo: A Post-Training Framework towards O(n) Attention in Efficient Video Generation','http://arxiv.org/abs/2510.08318v3','http://arxiv.org/pdf/2510.08318v3')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2510.08318v3')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2510.08318v3" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2510.08318v3" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2509.25210v2"><div class="ch">
<span class="ci">179</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2509.25210v2" target="_blank">STCast: Adaptive Boundary Alignment for Global and Regional Weather Forecasting</a></div>
<div class="sum-cn">研究问题：如何提高区域天气预报的准确性。方法：提出了一种基于区域集成的方法。创新点：结合了物理和数据驱动方法。结果：提高了区域天气预报的准确性。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2509.25210v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2509.25210v2','STCast: Adaptive Boundary Alignment for Global and Regional Weather Forecasting','http://arxiv.org/abs/2509.25210v2','http://arxiv.org/pdf/2509.25210v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2509.25210v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2509.25210v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2509.25210v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2509.14544v2"><div class="ch">
<span class="ci">180</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2509.14544v2" target="_blank">Association and Consolidation: Evolutionary Memory-Enhanced Incremental Multi-View Clustering</a></div>
<div class="sum-cn">研究问题：如何解决增量多视图聚类中的稳定性-塑性困境（SPD）。方法：提出了一种新的增量多视图聚类方法。创新点：平衡了稳定性和塑性。结果：实现了稳定的聚类结果。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2509.14544v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2509.14544v2','Association and Consolidation: Evolutionary Memory-Enhanced Incremental Multi-View Clustering','http://arxiv.org/abs/2509.14544v2','http://arxiv.org/pdf/2509.14544v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2509.14544v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2509.14544v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2509.14544v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2509.01552v2"><div class="ch">
<span class="ci">181</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2509.01552v2" target="_blank">Variation-aware Vision Token Dropping for Faster Large Vision-Language Models</a></div>
<div class="sum-cn">研究问题：大视觉语言模型在多模态理解任务中的效率问题。方法：提出一种基于token压缩的优化方法。创新点：通过减少token数量提高推理效率。结果：显著提升了推理速度。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2509.01552v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2509.01552v2','Variation-aware Vision Token Dropping for Faster Large Vision-Language Models','http://arxiv.org/abs/2509.01552v2','http://arxiv.org/pdf/2509.01552v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2509.01552v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2509.01552v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2509.01552v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2508.02291v2"><div class="ch">
<span class="ci">182</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2508.02291v2" target="_blank">FAIR-Pruner: Leveraging Tolerance of Difference for Flexible Automatic Layer-Wise Neural Network Pruning</a></div>
<div class="sum-cn">研究问题：神经网络剪枝方法导致性能下降。方法：提出一种非均匀剪枝策略。创新点：根据重要性调整剪枝力度。结果：在保持性能的同时降低了参数规模。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2508.02291v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2508.02291v2','FAIR-Pruner: Leveraging Tolerance of Difference for Flexible Automatic Layer-Wise Neural Network Pruning','http://arxiv.org/abs/2508.02291v2','http://arxiv.org/pdf/2508.02291v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2508.02291v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2508.02291v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2508.02291v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2507.10065v2"><div class="ch">
<span class="ci">183</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2507.10065v2" target="_blank">MoVieS: Motion-Aware 4D Dynamic View Synthesis in One Second</a></div>
<div class="sum-cn">研究问题：从单目视频中重建4D动态场景。方法：提出MoVieS模型，使用高斯原语表示动态场景。创新点：首次实现统一运动感知。结果：重建效果显著。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2507.10065v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2507.10065v2','MoVieS: Motion-Aware 4D Dynamic View Synthesis in One Second','http://arxiv.org/abs/2507.10065v2','http://arxiv.org/pdf/2507.10065v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2507.10065v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2507.10065v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2507.10065v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2506.09217v2"><div class="ch">
<span class="ci">184</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2506.09217v2" target="_blank">Perception Characteristics Distance: Measuring Stability and Robustness of Perception System in Dynamic Conditions under a Certain Decision Rule</a></div>
<div class="sum-cn">研究问题：自动驾驶系统中感知算法的随机性对安全的影响。方法：提出一种基于时间碰撞估计的改进方法。创新点：提高感知算法的准确性。结果：提升了自动驾驶系统的安全性。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2506.09217v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2506.09217v2','Perception Characteristics Distance: Measuring Stability and Robustness of Perception System in Dynamic Conditions under a Certain Decision Rule','http://arxiv.org/abs/2506.09217v2','http://arxiv.org/pdf/2506.09217v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2506.09217v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2506.09217v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2506.09217v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2506.07917v3"><div class="ch">
<span class="ci">185</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2506.07917v3" target="_blank">SpeeDe3DGS: Speedy Deformable 3D Gaussian Splatting with Temporal Pruning and Motion Grouping</a></div>
<div class="sum-cn">研究问题：3D高斯分层（3DGS）模型的计算成本。方法：提出Speedy Deformable 3D Gaussian Splatting（SpeeDe3DGS）模型。创新点：降低计算成本。结果：提高了重建速度。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2506.07917v3')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2506.07917v3','SpeeDe3DGS: Speedy Deformable 3D Gaussian Splatting with Temporal Pruning and Motion Grouping','http://arxiv.org/abs/2506.07917v3','http://arxiv.org/pdf/2506.07917v3')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2506.07917v3')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2506.07917v3" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2506.07917v3" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2506.01783v2"><div class="ch">
<span class="ci">186</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2506.01783v2" target="_blank">Harnessing Chain-of-Thought Reasoning in Multimodal Large Language Models for Face Anti-Spoofing</a></div>
<div class="sum-cn">研究问题：人脸反欺骗（FAS）的泛化能力。方法：提出一种多模态方法。创新点：结合多种视觉模态提高泛化能力。结果：提升了FAS的性能。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2506.01783v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2506.01783v2','Harnessing Chain-of-Thought Reasoning in Multimodal Large Language Models for Face Anti-Spoofing','http://arxiv.org/abs/2506.01783v2','http://arxiv.org/pdf/2506.01783v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2506.01783v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2506.01783v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2506.01783v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2506.01085v2"><div class="ch">
<span class="ci">187</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2506.01085v2" target="_blank">Learning What Matters: Prioritized Concept Learning via Relative Error-driven Sample Selection</a></div>
<div class="sum-cn">研究问题：视觉语言模型（VLM）的指令微调成本高。方法：提出PROGRESS方法。创新点：通过相对误差驱动样本选择降低成本。结果：提高了指令微调的效率。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2506.01085v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2506.01085v2','Learning What Matters: Prioritized Concept Learning via Relative Error-driven Sample Selection','http://arxiv.org/abs/2506.01085v2','http://arxiv.org/pdf/2506.01085v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2506.01085v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2506.01085v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2506.01085v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2505.22499v3"><div class="ch">
<span class="ci">188</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2505.22499v3" target="_blank">SABER: Spatially Consistent 3D Universal Adversarial Objects for BEV Detectors</a></div>
<div class="sum-cn">研究问题：BEV 3D目标检测器的对抗鲁棒性。方法：提出一种非侵入式攻击方法。创新点：无需修改目标车辆。结果：提高了检测器的鲁棒性。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2505.22499v3')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2505.22499v3','SABER: Spatially Consistent 3D Universal Adversarial Objects for BEV Detectors','http://arxiv.org/abs/2505.22499v3','http://arxiv.org/pdf/2505.22499v3')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2505.22499v3')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2505.22499v3" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2505.22499v3" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2504.18594v2"><div class="ch">
<span class="ci">189</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2504.18594v2" target="_blank">RaPA: Enhancing Transferable Targeted Attacks via Random Parameter Pruning</a></div>
<div class="sum-cn">研究问题：针对目标攻击的攻击成功率低。方法：提出一种基于多样化输入、稳定梯度和重新训练代理模型的方法。创新点：提高攻击成功率。结果：提升了攻击效果。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2504.18594v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2504.18594v2','RaPA: Enhancing Transferable Targeted Attacks via Random Parameter Pruning','http://arxiv.org/abs/2504.18594v2','http://arxiv.org/pdf/2504.18594v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2504.18594v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2504.18594v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2504.18594v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2504.11434v2"><div class="ch">
<span class="ci">190</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2504.11434v2" target="_blank">Enhancing Out-of-Distribution Detection with Extended Logit Normalization</a></div>
<div class="sum-cn">研究问题：模型校准在分布外（OOD）检测中的应用。方法：提出一种基于模型校准的OOD检测方法。创新点：提高检测准确性。结果：提升了OOD检测的性能。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2504.11434v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2504.11434v2','Enhancing Out-of-Distribution Detection with Extended Logit Normalization','http://arxiv.org/abs/2504.11434v2','http://arxiv.org/pdf/2504.11434v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2504.11434v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2504.11434v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2504.11434v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2503.10981v4"><div class="ch">
<span class="ci">191</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2503.10981v4" target="_blank">CLIP-Free, Label Free, Unsupervised Concept Bottleneck Models</a></div>
<div class="sum-cn">研究问题：如何设计不依赖CLIP模型的Concept Bottleneck Models (CBMs)。方法：提出一种新的CBMs设计方法。创新点：无需CLIP模型，直接从图像中提取概念。结果：实验表明，该方法在预测准确率上与依赖CLIP模型的CBMs相当。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2503.10981v4')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2503.10981v4','CLIP-Free, Label Free, Unsupervised Concept Bottleneck Models','http://arxiv.org/abs/2503.10981v4','http://arxiv.org/pdf/2503.10981v4')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2503.10981v4')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2503.10981v4" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2503.10981v4" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2503.08049v3"><div class="ch">
<span class="ci">192</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2503.08049v3" target="_blank">SphOR: A Representation Learning Perspective on Open-set Recognition for Identifying Unknown Classes in Deep Learning Models</a></div>
<div class="sum-cn">研究问题：如何提高基于DNN分类器的Open-Set Recognition (OSR)能力。方法：提出一种新的OSR算法。创新点：通过识别未知类别数据，避免误分类。结果：实验证明，该方法在OSR任务中具有显著优势。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2503.08049v3')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2503.08049v3','SphOR: A Representation Learning Perspective on Open-set Recognition for Identifying Unknown Classes in Deep Learning Models','http://arxiv.org/abs/2503.08049v3','http://arxiv.org/pdf/2503.08049v3')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2503.08049v3')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2503.08049v3" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2503.08049v3" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2503.07853v2"><div class="ch">
<span class="ci">193</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2503.07853v2" target="_blank">Hier-COS: Making Deep Features Hierarchy-aware via Composition of Orthogonal Subspaces</a></div>
<div class="sum-cn">研究问题：如何改进传统分类器在具有语义层次结构场景下的性能。方法：提出一种基于层次结构的分类器。创新点：考虑负类别的偏好顺序，提高分类准确率。结果：实验结果表明，该方法在多个数据集上均优于传统分类器。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2503.07853v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2503.07853v2','Hier-COS: Making Deep Features Hierarchy-aware via Composition of Orthogonal Subspaces','http://arxiv.org/abs/2503.07853v2','http://arxiv.org/pdf/2503.07853v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2503.07853v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2503.07853v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2503.07853v2" target="_blank">PDF</a></div>
</div></div><div class="card" data-pid="2411.16758v2"><div class="ch">
<span class="ci">194</span><div class="cb">
<div class="ct"><a href="http://arxiv.org/abs/2411.16758v2" target="_blank">Motion-Aware Animatable Gaussian Avatars Deblurring</a></div>
<div class="sum-cn">研究问题：如何从多视角视频中创建3D人像。方法：提出一种基于视频的3D人像生成方法。创新点：无需高质量图像，适应实际场景。结果：实验证明，该方法在生成3D人像方面具有较高准确率和鲁棒性。</div></div>
<div class="actions">
<button class="abtn chk-btn" onclick="toggleCheck(this,'2411.16758v2')" title="已读">&#10003;</button>
<button class="abtn fav-btn" onclick="toggleFav(this,'2411.16758v2','Motion-Aware Animatable Gaussian Avatars Deblurring','http://arxiv.org/abs/2411.16758v2','http://arxiv.org/pdf/2411.16758v2')" title="收藏">&#9825;</button>
<button class="abtn del-btn" onclick="delPaper(this,'2411.16758v2')" title="删除">&times;</button>
</div>
<div class="links"><a href="http://arxiv.org/abs/2411.16758v2" target="_blank">arXiv</a><a href="http://arxiv.org/pdf/2411.16758v2" target="_blank">PDF</a></div>
</div></div>`;
function getDeleted(){try{return JSON.parse(localStorage.getItem('del_papers')||'[]')}catch{return[]}}
function getFavs(){try{return JSON.parse(localStorage.getItem('fav_papers')||'{}')}catch{return{}}}
function getChecked(){try{return JSON.parse(localStorage.getItem('chk_papers')||'[]')}catch{return[]}}
function toggleCheck(btn,pid){const chks=getChecked();const card=btn.closest('.card');if(chks.includes(pid)){chks.splice(chks.indexOf(pid),1);btn.classList.remove('on');if(card)card.classList.remove('checked')}else{chks.push(pid);btn.classList.add('on');if(card)card.classList.add('checked')}localStorage.setItem('chk_papers',JSON.stringify(chks))}
function renum(){document.querySelectorAll('.card').forEach((c,i)=>{const ci=c.querySelector('.ci');if(ci)ci.textContent=i+1})}
function delPaper(btn,pid){const dels=getDeleted();if(!dels.includes(pid))dels.push(pid);localStorage.setItem('del_papers',JSON.stringify(dels));const card=btn.closest('.card');if(card){card.style.transition='all .3s';card.style.opacity='0';card.style.transform='scale(.97)';setTimeout(()=>{card.remove();renum()},300)}}
function toggleFav(btn,pid,title,link,pdf){const favs=getFavs();if(favs[pid]){delete favs[pid];btn.innerHTML='&#9825;';btn.classList.remove('on')}else{favs[pid]={title,link,pdf,t:Date.now()};btn.innerHTML='&#9829;';btn.classList.add('on')}localStorage.setItem('fav_papers',JSON.stringify(favs))}
function initCards(){const dels=getDeleted();const favs=getFavs();const chks=getChecked();document.querySelectorAll('.card[data-pid]').forEach(c=>{const pid=c.dataset.pid;if(dels.includes(pid)){c.remove();return}const fb=c.querySelector('.fav-btn');if(fb&&favs[pid]){fb.innerHTML='&#9829;';fb.classList.add('on')}const cb=c.querySelector('.chk-btn');if(cb&&chks.includes(pid)){cb.classList.add('on');c.classList.add('checked')}});renum()};
function filter(){const q=document.getElementById('si').value.toLowerCase();const el=document.getElementById('pl');const d=document.createElement('div');d.innerHTML=ALL;const cards=[...d.querySelectorAll('.card')];let n=0;let h='';cards.forEach(c=>{const t=c.textContent.toLowerCase();if(!q||q.split(/\s+/).every(w=>t.includes(w))){h+=c.outerHTML;n++}});el.innerHTML=h||'<div class="nr">没有匹配的论文</div>';document.getElementById('cnt').textContent=n+' 篇';initCards()}
window.addEventListener('scroll',()=>document.getElementById('st').classList.toggle('v',window.scrollY>400));

const REPO='Issac304/arxiv-papers';
function getToken(){let t=localStorage.getItem('gh_token');if(!t){t=prompt('首次使用需输入 GitHub Token\n\nGitHub → Settings → Developer settings → Personal access tokens → Fine-grained → Generate\n\n权限勾选 Actions: Read and Write');if(t)localStorage.setItem('gh_token',t)}return t}
async function doFetchCvpr(){
const token=getToken();if(!token)return;
const fs=document.getElementById('fs');
fs.textContent='正在触发 CVPR 抓取...';fs.style.color='var(--ac)';
try{
const r=await fetch(`https://api.github.com/repos/${REPO}/actions/workflows/daily.yml/dispatches`,{
method:'POST',headers:{'Authorization':`token ${token}`,'Accept':'application/vnd.github.v3+json'},
body:JSON.stringify({ref:'master',inputs:{date:''}})
});
if(r.status===204){fs.textContent='已触发抓取，约2-3分钟后刷新页面查看';fs.style.color='var(--ac2)';pollCvpr(token)}
else if(r.status===401){localStorage.removeItem('gh_token');fs.textContent='Token 无效，请重新输入';fs.style.color='#ff6b6b'}
else{fs.textContent='触发失败';fs.style.color='#ff6b6b'}
}catch(e){fs.textContent='网络错误: '+e.message;fs.style.color='#ff6b6b'}
}
async function pollCvpr(token){
const fs=document.getElementById('fs');
for(let i=0;i<30;i++){
await new Promise(r=>setTimeout(r,5000));
try{
const r=await fetch(`https://api.github.com/repos/${REPO}/actions/runs?per_page=1`,{headers:{'Authorization':`token ${token}`}});
const d=await r.json();const run=d.workflow_runs&&d.workflow_runs[0];
if(!run)continue;
if(run.status==='completed'){
if(run.conclusion==='success'){fs.textContent='CVPR 抓取完成! 刷新页面查看';fs.style.color='#45d4c8'}
else{fs.textContent='抓取结束 ('+run.conclusion+')';fs.style.color='#ff6b6b'}
return}
fs.textContent='抓取中... ('+run.status+')';
}catch{}
}
}

filter();
</script>
<button class="chat-btn" onclick="document.getElementById('chatbox').classList.toggle('open')" title="AI 助手">&#128172;</button>
<div class="chat-box" id="chatbox">
<div class="chat-header"><span>Frontier AI</span><button class="chat-close" onclick="document.getElementById('chatbox').classList.remove('open')">&times;</button></div>
<div class="chat-msgs" id="chatmsgs"><div class="chat-msg bot">你好！我是 AI 助手，可以帮你解读论文、回答 AI 相关问题。</div></div>
<div class="chat-input"><input id="chatin" placeholder="输入问题..." onkeydown="if(event.key==='Enter')sendChat()"><button onclick="sendChat()">发送</button></div>
</div>
<script>
function getZhipuKey(){let k=localStorage.getItem('zhipu_key');if(!k){k=prompt('输入智谱 API Key（GLM-4-Flash 免费）');if(k)localStorage.setItem('zhipu_key',k)}return k}
async function sendChat(){
const input=document.getElementById('chatin');const msg=input.value.trim();if(!msg)return;
const key=getZhipuKey();if(!key)return;
const msgs=document.getElementById('chatmsgs');
msgs.innerHTML+=`<div class="chat-msg user">${msg.replace(/</g,'&lt;')}</div>`;
msgs.innerHTML+=`<div class="chat-msg bot loading" id="botloading">思考中...</div>`;
msgs.scrollTop=msgs.scrollHeight;input.value='';
try{
const r=await fetch('https://open.bigmodel.cn/api/paas/v4/chat/completions',{
method:'POST',headers:{'Authorization':'Bearer '+key,'Content-Type':'application/json'},
body:JSON.stringify({model:'glm-4-flash',messages:[{role:'system',content:'你是一个AI论文助手，帮助用户理解论文、解释概念、回答AI相关问题。用中文回答，简洁专业。'},{role:'user',content:msg}],temperature:0.7,max_tokens:1000})
});
const d=await r.json();const reply=d.choices[0].message.content;
document.getElementById('botloading').outerHTML=`<div class="chat-msg bot">${reply.replace(/</g,'&lt;').replace(/\n/g,'<br>')}</div>`;
}catch(e){document.getElementById('botloading').outerHTML=`<div class="chat-msg bot" style="color:#ff6b6b">请求失败: ${e.message}</div>`}
msgs.scrollTop=msgs.scrollHeight;
}
</script>
</body></html>