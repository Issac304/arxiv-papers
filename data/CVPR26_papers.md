# CVPR 2026 论文列表 (arXiv)

> 来源: arXiv API 搜索
> 关键词: CVPR 2026, CVPR2026, CVPR 26, cvpr26
> 已排除 workshop 论文
> 总计: 194 篇论文

---

## 1. VGG-T$^3$: Offline Feed-Forward 3D Reconstruction at Scale

- **arXiv ID**: 2602.23361v1
- **作者**: Sven Elflein, Ruilong Li, Sérgio Agostinho, Zan Gojcic, Laura Leal-Taixé 等 (共7位作者)
- **发布日期**: 2026-02-26
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.23361v1](http://arxiv.org/abs/2602.23361v1)
- **PDF**: [http://arxiv.org/pdf/2602.23361v1](http://arxiv.org/pdf/2602.23361v1)
- **摘要**: We present a scalable 3D reconstruction model that addresses a critical limitation in offline feed-forward methods: their computational and memory requirements grow quadratically w.r.t. the number of input images. Our approach is built on the key insight that this bottleneck stems from the varying-l...

---

## 2. SeeThrough3D: Occlusion Aware 3D Control in Text-to-Image Generation

- **arXiv ID**: 2602.23359v1
- **作者**: Vaibhav Agrawal, Rishubh Parihar, Pradhaan Bhat, Ravi Kiran Sarvadevabhatla, R. Venkatesh Babu
- **发布日期**: 2026-02-26
- **分类**: cs.CV, cs.AI
- **论文链接**: [http://arxiv.org/abs/2602.23359v1](http://arxiv.org/abs/2602.23359v1)
- **PDF**: [http://arxiv.org/pdf/2602.23359v1](http://arxiv.org/pdf/2602.23359v1)
- **摘要**: We identify occlusion reasoning as a fundamental yet overlooked aspect for 3D layout-conditioned generation. It is essential for synthesizing partially occluded objects with depth-consistent geometry and scale. While existing methods can generate realistic scenes that follow input layouts, they ofte...

---

## 3. Uni-Animator: Towards Unified Visual Colorization

- **arXiv ID**: 2602.23191v1
- **作者**: Xinyuan Chen, Yao Xu, Shaowen Wang, Pengjie Song, Bowen Deng
- **发布日期**: 2026-02-26
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.23191v1](http://arxiv.org/abs/2602.23191v1)
- **PDF**: [http://arxiv.org/pdf/2602.23191v1](http://arxiv.org/pdf/2602.23191v1)
- **摘要**: We propose Uni-Animator, a novel Diffusion Transformer (DiT)-based framework for unified image and video sketch colorization. Existing sketch colorization methods struggle to unify image and video tasks, suffering from imprecise color transfer with single or multiple references, inadequate preservat...

---

## 4. Efficient Encoder-Free Fourier-based 3D Large Multimodal Model

- **arXiv ID**: 2602.23153v1
- **作者**: Guofeng Mei, Wei Lin, Luigi Riz, Yujiao Wu, Yiming Wang 等 (共6位作者)
- **发布日期**: 2026-02-26
- **分类**: cs.CV, cs.AI
- **论文链接**: [http://arxiv.org/abs/2602.23153v1](http://arxiv.org/abs/2602.23153v1)
- **PDF**: [http://arxiv.org/pdf/2602.23153v1](http://arxiv.org/pdf/2602.23153v1)
- **摘要**: Large Multimodal Models (LMMs) that process 3D data typically rely on heavy, pre-trained visual encoders to extract geometric features. While recent 2D LMMs have begun to eliminate such encoders for efficiency and scalability, extending this paradigm to 3D remains challenging due to the unordered an...

---

## 5. TriLite: Efficient Weakly Supervised Object Localization with Universal Visual Features and Tri-Region Disentanglement

- **arXiv ID**: 2602.23120v1
- **作者**: Arian Sabaghi, José Oramas
- **发布日期**: 2026-02-26
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.23120v1](http://arxiv.org/abs/2602.23120v1)
- **PDF**: [http://arxiv.org/pdf/2602.23120v1](http://arxiv.org/pdf/2602.23120v1)
- **摘要**: Weakly supervised object localization (WSOL) aims to localize target objects in images using only image-level labels. Despite recent progress, many approaches still rely on multi-stage pipelines or full fine-tuning of large backbones, which increases training cost, while the broader WSOL community c...

---

## 6. GeoWorld: Geometric World Models

- **arXiv ID**: 2602.23058v1
- **作者**: Zeyu Zhang, Danning Li, Ian Reid, Richard Hartley
- **发布日期**: 2026-02-26
- **分类**: cs.CV, cs.RO
- **论文链接**: [http://arxiv.org/abs/2602.23058v1](http://arxiv.org/abs/2602.23058v1)
- **PDF**: [http://arxiv.org/pdf/2602.23058v1](http://arxiv.org/pdf/2602.23058v1)
- **摘要**: Energy-based predictive world models provide a powerful approach for multi-step visual planning by reasoning over latent energy landscapes rather than generating pixels. However, existing approaches face two major challenges: (i) their latent representations are typically learned in Euclidean space,...

---

## 7. PackUV: Packed Gaussian UV Maps for 4D Volumetric Video

- **arXiv ID**: 2602.23040v1
- **作者**: Aashish Rai, Angela Xing, Anushka Agarwal, Xiaoyan Cong, Zekun Li 等 (共8位作者)
- **发布日期**: 2026-02-26
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.23040v1](http://arxiv.org/abs/2602.23040v1)
- **PDF**: [http://arxiv.org/pdf/2602.23040v1](http://arxiv.org/pdf/2602.23040v1)
- **摘要**: Volumetric videos offer immersive 4D experiences, but remain difficult to reconstruct, store, and stream at scale. Existing Gaussian Splatting based methods achieve high-quality reconstruction but break down on long sequences, temporal inconsistency, and fail under large motions and disocclusions. M...

---

## 8. DMAligner: Enhancing Image Alignment via Diffusion Model Based View Synthesis

- **arXiv ID**: 2602.23022v1
- **作者**: Xinglong Luo, Ao Luo, Zhengning Wang, Yueqi Yang, Chaoyu Feng 等 (共8位作者)
- **发布日期**: 2026-02-26
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.23022v1](http://arxiv.org/abs/2602.23022v1)
- **PDF**: [http://arxiv.org/pdf/2602.23022v1](http://arxiv.org/pdf/2602.23022v1)
- **摘要**: Image alignment is a fundamental task in computer vision with broad applications. Existing methods predominantly employ optical flow-based image warping. However, this technique is susceptible to common challenges such as occlusions and illumination variations, leading to degraded alignment visual q...

---

## 9. SubspaceAD: Training-Free Few-Shot Anomaly Detection via Subspace Modeling

- **arXiv ID**: 2602.23013v1
- **作者**: Camile Lendering, Erkut Akdag, Egor Bondarev
- **发布日期**: 2026-02-26
- **分类**: cs.CV, cs.LG
- **论文链接**: [http://arxiv.org/abs/2602.23013v1](http://arxiv.org/abs/2602.23013v1)
- **PDF**: [http://arxiv.org/pdf/2602.23013v1](http://arxiv.org/pdf/2602.23013v1)
- **摘要**: Detecting visual anomalies in industrial inspection often requires training with only a few normal images per category. Recent few-shot methods achieve strong results employing foundation-model features, but typically rely on memory banks, auxiliary datasets, or multi-modal tuning of vision-language...

---

## 10. OpenFS: Multi-Hand-Capable Fingerspelling Recognition with Implicit Signing-Hand Detection and Frame-Wise Letter-Conditioned Synthesis

- **arXiv ID**: 2602.22949v1
- **作者**: Junuk Cha, Jihyeon Kim, Han-Mu Park
- **发布日期**: 2026-02-26
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.22949v1](http://arxiv.org/abs/2602.22949v1)
- **PDF**: [http://arxiv.org/pdf/2602.22949v1](http://arxiv.org/pdf/2602.22949v1)
- **摘要**: Fingerspelling is a component of sign languages in which words are spelled out letter by letter using specific hand poses. Automatic fingerspelling recognition plays a crucial role in bridging the communication gap between Deaf and hearing communities, yet it remains challenging due to the signing-h...

---

## 11. Towards Multimodal Domain Generalization with Few Labels

- **arXiv ID**: 2602.22917v1
- **作者**: Hongzhao Li, Hao Dong, Hualei Wan, Shupan Li, Mingliang Xu 等 (共6位作者)
- **发布日期**: 2026-02-26
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.22917v1](http://arxiv.org/abs/2602.22917v1)
- **PDF**: [http://arxiv.org/pdf/2602.22917v1](http://arxiv.org/pdf/2602.22917v1)
- **摘要**: Multimodal models ideally should generalize to unseen domains while remaining data-efficient to reduce annotation costs. To this end, we introduce and study a new problem, Semi-Supervised Multimodal Domain Generalization (SSMDG), which aims to learn robust multimodal models from multi-source data wi...

---

## 12. GraspLDP: Towards Generalizable Grasping Policy via Latent Diffusion

- **arXiv ID**: 2602.22862v1
- **作者**: Enda Xiang, Haoxiang Ma, Xinzhu Ma, Zicheng Liu, Di Huang
- **发布日期**: 2026-02-26
- **分类**: cs.RO, cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.22862v1](http://arxiv.org/abs/2602.22862v1)
- **PDF**: [http://arxiv.org/pdf/2602.22862v1](http://arxiv.org/pdf/2602.22862v1)
- **摘要**: This paper focuses on enhancing the grasping precision and generalization of manipulation policies learned via imitation learning. Diffusion-based policy learning methods have recently become the mainstream approach for robotic manipulation tasks. As grasping is a critical subtask in manipulation, t...

---

## 13. Face Time Traveller : Travel Through Ages Without Losing Identity

- **arXiv ID**: 2602.22819v1
- **作者**: Purbayan Kar, Ayush Ghadiya, Vishal Chudasama, Pankaj Wasnik, C. V. Jawahar
- **发布日期**: 2026-02-26
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.22819v1](http://arxiv.org/abs/2602.22819v1)
- **PDF**: [http://arxiv.org/pdf/2602.22819v1](http://arxiv.org/pdf/2602.22819v1)
- **摘要**: Face aging, an ill-posed problem shaped by environmental and genetic factors, is vital in entertainment, forensics, and digital archiving, where realistic age transformations must preserve both identity and visual realism. However, existing works relying on numerical age representations overlook the...

---

## 14. TrajTok: Learning Trajectory Tokens enables better Video Understanding

- **arXiv ID**: 2602.22779v1
- **作者**: Chenhao Zheng, Jieyu Zhang, Jianing Zhang, Weikai Huang, Ashutosh Kumar 等 (共9位作者)
- **发布日期**: 2026-02-26
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.22779v1](http://arxiv.org/abs/2602.22779v1)
- **PDF**: [http://arxiv.org/pdf/2602.22779v1](http://arxiv.org/pdf/2602.22779v1)
- **摘要**: Tokenization in video models, typically through patchification, generates an excessive and redundant number of tokens. This severely limits video efficiency and scalability. While recent trajectory-based tokenizers offer a promising solution by decoupling video duration from token count, they rely o...

---

## 15. HulluEdit: Single-Pass Evidence-Consistent Subspace Editing for Mitigating Hallucinations in Large Vision-Language Models

- **arXiv ID**: 2602.22727v1
- **作者**: Yangguang Lin, Quan Fang, Yufei Li, Jiachen Sun, Junyu Gao 等 (共6位作者)
- **发布日期**: 2026-02-26
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.22727v1](http://arxiv.org/abs/2602.22727v1)
- **PDF**: [http://arxiv.org/pdf/2602.22727v1](http://arxiv.org/pdf/2602.22727v1)
- **摘要**: Object hallucination in Large Vision-Language Models (LVLMs) significantly hinders their reliable deployment. Existing methods struggle to balance efficiency and accuracy: they often require expensive reference models and multiple forward passes, or apply static edits that risk suppressing genuine v...

---

## 16. SoPE: Spherical Coordinate-Based Positional Embedding for Enhancing Spatial Perception of 3D LVLMs

- **arXiv ID**: 2602.22716v1
- **作者**: Guanting Ye, Qiyan Zhao, Wenhao Yu, Liangyu Yuan, Mingkai Li 等 (共10位作者)
- **发布日期**: 2026-02-26
- **分类**: cs.CV, cs.AI
- **论文链接**: [http://arxiv.org/abs/2602.22716v1](http://arxiv.org/abs/2602.22716v1)
- **PDF**: [http://arxiv.org/pdf/2602.22716v1](http://arxiv.org/pdf/2602.22716v1)
- **摘要**: 3D Large Vision-Language Models (3D LVLMs) built upon Large Language Models (LLMs) have achieved remarkable progress across various multimodal tasks. However, their inherited position-dependent modeling mechanism, Rotary Position Embedding (RoPE), remains suboptimal for 3D multimodal understanding. ...

---

## 17. Denoising as Path Planning: Training-Free Acceleration of Diffusion Models with DPCache

- **arXiv ID**: 2602.22654v1
- **作者**: Bowen Cui, Yuanbin Wang, Huajiang Xu, Biaolong Chen, Aixi Zhang 等 (共9位作者)
- **发布日期**: 2026-02-26
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.22654v1](http://arxiv.org/abs/2602.22654v1)
- **PDF**: [http://arxiv.org/pdf/2602.22654v1](http://arxiv.org/pdf/2602.22654v1)
- **摘要**: Diffusion models have demonstrated remarkable success in image and video generation, yet their practical deployment remains hindered by the substantial computational overhead of multi-step iterative sampling. Among acceleration strategies, caching-based methods offer a training-free and effective so...

---

## 18. QuadSync: Quadrifocal Tensor Synchronization via Tucker Decomposition

- **arXiv ID**: 2602.22639v1
- **作者**: Daniel Miao, Gilad Lerman, Joe Kileel
- **发布日期**: 2026-02-26
- **分类**: cs.CV, math.NA, math.OC
- **论文链接**: [http://arxiv.org/abs/2602.22639v1](http://arxiv.org/abs/2602.22639v1)
- **PDF**: [http://arxiv.org/pdf/2602.22639v1](http://arxiv.org/pdf/2602.22639v1)
- **摘要**: In structure from motion, quadrifocal tensors capture more information than their pairwise counterparts (essential matrices), yet they have often been thought of as impractical and only of theoretical interest. In this work, we challenge such beliefs by providing a new framework to recover $n$ camer...

---

## 19. DiffBMP: Differentiable Rendering with Bitmap Primitives

- **arXiv ID**: 2602.22625v1
- **作者**: Seongmin Hong, Junghun James Kim, Daehyeop Kim, Insoo Chung, Se Young Chun
- **发布日期**: 2026-02-26
- **分类**: cs.GR, cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.22625v1](http://arxiv.org/abs/2602.22625v1)
- **PDF**: [http://arxiv.org/pdf/2602.22625v1](http://arxiv.org/pdf/2602.22625v1)
- **摘要**: We introduce DiffBMP, a scalable and efficient differentiable rendering engine for a collection of bitmap images. Our work addresses a limitation that traditional differentiable renderers are constrained to vector graphics, given that most images in the world are bitmaps. Our core contribution is a ...

---

## 20. Coded-E2LF: Coded Aperture Light Field Imaging from Events

- **arXiv ID**: 2602.22620v1
- **作者**: Tomoya Tsuchida, Keita Takahashi, Chihiro Tsutake, Toshiaki Fujii, Hajime Nagahara
- **发布日期**: 2026-02-26
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.22620v1](http://arxiv.org/abs/2602.22620v1)
- **PDF**: [http://arxiv.org/pdf/2602.22620v1](http://arxiv.org/pdf/2602.22620v1)
- **摘要**: We propose Coded-E2LF (coded event to light field), a computational imaging method for acquiring a 4-D light field using a coded aperture and a stationary event-only camera. In a previous work, an imaging system similar to ours was adopted, but both events and intensity images were captured and used...

---

## 21. Causal Motion Diffusion Models for Autoregressive Motion Generation

- **arXiv ID**: 2602.22594v1
- **作者**: Qing Yu, Akihisa Watanabe, Kent Fujiwara
- **发布日期**: 2026-02-26
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.22594v1](http://arxiv.org/abs/2602.22594v1)
- **PDF**: [http://arxiv.org/pdf/2602.22594v1](http://arxiv.org/pdf/2602.22594v1)
- **摘要**: Recent advances in motion diffusion models have substantially improved the realism of human motion synthesis. However, existing approaches either rely on full-sequence diffusion models with bidirectional generation, which limits temporal causality and real-time applicability, or autoregressive model...

---

## 22. No Labels, No Look-Ahead: Unsupervised Online Video Stabilization with Classical Priors

- **arXiv ID**: 2602.23141v1
- **作者**: Tao Liu, Gang Wan, Kan Ren, Shibo Wen
- **发布日期**: 2026-02-26
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.23141v1](http://arxiv.org/abs/2602.23141v1)
- **PDF**: [http://arxiv.org/pdf/2602.23141v1](http://arxiv.org/pdf/2602.23141v1)
- **摘要**: We propose a new unsupervised framework for online video stabilization. Unlike methods based on deep learning that require paired stable and unstable datasets, our approach instantiates the classical stabilization pipeline with three stages and incorporates a multithreaded buffering mechanism. This ...

---

## 23. MSJoE: Jointly Evolving MLLM and Sampler for Efficient Long-Form Video Understanding

- **arXiv ID**: 2602.22932v1
- **作者**: Wenhui Tan, Xiaoyi Yu, Jiaze Li, Yijing Chen, Jianzhong Ju 等 (共8位作者)
- **发布日期**: 2026-02-26
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.22932v1](http://arxiv.org/abs/2602.22932v1)
- **PDF**: [http://arxiv.org/pdf/2602.22932v1](http://arxiv.org/pdf/2602.22932v1)
- **摘要**: Efficiently understanding long-form videos remains a fundamental challenge for multimodal large language models (MLLMs). In this paper, we present MLLM-Sampler Joint Evolution (MSJoE), a novel framework that jointly evolves the MLLM and a lightweight key-frame sampler for efficient long-form video u...

---

## 24. Monocular Open Vocabulary Occupancy Prediction for Indoor Scenes

- **arXiv ID**: 2602.22667v1
- **作者**: Changqing Zhou, Yueru Luo, Han Zhang, Zeyu Jiang, Changhao Chen
- **发布日期**: 2026-02-26
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.22667v1](http://arxiv.org/abs/2602.22667v1)
- **PDF**: [http://arxiv.org/pdf/2602.22667v1](http://arxiv.org/pdf/2602.22667v1)
- **摘要**: Open-vocabulary 3D occupancy is vital for embodied agents, which need to understand complex indoor environments where semantic categories are abundant and evolve beyond fixed taxonomies. While recent work has explored open-vocabulary occupancy in outdoor driving scenarios, such methods transfer poor...

---

## 25. $φ$-DPO: Fairness Direct Preference Optimization Approach to Continual Learning in Large Multimodal Models

- **arXiv ID**: 2602.22601v1
- **作者**: Thanh-Dat Truong, Huu-Thien Tran, Jackson Cothren, Bhiksha Raj, Khoa Luu
- **发布日期**: 2026-02-26
- **分类**: cs.LG, cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.22601v1](http://arxiv.org/abs/2602.22601v1)
- **PDF**: [http://arxiv.org/pdf/2602.22601v1](http://arxiv.org/pdf/2602.22601v1)
- **摘要**: Fairness in Continual Learning for Large Multimodal Models (LMMs) is an emerging yet underexplored challenge, particularly in the presence of imbalanced data distributions that can lead to biased model updates and suboptimal performance across tasks. While recent continual learning studies have made...

---

## 26. GFRRN: Explore the Gaps in Single Image Reflection Removal

- **arXiv ID**: 2602.22695v1
- **作者**: Yu Chen, Zewei He, Xingyu Liu, Zixuan Chen, Zheming Lu
- **发布日期**: 2026-02-26
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.22695v1](http://arxiv.org/abs/2602.22695v1)
- **PDF**: [http://arxiv.org/pdf/2602.22695v1](http://arxiv.org/pdf/2602.22695v1)
- **摘要**: Prior dual-stream methods with the feature interaction mechanism have achieved remarkable performance in single image reflection removal (SIRR). However, they often struggle with (1) semantic understanding gap between the features of pre-trained models and those of reflection removal models, and (2)...

---

## 27. CLIP Is Shortsighted: Paying Attention Beyond the First Sentence

- **arXiv ID**: 2602.22419v1
- **作者**: Marc-Antoine Lavoie, Anas Mahmoud, Aldo Zaimi, Arsene Fansi Tchango, Steven L. Waslander
- **发布日期**: 2026-02-25
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.22419v1](http://arxiv.org/abs/2602.22419v1)
- **PDF**: [http://arxiv.org/pdf/2602.22419v1](http://arxiv.org/pdf/2602.22419v1)
- **摘要**: CLIP models learn transferable multi-modal features via image-text contrastive learning on internet-scale data. They are widely used in zero-shot classification, multi-modal retrieval, text-to-image diffusion, and as image encoders in large vision-language models. However, CLIP's pretraining is domi...

---

## 28. Vision Transformers Need More Than Registers

- **arXiv ID**: 2602.22394v1
- **作者**: Cheng Shi, Yizhou Yu, Sibei Yang
- **发布日期**: 2026-02-25
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.22394v1](http://arxiv.org/abs/2602.22394v1)
- **PDF**: [http://arxiv.org/pdf/2602.22394v1](http://arxiv.org/pdf/2602.22394v1)
- **摘要**: Vision Transformers (ViTs), when pre-trained on large-scale data, provide general-purpose representations for diverse downstream tasks. However, artifacts in ViTs are widely observed across different supervision paradigms and downstream tasks. Through systematic analysis of artifacts in ViTs, we fin...

---

## 29. AeroDGS: Physically Consistent Dynamic Gaussian Splatting for Single-Sequence Aerial 4D Reconstruction

- **arXiv ID**: 2602.22376v1
- **作者**: Hanyang Liu, Rongjun Qin
- **发布日期**: 2026-02-25
- **分类**: cs.CV, cs.AI
- **论文链接**: [http://arxiv.org/abs/2602.22376v1](http://arxiv.org/abs/2602.22376v1)
- **PDF**: [http://arxiv.org/pdf/2602.22376v1](http://arxiv.org/pdf/2602.22376v1)
- **摘要**: Recent advances in 4D scene reconstruction have significantly improved dynamic modeling across various domains. However, existing approaches remain limited under aerial conditions with single-view capture, wide spatial range, and dynamic objects of limited spatial footprint and large motion disparit...

---

## 30. Neu-PiG: Neural Preconditioned Grids for Fast Dynamic Surface Reconstruction on Long Sequences

- **arXiv ID**: 2602.22212v1
- **作者**: Julian Kaltheuner, Hannah Dröge, Markus Plack, Patrick Stotko, Reinhard Klein
- **发布日期**: 2026-02-25
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.22212v1](http://arxiv.org/abs/2602.22212v1)
- **PDF**: [http://arxiv.org/pdf/2602.22212v1](http://arxiv.org/pdf/2602.22212v1)
- **摘要**: Temporally consistent surface reconstruction of dynamic 3D objects from unstructured point cloud data remains challenging, especially for very long sequences. Existing methods either optimize deformations incrementally, risking drift and requiring long runtimes, or rely on complex learned models tha...

---

## 31. WeaveTime: Stream from Earlier Frames into Emergent Memory in VideoLLMs

- **arXiv ID**: 2602.22142v1
- **作者**: Yulin Zhang, Cheng Shi, Sibei Yang
- **发布日期**: 2026-02-25
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.22142v1](http://arxiv.org/abs/2602.22142v1)
- **PDF**: [http://arxiv.org/pdf/2602.22142v1](http://arxiv.org/pdf/2602.22142v1)
- **摘要**: Recent advances in Multimodal Large Language Models have greatly improved visual understanding and reasoning, yet their quadratic attention and offline training protocols make them ill-suited for streaming settings where frames arrive sequentially and future observations are inaccessible. We diagnos...

---

## 32. Lumosaic: Hyperspectral Video via Active Illumination and Coded-Exposure Pixels

- **arXiv ID**: 2602.22140v1
- **作者**: Dhruv Verma, Andrew Qiu, Roberto Rangel, Ayandev Barman, Hao Yang 等 (共11位作者)
- **发布日期**: 2026-02-25
- **分类**: eess.IV, cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.22140v1](http://arxiv.org/abs/2602.22140v1)
- **PDF**: [http://arxiv.org/pdf/2602.22140v1](http://arxiv.org/pdf/2602.22140v1)
- **摘要**: We present Lumosaic, a compact active hyperspectral video system designed for real-time capture of dynamic scenes. Our approach combines a narrowband LED array with a coded-exposure-pixel (CEP) camera capable of high-speed, per-pixel exposure control, enabling joint encoding of scene information acr...

---

## 33. Learning to Drive is a Free Gift: Large-Scale Label-Free Autonomy Pretraining from Unposed In-The-Wild Videos

- **arXiv ID**: 2602.22091v1
- **作者**: Matthew Strong, Wei-Jer Chang, Quentin Herau, Jiezhi Yang, Yihan Hu 等 (共7位作者)
- **发布日期**: 2026-02-25
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.22091v1](http://arxiv.org/abs/2602.22091v1)
- **PDF**: [http://arxiv.org/pdf/2602.22091v1](http://arxiv.org/pdf/2602.22091v1)
- **摘要**: Ego-centric driving videos available online provide an abundant source of visual data for autonomous driving, yet their lack of annotations makes it difficult to learn representations that capture both semantic structure and 3D geometry. Recent advances in large feedforward spatial models demonstrat...

---

## 34. NESTOR: A Nested MOE-based Neural Operator for Large-Scale PDE Pre-Training

- **arXiv ID**: 2602.22059v1
- **作者**: Dengdi Sun, Xiaoya Zhou, Xiao Wang, Hao Si, Wanli Lyu 等 (共7位作者)
- **发布日期**: 2026-02-25
- **分类**: cs.CV, cs.AI
- **论文链接**: [http://arxiv.org/abs/2602.22059v1](http://arxiv.org/abs/2602.22059v1)
- **PDF**: [http://arxiv.org/pdf/2602.22059v1](http://arxiv.org/pdf/2602.22059v1)
- **摘要**: Neural operators have emerged as an efficient paradigm for solving PDEs, overcoming the limitations of traditional numerical methods and significantly improving computational efficiency. However, due to the diversity and complexity of PDE systems, existing neural operators typically rely on a single...

---

## 35. Global-Aware Edge Prioritization for Pose Graph Initialization

- **arXiv ID**: 2602.21963v1
- **作者**: Tong Wei, Giorgos Tolias, Jiri Matas, Daniel Barath
- **发布日期**: 2026-02-25
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.21963v1](http://arxiv.org/abs/2602.21963v1)
- **PDF**: [http://arxiv.org/pdf/2602.21963v1](http://arxiv.org/pdf/2602.21963v1)
- **摘要**: The pose graph is a core component of Structure-from-Motion (SfM), where images act as nodes and edges encode relative poses. Since geometric verification is expensive, SfM pipelines restrict the pose graph to a sparse set of candidate edges, making initialization critical. Existing methods rely on ...

---

## 36. Geometry-as-context: Modulating Explicit 3D in Scene-consistent Video Generation to Geometry Context

- **arXiv ID**: 2602.21929v1
- **作者**: JiaKui Hu, Jialun Liu, Liying Yang, Xinliang Zhang, Kaiwen Li 等 (共10位作者)
- **发布日期**: 2026-02-25
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.21929v1](http://arxiv.org/abs/2602.21929v1)
- **PDF**: [http://arxiv.org/pdf/2602.21929v1](http://arxiv.org/pdf/2602.21929v1)
- **摘要**: Scene-consistent video generation aims to create videos that explore 3D scenes based on a camera trajectory. Previous methods rely on video generation models with external memory for consistency, or iterative 3D reconstruction and inpainting, which accumulate errors during inference due to incorrect...

---

## 37. How to Take a Memorable Picture? Empowering Users with Actionable Feedback

- **arXiv ID**: 2602.21877v1
- **作者**: Francesco Laiti, Davide Talon, Jacopo Staiano, Elisa Ricci
- **发布日期**: 2026-02-25
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.21877v1](http://arxiv.org/abs/2602.21877v1)
- **PDF**: [http://arxiv.org/pdf/2602.21877v1](http://arxiv.org/pdf/2602.21877v1)
- **摘要**: Image memorability, i.e., how likely an image is to be remembered, has traditionally been studied in computer vision either as a passive prediction task, with models regressing a scalar score, or with generative methods altering the visual input to boost the image likelihood of being remembered. Yet...

---

## 38. DynamicGTR: Leveraging Graph Topology Representation Preferences to Boost VLM Capabilities on Graph QAs

- **arXiv ID**: 2602.21864v1
- **作者**: Yanbin Wei, Jiangyue Yan, Chun Kang, Yang Chen, Hua Liu 等 (共7位作者)
- **发布日期**: 2026-02-25
- **分类**: cs.CV, cs.AI, cs.CL
- **论文链接**: [http://arxiv.org/abs/2602.21864v1](http://arxiv.org/abs/2602.21864v1)
- **PDF**: [http://arxiv.org/pdf/2602.21864v1](http://arxiv.org/pdf/2602.21864v1)
- **摘要**: Vision-Language Models (VLMs) have emerged as versatile solutions for zero-shot question answering (QA) across various domains. However, enabling VLMs to effectively comprehend structured graphs and perform accurate, efficient QA remains challenging. Existing approaches typically rely on one single ...

---

## 39. Beyond Static Artifacts: A Forensic Benchmark for Video Deepfake Reasoning in Vision Language Models

- **arXiv ID**: 2602.21779v1
- **作者**: Zheyuan Gu, Qingsong Zhao, Yusong Wang, Zhaohong Huang, Xinqi Li 等 (共9位作者)
- **发布日期**: 2026-02-25
- **分类**: cs.CV, cs.AI
- **论文链接**: [http://arxiv.org/abs/2602.21779v1](http://arxiv.org/abs/2602.21779v1)
- **PDF**: [http://arxiv.org/pdf/2602.21779v1](http://arxiv.org/pdf/2602.21779v1)
- **摘要**: Current Vision-Language Models (VLMs) for deepfake detection excel at identifying spatial artifacts but overlook a critical dimension: temporal inconsistencies in video forgeries. Adapting VLMs to reason about these dynamic cues remains a distinct challenge. To bridge this gap, we propose Forensic A...

---

## 40. LiREC-Net: A Target-Free and Learning-Based Network for LiDAR, RGB, and Event Calibration

- **arXiv ID**: 2602.21754v1
- **作者**: Aditya Ranjan Dash, Ramy Battrawy, René Schuster, Didier Stricker
- **发布日期**: 2026-02-25
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.21754v1](http://arxiv.org/abs/2602.21754v1)
- **PDF**: [http://arxiv.org/pdf/2602.21754v1](http://arxiv.org/pdf/2602.21754v1)
- **摘要**: Advanced autonomous systems rely on multi-sensor fusion for safer and more robust perception. To enable effective fusion, calibrating directly from natural driving scenes (i.e., target-free) with high accuracy is crucial for precise multi-sensor alignment. Existing learning-based calibration methods...

---

## 41. E-comIQ-ZH: A Human-Aligned Dataset and Benchmark for Fine-Grained Evaluation of E-commerce Posters with Chain-of-Thought

- **arXiv ID**: 2602.21698v1
- **作者**: Meiqi Sun, Mingyu Li, Junxiong Zhu
- **发布日期**: 2026-02-25
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.21698v1](http://arxiv.org/abs/2602.21698v1)
- **PDF**: [http://arxiv.org/pdf/2602.21698v1](http://arxiv.org/pdf/2602.21698v1)
- **摘要**: Generative AI is widely used to create commercial posters. However, rapid advances in generation have outpaced automated quality assessment. Existing models emphasize generic esthetics or low level distortions and lack the functional criteria required for e-commerce design. It is especially challeng...

---

## 42. CCCaption: Dual-Reward Reinforcement Learning for Complete and Correct Image Captioning

- **arXiv ID**: 2602.21655v1
- **作者**: Zhijiang Tang, Linhua Wang, Jiaxin Qi, Weihao Jiang, Peng Hou 等 (共7位作者)
- **发布日期**: 2026-02-25
- **分类**: cs.CV, cs.AI
- **论文链接**: [http://arxiv.org/abs/2602.21655v1](http://arxiv.org/abs/2602.21655v1)
- **PDF**: [http://arxiv.org/pdf/2602.21655v1](http://arxiv.org/pdf/2602.21655v1)
- **摘要**: Image captioning remains a fundamental task for vision language understanding, yet ground-truth supervision still relies predominantly on human-annotated references. Because human annotations reflect subjective preferences and expertise, ground-truth captions are often incomplete or even incorrect, ...

---

## 43. Easy3E: Feed-Forward 3D Asset Editing via Rectified Voxel Flow

- **arXiv ID**: 2602.21499v1
- **作者**: Shimin Hu, Yuanyi Wei, Fei Zha, Yudong Guo, Juyong Zhang
- **发布日期**: 2026-02-25
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.21499v1](http://arxiv.org/abs/2602.21499v1)
- **PDF**: [http://arxiv.org/pdf/2602.21499v1](http://arxiv.org/pdf/2602.21499v1)
- **摘要**: Existing 3D editing methods rely on computationally intensive scene-by-scene iterative optimization and suffer from multi-view inconsistency. We propose an effective and fully feedforward 3D editing framework based on the TRELLIS generative backbone, capable of modifying 3D models from a single edit...

---

## 44. CoLoGen: Progressive Learning of Concept-Localization Duality for Unified Image Generation

- **arXiv ID**: 2602.22150v2
- **作者**: YuXin Song, Yu Lu, Haoyuan Sun, Huanjin Yao, Fanglong Liu 等 (共9位作者)
- **发布日期**: 2026-02-25
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.22150v2](http://arxiv.org/abs/2602.22150v2)
- **PDF**: [http://arxiv.org/pdf/2602.22150v2](http://arxiv.org/pdf/2602.22150v2)
- **摘要**: Unified conditional image generation remains difficult because different tasks depend on fundamentally different internal representations. Some require conceptual understanding for semantic synthesis, while others rely on localization cues for spatial precision. Forcing these heterogeneous tasks to ...

---

## 45. RobustVisRAG: Causality-Aware Vision-Based Retrieval-Augmented Generation under Visual Degradations

- **arXiv ID**: 2602.22013v1
- **作者**: I-Hsiang Chen, Yu-Wei Liu, Tse-Yu Wu, Yu-Chien Chiang, Jen-Chien Yang 等 (共6位作者)
- **发布日期**: 2026-02-25
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.22013v1](http://arxiv.org/abs/2602.22013v1)
- **PDF**: [http://arxiv.org/pdf/2602.22013v1](http://arxiv.org/pdf/2602.22013v1)
- **摘要**: Vision-based Retrieval-Augmented Generation (VisRAG) leverages vision-language models (VLMs) to jointly retrieve relevant visual documents and generate grounded answers based on multimodal evidence. However, existing VisRAG models degrade in performance when visual inputs suffer from distortions suc...

---

## 46. MindDriver: Introducing Progressive Multimodal Reasoning for Autonomous Driving

- **arXiv ID**: 2602.21952v1
- **作者**: Lingjun Zhang, Yujian Yuan, Changjie Wu, Xinyuan Chang, Xin Cai 等 (共10位作者)
- **发布日期**: 2026-02-25
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.21952v1](http://arxiv.org/abs/2602.21952v1)
- **PDF**: [http://arxiv.org/pdf/2602.21952v1](http://arxiv.org/pdf/2602.21952v1)
- **摘要**: Vision-Language Models (VLM) exhibit strong reasoning capabilities, showing promise for end-to-end autonomous driving systems. Chain-of-Thought (CoT), as VLM's widely used reasoning strategy, is facing critical challenges. Existing textual CoT has a large gap between text semantic space and trajecto...

---

## 47. OmniZip: Learning a Unified and Lightweight Lossless Compressor for Multi-Modal Data

- **arXiv ID**: 2602.22286v1
- **作者**: Yan Zhao, Zhengxue Cheng, Junxuan Zhang, Dajiang Zhou, Qunshan Gu 等 (共7位作者)
- **发布日期**: 2026-02-25
- **分类**: cs.LG, cs.IT
- **论文链接**: [http://arxiv.org/abs/2602.22286v1](http://arxiv.org/abs/2602.22286v1)
- **PDF**: [http://arxiv.org/pdf/2602.22286v1](http://arxiv.org/pdf/2602.22286v1)
- **摘要**: Lossless compression is essential for efficient data storage and transmission. Although learning-based lossless compressors achieve strong results, most of them are designed for a single modality, leading to redundant compressor deployments in multi-modal settings. Designing a unified multi-modal co...

---

## 48. Joint-Aligned Latent Action: Towards Scalable VLA Pretraining in the Wild

- **arXiv ID**: 2602.21736v1
- **作者**: Hao Luo, Ye Wang, Wanpeng Zhang, Haoqi Yuan, Yicheng Feng 等 (共8位作者)
- **发布日期**: 2026-02-25
- **分类**: cs.RO
- **论文链接**: [http://arxiv.org/abs/2602.21736v1](http://arxiv.org/abs/2602.21736v1)
- **PDF**: [http://arxiv.org/pdf/2602.21736v1](http://arxiv.org/pdf/2602.21736v1)
- **摘要**: Despite progress, Vision-Language-Action models (VLAs) are limited by a scarcity of large-scale, diverse robot data. While human manipulation videos offer a rich alternative, existing methods are forced to choose between small, precisely-labeled datasets and vast in-the-wild footage with unreliable ...

---

## 49. CADC: Content Adaptive Diffusion-Based Generative Image Compression

- **arXiv ID**: 2602.21591v1
- **作者**: Xihua Sheng, Lingyu Zhu, Tianyu Zhang, Dong Liu, Shiqi Wang 等 (共6位作者)
- **发布日期**: 2026-02-25
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.21591v1](http://arxiv.org/abs/2602.21591v1)
- **PDF**: [http://arxiv.org/pdf/2602.21591v1](http://arxiv.org/pdf/2602.21591v1)
- **摘要**: Diffusion-based generative image compression has demonstrated remarkable potential for achieving realistic reconstruction at ultra-low bitrates. The key to unlocking this potential lies in making the entire compression process content-adaptive, ensuring that the encoder's representation and the deco...

---

## 50. Generalizing Visual Geometry Priors to Sparse Gaussian Occupancy Prediction

- **arXiv ID**: 2602.21552v1
- **作者**: Changqing Zhou, Yueru Luo, Changhao Chen
- **发布日期**: 2026-02-25
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.21552v1](http://arxiv.org/abs/2602.21552v1)
- **PDF**: [http://arxiv.org/pdf/2602.21552v1](http://arxiv.org/pdf/2602.21552v1)
- **摘要**: Accurate 3D scene understanding is essential for embodied intelligence, with occupancy prediction emerging as a key task for reasoning about both objects and free space. Existing approaches largely rely on depth priors (e.g., DepthAnything) but make only limited use of 3D cues, restricting performan...

---

## 51. See It, Say It, Sorted: An Iterative Training-Free Framework for Visually-Grounded Multimodal Reasoning in LVLMs

- **arXiv ID**: 2602.21497v1
- **作者**: Yongchang Zhang, Xianzheng Ma, Tianyi Liu, Guangquan Zhou, Yang Chen
- **发布日期**: 2026-02-25
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.21497v1](http://arxiv.org/abs/2602.21497v1)
- **PDF**: [http://arxiv.org/pdf/2602.21497v1](http://arxiv.org/pdf/2602.21497v1)
- **摘要**: Recent large vision-language models (LVLMs) have demonstrated impressive reasoning ability by generating long chain-of-thought (CoT) responses. However, CoT reasoning in multimodal contexts is highly vulnerable to visual hallucination propagation: once an intermediate reasoning step becomes inconsis...

---

## 52. VecGlypher: Unified Vector Glyph Generation with Language Models

- **arXiv ID**: 2602.21461v1
- **作者**: Xiaoke Huang, Bhavul Gauri, Kam Woh Ng, Tony Ng, Mengmeng Xu 等 (共15位作者)
- **发布日期**: 2026-02-25
- **分类**: cs.CL
- **论文链接**: [http://arxiv.org/abs/2602.21461v1](http://arxiv.org/abs/2602.21461v1)
- **PDF**: [http://arxiv.org/pdf/2602.21461v1](http://arxiv.org/pdf/2602.21461v1)
- **摘要**: Vector glyphs are the atomic units of digital typography, yet most learning-based pipelines still depend on carefully curated exemplar sheets and raster-to-vector postprocessing, which limits accessibility and editability. We introduce VecGlypher, a single multimodal language model that generates hi...

---

## 53. Scan Clusters, Not Pixels: A Cluster-Centric Paradigm for Efficient Ultra-high-definition Image Restoration

- **arXiv ID**: 2602.21917v1
- **作者**: Chen Wu, Ling Wang, Zhuoran Zheng, Yuning Cui, Zhixiong Yang 等 (共9位作者)
- **发布日期**: 2026-02-25
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.21917v1](http://arxiv.org/abs/2602.21917v1)
- **PDF**: [http://arxiv.org/pdf/2602.21917v1](http://arxiv.org/pdf/2602.21917v1)
- **摘要**: Ultra-High-Definition (UHD) image restoration is trapped in a scalability crisis: existing models, bound to pixel-wise operations, demand unsustainable computation. While state space models (SSMs) like Mamba promise linear complexity, their pixel-serial scanning remains a fundamental bottleneck for ...

---

## 54. FedVG: Gradient-Guided Aggregation for Enhanced Federated Learning

- **arXiv ID**: 2602.21399v1
- **作者**: Alina Devkota, Jacob Thrasher, Donald Adjeroh, Binod Bhattarai, Prashnna K. Gyawali
- **发布日期**: 2026-02-24
- **分类**: cs.LG, cs.AI, cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.21399v1](http://arxiv.org/abs/2602.21399v1)
- **PDF**: [http://arxiv.org/pdf/2602.21399v1](http://arxiv.org/pdf/2602.21399v1)
- **摘要**: Federated Learning (FL) enables collaborative model training across multiple clients without sharing their private data. However, data heterogeneity across clients leads to client drift, which degrades the overall generalization performance of the model. This effect is further compounded by overemph...

---

## 55. Momentum Memory for Knowledge Distillation in Computational Pathology

- **arXiv ID**: 2602.21395v1
- **作者**: Yongxin Guo, Hao Lu, Onur C. Koyun, Zhengjie Zhu, Muhammet Fatih Demir 等 (共6位作者)
- **发布日期**: 2026-02-24
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.21395v1](http://arxiv.org/abs/2602.21395v1)
- **PDF**: [http://arxiv.org/pdf/2602.21395v1](http://arxiv.org/pdf/2602.21395v1)
- **摘要**: Multimodal learning that integrates genomics and histopathology has shown strong potential in cancer diagnosis, yet its clinical translation is hindered by the limited availability of paired histology-genomics data. Knowledge distillation (KD) offers a practical solution by transferring genomic supe...

---

## 56. NoRD: A Data-Efficient Vision-Language-Action Model that Drives without Reasoning

- **arXiv ID**: 2602.21172v2
- **作者**: Ishaan Rawal, Shubh Gupta, Yihan Hu, Wei Zhan
- **发布日期**: 2026-02-24
- **分类**: cs.AI, cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.21172v2](http://arxiv.org/abs/2602.21172v2)
- **PDF**: [http://arxiv.org/pdf/2602.21172v2](http://arxiv.org/pdf/2602.21172v2)
- **摘要**: Vision-Language-Action (VLA) models are advancing autonomous driving by replacing modular pipelines with unified end-to-end architectures. However, current VLAs face two expensive requirements: (1) massive dataset collection, and (2) dense reasoning annotations. In this work, we address both challen...

---

## 57. BrepGaussian: CAD reconstruction from Multi-View Images with Gaussian Splatting

- **arXiv ID**: 2602.21105v1
- **作者**: Jiaxing Yu, Dongyang Ren, Hangyu Xu, Zhouyuxiao Yang, Yuanqi Li 等 (共8位作者)
- **发布日期**: 2026-02-24
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.21105v1](http://arxiv.org/abs/2602.21105v1)
- **PDF**: [http://arxiv.org/pdf/2602.21105v1](http://arxiv.org/pdf/2602.21105v1)
- **摘要**: The boundary representation (B-rep) models a 3D solid as its explicit boundaries: trimmed corners, edges, and faces. Recovering B-rep representation from unstructured data is a challenging and valuable task of computer vision and graphics. Recent advances in deep learning have greatly improved the r...

---

## 58. ProxyFL: A Proxy-Guided Framework for Federated Semi-Supervised Learning

- **arXiv ID**: 2602.21078v1
- **作者**: Duowen Chen, Yan Wang
- **发布日期**: 2026-02-24
- **分类**: cs.LG, cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.21078v1](http://arxiv.org/abs/2602.21078v1)
- **PDF**: [http://arxiv.org/pdf/2602.21078v1](http://arxiv.org/pdf/2602.21078v1)
- **摘要**: Federated Semi-Supervised Learning (FSSL) aims to collaboratively train a global model across clients by leveraging partially-annotated local data in a privacy-preserving manner. In FSSL, data heterogeneity is a challenging issue, which exists both across clients and within clients. External heterog...

---

## 59. Olbedo: An Albedo and Shading Aerial Dataset for Large-Scale Outdoor Environments

- **arXiv ID**: 2602.22025v1
- **作者**: Shuang Song, Debao Huang, Deyan Deng, Haolin Xiong, Yang Tang 等 (共7位作者)
- **发布日期**: 2026-02-24
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.22025v1](http://arxiv.org/abs/2602.22025v1)
- **PDF**: [http://arxiv.org/pdf/2602.22025v1](http://arxiv.org/pdf/2602.22025v1)
- **摘要**: Intrinsic image decomposition (IID) of outdoor scenes is crucial for relighting, editing, and understanding large-scale environments, but progress has been limited by the lack of real-world datasets with reliable albedo and shading supervision. We introduce Olbedo, a large-scale aerial dataset for o...

---

## 60. Cycle-Consistent Tuning for Layered Image Decomposition

- **arXiv ID**: 2602.20989v1
- **作者**: Zheng Gu, Min Lu, Zhida Sun, Dani Lischinski, Daniel Cohen-O 等 (共6位作者)
- **发布日期**: 2026-02-24
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.20989v1](http://arxiv.org/abs/2602.20989v1)
- **PDF**: [http://arxiv.org/pdf/2602.20989v1](http://arxiv.org/pdf/2602.20989v1)
- **摘要**: Disentangling visual layers in real-world images is a persistent challenge in vision and graphics, as such layers often involve non-linear and globally coupled interactions, including shading, reflection, and perspective distortion. In this work, we present an in-context image decomposition framewor...

---

## 61. EW-DETR: Evolving World Object Detection via Incremental Low-Rank DEtection TRansformer

- **arXiv ID**: 2602.20985v1
- **作者**: Munish Monga, Vishal Chudasama, Pankaj Wasnik, C. V. Jawahar
- **发布日期**: 2026-02-24
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.20985v1](http://arxiv.org/abs/2602.20985v1)
- **PDF**: [http://arxiv.org/pdf/2602.20985v1](http://arxiv.org/pdf/2602.20985v1)
- **摘要**: Real-world object detection must operate in evolving environments where new classes emerge, domains shift, and unseen objects must be identified as "unknown": all without accessing prior data. We introduce Evolving World Object Detection (EWOD), a paradigm coupling incremental learning, domain adapt...

---

## 62. Echoes Over Time: Unlocking Length Generalization in Video-to-Audio Generation Models

- **arXiv ID**: 2602.20981v2
- **作者**: Christian Simon, Masato Ishii, Wei-Yao Wang, Koichi Saito, Akio Hayakawa 等 (共11位作者)
- **发布日期**: 2026-02-24
- **分类**: cs.CV, cs.AI
- **论文链接**: [http://arxiv.org/abs/2602.20981v2](http://arxiv.org/abs/2602.20981v2)
- **PDF**: [http://arxiv.org/pdf/2602.20981v2](http://arxiv.org/pdf/2602.20981v2)
- **摘要**: Scaling multimodal alignment between video and audio is challenging, particularly due to limited data and the mismatch between text descriptions and frame-level video information. In this work, we tackle the scaling challenge in multimodal-to-audio generation, examining whether models trained on sho...

---

## 63. Dropping Anchor and Spherical Harmonics for Sparse-view Gaussian Splatting

- **arXiv ID**: 2602.20933v1
- **作者**: Shuangkang Fang, I-Chao Shen, Xuanyang Zhang, Zesheng Wang, Yufeng Wang 等 (共8位作者)
- **发布日期**: 2026-02-24
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.20933v1](http://arxiv.org/abs/2602.20933v1)
- **PDF**: [http://arxiv.org/pdf/2602.20933v1](http://arxiv.org/pdf/2602.20933v1)
- **摘要**: Recent 3D Gaussian Splatting (3DGS) Dropout methods address overfitting under sparse-view conditions by randomly nullifying Gaussian opacities. However, we identify a neighbor compensation effect in these approaches: dropped Gaussians are often compensated by their neighbors, weakening the intended ...

---

## 64. LongVideo-R1: Smart Navigation for Low-cost Long Video Understanding

- **arXiv ID**: 2602.20913v1
- **作者**: Jihao Qiu, Lingxi Xie, Xinyue Huo, Qi Tian, Qixiang Ye
- **发布日期**: 2026-02-24
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.20913v1](http://arxiv.org/abs/2602.20913v1)
- **PDF**: [http://arxiv.org/pdf/2602.20913v1](http://arxiv.org/pdf/2602.20913v1)
- **摘要**: This paper addresses the critical and underexplored challenge of long video understanding with low computational budgets. We propose LongVideo-R1, an active, reasoning-equipped multimodal large language model (MLLM) agent designed for efficient video context navigation, avoiding the redundancy of ex...

---

## 65. TextPecker: Rewarding Structural Anomaly Quantification for Enhancing Visual Text Rendering

- **arXiv ID**: 2602.20903v3
- **作者**: Hanshen Zhu, Yuliang Liu, Xuecheng Wu, An-Lan Wang, Hao Feng 等 (共10位作者)
- **发布日期**: 2026-02-24
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.20903v3](http://arxiv.org/abs/2602.20903v3)
- **PDF**: [http://arxiv.org/pdf/2602.20903v3](http://arxiv.org/pdf/2602.20903v3)
- **摘要**: Visual Text Rendering (VTR) remains a critical challenge in text-to-image generation, where even advanced models frequently produce text with structural anomalies such as distortion, blurriness, and misalignment. However, we find that leading MLLMs and specialist OCR models largely fail to perceive ...

---

## 66. SpatiaLQA: A Benchmark for Evaluating Spatial Logical Reasoning in Vision-Language Models

- **arXiv ID**: 2602.20901v1
- **作者**: Yuechen Xie, Xiaoyan Zhang, Yicheng Shan, Hao Zhu, Rui Tang 等 (共9位作者)
- **发布日期**: 2026-02-24
- **分类**: cs.CV, cs.LG
- **论文链接**: [http://arxiv.org/abs/2602.20901v1](http://arxiv.org/abs/2602.20901v1)
- **PDF**: [http://arxiv.org/pdf/2602.20901v1](http://arxiv.org/pdf/2602.20901v1)
- **摘要**: Vision-Language Models (VLMs) have been increasingly applied in real-world scenarios due to their outstanding understanding and reasoning capabilities. Although VLMs have already demonstrated impressive capabilities in common visual question answering and logical reasoning, they still lack the abili...

---

## 67. When Safety Collides: Resolving Multi-Category Harmful Conflicts in Text-to-Image Diffusion via Adaptive Safety Guidance

- **arXiv ID**: 2602.20880v2
- **作者**: Yongli Xiang, Ziming Hong, Zhaoqing Wang, Xiangyu Zhao, Bo Han 等 (共6位作者)
- **发布日期**: 2026-02-24
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.20880v2](http://arxiv.org/abs/2602.20880v2)
- **PDF**: [http://arxiv.org/pdf/2602.20880v2](http://arxiv.org/pdf/2602.20880v2)
- **摘要**: Text-to-Image (T2I) diffusion models have demonstrated significant advancements in generating high-quality images, while raising potential safety concerns regarding harmful content generation. Safety-guidance-based methods have been proposed to mitigate harmful outputs by steering generation away fr...

---

## 68. MUSE: Harnessing Precise and Diverse Semantics for Few-Shot Whole Slide Image Classification

- **arXiv ID**: 2602.20873v1
- **作者**: Jiahao Xu, Sheng Huang, Xin Zhang, Zhixiong Nan, Jiajun Dong 等 (共6位作者)
- **发布日期**: 2026-02-24
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.20873v1](http://arxiv.org/abs/2602.20873v1)
- **PDF**: [http://arxiv.org/pdf/2602.20873v1](http://arxiv.org/pdf/2602.20873v1)
- **摘要**: In computational pathology, few-shot whole slide image classification is primarily driven by the extreme scarcity of expert-labeled slides. Recent vision-language methods incorporate textual semantics generated by large language models, but treat these descriptions as static class-level priors that ...

---

## 69. GeCo-SRT: Geometry-aware Continual Adaptation for Robotic Cross-Task Sim-to-Real Transfer

- **arXiv ID**: 2602.20871v2
- **作者**: Wenbo Yu, Wenke Xia, Weitao Zhang, Di Hu
- **发布日期**: 2026-02-24
- **分类**: cs.RO
- **论文链接**: [http://arxiv.org/abs/2602.20871v2](http://arxiv.org/abs/2602.20871v2)
- **PDF**: [http://arxiv.org/pdf/2602.20871v2](http://arxiv.org/pdf/2602.20871v2)
- **摘要**: Bridging the sim-to-real gap is important for applying low-cost simulation data to real-world robotic systems. However, previous methods are severely limited by treating each transfer as an isolated endeavor, demanding repeated, costly tuning and wasting prior transfer experience. To move beyond iso...

---

## 70. VGGDrive: Empowering Vision-Language Models with Cross-View Geometric Grounding for Autonomous Driving

- **arXiv ID**: 2602.20794v1
- **作者**: Jie Wang, Guang Li, Zhijian Huang, Chenxu Dang, Hangjun Ye 等 (共7位作者)
- **发布日期**: 2026-02-24
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.20794v1](http://arxiv.org/abs/2602.20794v1)
- **PDF**: [http://arxiv.org/pdf/2602.20794v1](http://arxiv.org/pdf/2602.20794v1)
- **摘要**: The significance of cross-view 3D geometric modeling capabilities for autonomous driving is self-evident, yet existing Vision-Language Models (VLMs) inherently lack this capability, resulting in their mediocre performance. While some promising approaches attempt to mitigate this by constructing Q&A ...

---

## 71. SIMSPINE: A Biomechanics-Aware Simulation Framework for 3D Spine Motion Annotation and Benchmarking

- **arXiv ID**: 2602.20792v1
- **作者**: Muhammad Saif Ullah Khan, Didier Stricker
- **发布日期**: 2026-02-24
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.20792v1](http://arxiv.org/abs/2602.20792v1)
- **PDF**: [http://arxiv.org/pdf/2602.20792v1](http://arxiv.org/pdf/2602.20792v1)
- **摘要**: Modeling spinal motion is fundamental to understanding human biomechanics, yet remains underexplored in computer vision due to the spine's complex multi-joint kinematics and the lack of large-scale 3D annotations. We present a biomechanics-aware keypoint simulation framework that augments existing h...

---

## 72. MatchED: Crisp Edge Detection Using End-to-End, Matching-based Supervision

- **arXiv ID**: 2602.20689v1
- **作者**: Bedrettin Cetinkaya, Sinan Kalkan, Emre Akbas
- **发布日期**: 2026-02-24
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.20689v1](http://arxiv.org/abs/2602.20689v1)
- **PDF**: [http://arxiv.org/pdf/2602.20689v1](http://arxiv.org/pdf/2602.20689v1)
- **摘要**: Generating crisp, i.e., one-pixel-wide, edge maps remains one of the fundamental challenges in edge detection, affecting both traditional and learning-based methods. To obtain crisp edges, most existing approaches rely on two hand-crafted post-processing algorithms, Non-Maximum Suppression (NMS) and...

---

## 73. RAYNOVA: Scale-Temporal Autoregressive World Modeling in Ray Space

- **arXiv ID**: 2602.20685v2
- **作者**: Yichen Xie, Chensheng Peng, Mazen Abdelfattah, Yihan Hu, Jiezhi Yang 等 (共9位作者)
- **发布日期**: 2026-02-24
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.20685v2](http://arxiv.org/abs/2602.20685v2)
- **PDF**: [http://arxiv.org/pdf/2602.20685v2](http://arxiv.org/pdf/2602.20685v2)
- **摘要**: World foundation models aim to simulate the evolution of the real world with physically plausible behavior. Unlike prior methods that handle spatial and temporal correlations separately, we propose RAYNOVA, a geometry-agonistic multiview world model for driving scenarios that employs a dual-causal a...

---

## 74. RecoverMark: Robust Watermarking for Localization and Recovery of Manipulated Faces

- **arXiv ID**: 2602.20618v1
- **作者**: Haonan An, Xiaohui Ye, Guang Hua, Yihang Tao, Hangcheng Cao 等 (共7位作者)
- **发布日期**: 2026-02-24
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.20618v1](http://arxiv.org/abs/2602.20618v1)
- **PDF**: [http://arxiv.org/pdf/2602.20618v1](http://arxiv.org/pdf/2602.20618v1)
- **摘要**: The proliferation of AI-generated content has facilitated sophisticated face manipulation, severely undermining visual integrity and posing unprecedented challenges to intellectual property. In response, a common proactive defense leverages fragile watermarks to detect, localize, or even recover man...

---

## 75. PFGNet: A Fully Convolutional Frequency-Guided Peripheral Gating Network for Efficient Spatiotemporal Predictive Learning

- **arXiv ID**: 2602.20537v1
- **作者**: Xinyong Cai, Changbin Sun, Yong Wang, Hongyu Yang, Yuankai Wu
- **发布日期**: 2026-02-24
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.20537v1](http://arxiv.org/abs/2602.20537v1)
- **PDF**: [http://arxiv.org/pdf/2602.20537v1](http://arxiv.org/pdf/2602.20537v1)
- **摘要**: Spatiotemporal predictive learning (STPL) aims to forecast future frames from past observations and is essential across a wide range of applications. Compared with recurrent or hybrid architectures, pure convolutional models offer superior efficiency and full parallelism, yet their fixed receptive f...

---

## 76. Probing and Bridging Geometry-Interaction Cues for Affordance Reasoning in Vision Foundation Models

- **arXiv ID**: 2602.20501v1
- **作者**: Qing Zhang, Xuesong Li, Jing Zhang
- **发布日期**: 2026-02-24
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.20501v1](http://arxiv.org/abs/2602.20501v1)
- **PDF**: [http://arxiv.org/pdf/2602.20501v1](http://arxiv.org/pdf/2602.20501v1)
- **摘要**: What does it mean for a visual system to truly understand affordance? We argue that this understanding hinges on two complementary capacities: geometric perception, which identifies the structural parts of objects that enable interaction, and interaction perception, which models how an agent's actio...

---

## 77. Pip-Stereo: Progressive Iterations Pruner for Iterative Optimization based Stereo Matching

- **arXiv ID**: 2602.20496v1
- **作者**: Jintu Zheng, Qizhe Liu, HuangXin Xu, Zhuojie Chen
- **发布日期**: 2026-02-24
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.20496v1](http://arxiv.org/abs/2602.20496v1)
- **PDF**: [http://arxiv.org/pdf/2602.20496v1](http://arxiv.org/pdf/2602.20496v1)
- **摘要**: While iterative stereo matching achieves high accuracy, its dependence on Recurrent Neural Networks (RNN) hinders edge deployment, a challenge underexplored in existing researches. We analyze iterative refinement and reveal that disparity updates are spatially sparse and temporally redundant. First,...

---

## 78. StoryTailor:A Zero-Shot Pipeline for Action-Rich Multi-Subject Visual Narratives

- **arXiv ID**: 2602.21273v1
- **作者**: Jinghao Hu, Yuhe Zhang, GuoHua Geng, Kang Li, Han Zhang
- **发布日期**: 2026-02-24
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.21273v1](http://arxiv.org/abs/2602.21273v1)
- **PDF**: [http://arxiv.org/pdf/2602.21273v1](http://arxiv.org/pdf/2602.21273v1)
- **摘要**: Generating multi-frame, action-rich visual narratives without fine-tuning faces a threefold tension: action text faithfulness, subject identity fidelity, and cross-frame background continuity. We propose StoryTailor, a zero-shot pipeline that runs on a single RTX 4090 (24 GB) and produces temporally...

---

## 79. MedCLIPSeg: Probabilistic Vision-Language Adaptation for Data-Efficient and Generalizable Medical Image Segmentation

- **arXiv ID**: 2602.20423v1
- **作者**: Taha Koleilat, Hojat Asgariandehkordi, Omid Nejati Manzari, Berardino Barile, Yiming Xiao 等 (共6位作者)
- **发布日期**: 2026-02-23
- **分类**: cs.CV, cs.CL
- **论文链接**: [http://arxiv.org/abs/2602.20423v1](http://arxiv.org/abs/2602.20423v1)
- **PDF**: [http://arxiv.org/pdf/2602.20423v1](http://arxiv.org/pdf/2602.20423v1)
- **摘要**: Medical image segmentation remains challenging due to limited annotations for training, ambiguous anatomical features, and domain shifts. While vision-language models such as CLIP offer strong cross-modal representations, their potential for dense, text-guided medical image segmentation remains unde...

---

## 80. gQIR: Generative Quanta Image Reconstruction

- **arXiv ID**: 2602.20417v1
- **作者**: Aryan Garg, Sizhuo Ma, Mohit Gupta
- **发布日期**: 2026-02-23
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.20417v1](http://arxiv.org/abs/2602.20417v1)
- **PDF**: [http://arxiv.org/pdf/2602.20417v1](http://arxiv.org/pdf/2602.20417v1)
- **摘要**: Capturing high-quality images from only a few detected photons is a fundamental challenge in computational imaging. Single-photon avalanche diode (SPAD) sensors promise high-quality imaging in regimes where conventional cameras fail, but raw \emph{quanta frames} contain only sparse, noisy, binary ph...

---

## 81. SimLBR: Learning to Detect Fake Images by Learning to Detect Real Images

- **arXiv ID**: 2602.20412v1
- **作者**: Aayush Dhakal, Subash Khanal, Srikumar Sastry, Jacob Arndt, Philipe Ambrozio Dias 等 (共7位作者)
- **发布日期**: 2026-02-23
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.20412v1](http://arxiv.org/abs/2602.20412v1)
- **PDF**: [http://arxiv.org/pdf/2602.20412v1](http://arxiv.org/pdf/2602.20412v1)
- **摘要**: The rapid advancement of generative models has made the detection of AI-generated images a critical challenge for both research and society. Recent works have shown that most state-of-the-art fake image detection methods overfit to their training data and catastrophically fail when evaluated on cura...

---

## 82. CLIPoint3D: Language-Grounded Few-Shot Unsupervised 3D Point Cloud Domain Adaptation

- **arXiv ID**: 2602.20409v1
- **作者**: Mainak Singha, Sarthak Mehrotra, Paolo Casari, Subhasis Chaudhuri, Elisa Ricci 等 (共6位作者)
- **发布日期**: 2026-02-23
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.20409v1](http://arxiv.org/abs/2602.20409v1)
- **PDF**: [http://arxiv.org/pdf/2602.20409v1](http://arxiv.org/pdf/2602.20409v1)
- **摘要**: Recent vision-language models (VLMs) such as CLIP demonstrate impressive cross-modal reasoning, extending beyond images to 3D perception. Yet, these models remain fragile under domain shifts, especially when adapting from synthetic to real-world point clouds. Conventional 3D domain adaptation approa...

---

## 83. Circuit Tracing in Vision-Language Models: Understanding the Internal Mechanisms of Multimodal Thinking

- **arXiv ID**: 2602.20330v1
- **作者**: Jingcheng Yang, Tianhu Xiong, Shengyi Qian, Klara Nahrstedt, Mingyuan Wu
- **发布日期**: 2026-02-23
- **分类**: cs.CV, cs.AI, cs.LG
- **论文链接**: [http://arxiv.org/abs/2602.20330v1](http://arxiv.org/abs/2602.20330v1)
- **PDF**: [http://arxiv.org/pdf/2602.20330v1](http://arxiv.org/pdf/2602.20330v1)
- **摘要**: Vision-language models (VLMs) are powerful but remain opaque black boxes. We introduce the first framework for transparent circuit tracing in VLMs to systematically analyze multimodal reasoning. By utilizing transcoders, attribution graphs, and attention-based methods, we uncover how VLMs hierarchic...

---

## 84. tttLRM: Test-Time Training for Long Context and Autoregressive 3D Reconstruction

- **arXiv ID**: 2602.20160v1
- **作者**: Chen Wang, Hao Tan, Wang Yifan, Zhiqin Chen, Yuheng Liu 等 (共9位作者)
- **发布日期**: 2026-02-23
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.20160v1](http://arxiv.org/abs/2602.20160v1)
- **PDF**: [http://arxiv.org/pdf/2602.20160v1](http://arxiv.org/pdf/2602.20160v1)
- **摘要**: We propose tttLRM, a novel large 3D reconstruction model that leverages a Test-Time Training (TTT) layer to enable long-context, autoregressive 3D reconstruction with linear computational complexity, further scaling the model's capability. Our framework efficiently compresses multiple image observat...

---

## 85. Flow3r: Factored Flow Prediction for Scalable Visual Geometry Learning

- **arXiv ID**: 2602.20157v1
- **作者**: Zhongxiao Cong, Qitao Zhao, Minsik Jeon, Shubham Tulsiani
- **发布日期**: 2026-02-23
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.20157v1](http://arxiv.org/abs/2602.20157v1)
- **PDF**: [http://arxiv.org/pdf/2602.20157v1](http://arxiv.org/pdf/2602.20157v1)
- **摘要**: Current feed-forward 3D/4D reconstruction systems rely on dense geometry and pose supervision -- expensive to obtain at scale and particularly scarce for dynamic real-world scenes. We present Flow3r, a framework that augments visual geometry learning with dense 2D correspondences (`flow') as supervi...

---

## 86. StruXLIP: Enhancing Vision-language Models with Multimodal Structural Cues

- **arXiv ID**: 2602.20089v2
- **作者**: Zanxi Ruan, Qiuyu Kong, Songqun Gao, Yiming Wang, Marco Cristani
- **发布日期**: 2026-02-23
- **分类**: cs.CV, cs.AI
- **论文链接**: [http://arxiv.org/abs/2602.20089v2](http://arxiv.org/abs/2602.20089v2)
- **PDF**: [http://arxiv.org/pdf/2602.20089v2](http://arxiv.org/pdf/2602.20089v2)
- **摘要**: Edge-based representations are fundamental cues for visual understanding, a principle rooted in early vision research and still central today. We extend this principle to vision-language alignment, showing that isolating and aligning structural cues across modalities can greatly benefit fine-tuning ...

---

## 87. Decoupling Defense Strategies for Robust Image Watermarking

- **arXiv ID**: 2602.20053v1
- **作者**: Jiahui Chen, Zehang Deng, Zeyu Zhang, Chaoyang Li, Lianchen Jia 等 (共6位作者)
- **发布日期**: 2026-02-23
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.20053v1](http://arxiv.org/abs/2602.20053v1)
- **PDF**: [http://arxiv.org/pdf/2602.20053v1](http://arxiv.org/pdf/2602.20053v1)
- **摘要**: Deep learning-based image watermarking, while robust against conventional distortions, remains vulnerable to advanced adversarial and regeneration attacks. Conventional countermeasures, which jointly optimize the encoder and decoder via a noise layer, face 2 inevitable challenges: (1) decrease of cl...

---

## 88. Discover, Segment, and Select: A Progressive Mechanism for Zero-shot Camouflaged Object Segmentation

- **arXiv ID**: 2602.19944v1
- **作者**: Yilong Yang, Jianxin Tian, Shengchuan Zhang, Liujuan Cao
- **发布日期**: 2026-02-23
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.19944v1](http://arxiv.org/abs/2602.19944v1)
- **PDF**: [http://arxiv.org/pdf/2602.19944v1](http://arxiv.org/pdf/2602.19944v1)
- **摘要**: Current zero-shot Camouflaged Object Segmentation methods typically employ a two-stage pipeline (discover-then-segment): using MLLMs to obtain visual prompts, followed by SAM segmentation. However, relying solely on MLLMs for camouflaged object discovery often leads to inaccurate localization, false...

---

## 89. Multi-Modal Representation Learning via Semi-Supervised Rate Reduction for Generalized Category Discovery

- **arXiv ID**: 2602.19910v1
- **作者**: Wei He, Xianghan Meng, Zhiyuan Huang, Xianbiao Qi, Rong Xiao 等 (共6位作者)
- **发布日期**: 2026-02-23
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.19910v1](http://arxiv.org/abs/2602.19910v1)
- **PDF**: [http://arxiv.org/pdf/2602.19910v1](http://arxiv.org/pdf/2602.19910v1)
- **摘要**: Generalized Category Discovery (GCD) aims to identify both known and unknown categories, with only partial labels given for the known categories, posing a challenging open-set recognition problem. State-of-the-art approaches for GCD task are usually built on multi-modality representation learning, w...

---

## 90. ExpPortrait: Expressive Portrait Generation via Personalized Representation

- **arXiv ID**: 2602.19900v1
- **作者**: Junyi Wang, Yudong Guo, Boyang Guo, Shengming Yang, Juyong Zhang
- **发布日期**: 2026-02-23
- **分类**: cs.CV, cs.GR
- **论文链接**: [http://arxiv.org/abs/2602.19900v1](http://arxiv.org/abs/2602.19900v1)
- **PDF**: [http://arxiv.org/pdf/2602.19900v1](http://arxiv.org/pdf/2602.19900v1)
- **摘要**: While diffusion models have shown great potential in portrait generation, generating expressive, coherent, and controllable cinematic portrait videos remains a significant challenge. Existing intermediate signals for portrait generation, such as 2D landmarks and parametric models, have limited disen...

---

## 91. Brewing Stronger Features: Dual-Teacher Distillation for Multispectral Earth Observation

- **arXiv ID**: 2602.19863v2
- **作者**: Filip Wolf, Blaž Rolih, Luka Čehovin Zajc
- **发布日期**: 2026-02-23
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.19863v2](http://arxiv.org/abs/2602.19863v2)
- **PDF**: [http://arxiv.org/pdf/2602.19863v2](http://arxiv.org/pdf/2602.19863v2)
- **摘要**: Foundation models are transforming Earth Observation (EO), yet the diversity of EO sensors and modalities makes a single universal model unrealistic. Multiple specialized EO foundation models (EOFMs) will likely coexist, making efficient knowledge transfer across modalities essential. Most existing ...

---

## 92. MultiModalPFN: Extending Prior-Data Fitted Networks for Multimodal Tabular Learning

- **arXiv ID**: 2602.20223v2
- **作者**: Wall Kim, Chaeyoung Song, Hanul Kim
- **发布日期**: 2026-02-23
- **分类**: cs.LG, cs.AI
- **论文链接**: [http://arxiv.org/abs/2602.20223v2](http://arxiv.org/abs/2602.20223v2)
- **PDF**: [http://arxiv.org/pdf/2602.20223v2](http://arxiv.org/pdf/2602.20223v2)
- **摘要**: Recently, TabPFN has gained attention as a foundation model for tabular data. However, it struggles to integrate heterogeneous modalities such as images and text, which are common in domains like healthcare and marketing, thereby limiting its applicability. To address this, we present the Multi-Moda...

---

## 93. RAP: Fast Feedforward Rendering-Free Attribute-Guided Primitive Importance Score Prediction for Efficient 3D Gaussian Splatting Processing

- **arXiv ID**: 2602.19753v1
- **作者**: Kaifa Yang, Qi Yang, Yiling Xu, Zhu Li
- **发布日期**: 2026-02-23
- **分类**: cs.CV, cs.GR
- **论文链接**: [http://arxiv.org/abs/2602.19753v1](http://arxiv.org/abs/2602.19753v1)
- **PDF**: [http://arxiv.org/pdf/2602.19753v1](http://arxiv.org/pdf/2602.19753v1)
- **摘要**: 3D Gaussian Splatting (3DGS) has emerged as a leading technology for high-quality 3D scene reconstruction. However, the iterative refinement and densification process leads to the generation of a large number of primitives, each contributing to the reconstruction to a substantially different extent....

---

## 94. Pixels Don't Lie (But Your Detector Might): Bootstrapping MLLM-as-a-Judge for Trustworthy Deepfake Detection and Reasoning Supervision

- **arXiv ID**: 2602.19715v1
- **作者**: Kartik Kuckreja, Parul Gupta, Muhammad Haris Khan, Abhinav Dhall
- **发布日期**: 2026-02-23
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.19715v1](http://arxiv.org/abs/2602.19715v1)
- **PDF**: [http://arxiv.org/pdf/2602.19715v1](http://arxiv.org/pdf/2602.19715v1)
- **摘要**: Deepfake detection models often generate natural-language explanations, yet their reasoning is frequently ungrounded in visual evidence, limiting reliability. Existing evaluations measure classification accuracy but overlook reasoning fidelity. We propose DeepfakeJudge, a framework for scalable reas...

---

## 95. TeHOR: Text-Guided 3D Human and Object Reconstruction with Textures

- **arXiv ID**: 2602.19679v1
- **作者**: Hyeongjin Nam, Daniel Sungho Jung, Kyoung Mu Lee
- **发布日期**: 2026-02-23
- **分类**: cs.CV, cs.AI
- **论文链接**: [http://arxiv.org/abs/2602.19679v1](http://arxiv.org/abs/2602.19679v1)
- **PDF**: [http://arxiv.org/pdf/2602.19679v1](http://arxiv.org/pdf/2602.19679v1)
- **摘要**: Joint reconstruction of 3D human and object from a single image is an active research area, with pivotal applications in robotics and digital content creation. Despite recent advances, existing approaches suffer from two fundamental limitations. First, their reconstructions rely heavily on physical ...

---

## 96. Seeing Clearly, Reasoning Confidently: Plug-and-Play Remedies for Vision Language Model Blindness

- **arXiv ID**: 2602.19615v1
- **作者**: Xin Hu, Haomiao Ni, Yunbei Zhang, Jihun Hamm, Zechen Li 等 (共6位作者)
- **发布日期**: 2026-02-23
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.19615v1](http://arxiv.org/abs/2602.19615v1)
- **PDF**: [http://arxiv.org/pdf/2602.19615v1](http://arxiv.org/pdf/2602.19615v1)
- **摘要**: Vision language models (VLMs) have achieved remarkable success in broad visual understanding, yet they remain challenged by object-centric reasoning on rare objects due to the scarcity of such instances in pretraining data. While prior efforts alleviate this issue by retrieving additional data or in...

---

## 97. RAID: Retrieval-Augmented Anomaly Detection

- **arXiv ID**: 2602.19611v1
- **作者**: Mingxiu Cai, Zhe Zhang, Gaochang Wu, Tianyou Chai, Xiatian Zhu
- **发布日期**: 2026-02-23
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.19611v1](http://arxiv.org/abs/2602.19611v1)
- **PDF**: [http://arxiv.org/pdf/2602.19611v1](http://arxiv.org/pdf/2602.19611v1)
- **摘要**: Unsupervised Anomaly Detection (UAD) aims to identify abnormal regions by establishing correspondences between test images and normal templates. Existing methods primarily rely on image reconstruction or template retrieval but face a fundamental challenge: matching between test images and normal tem...

---

## 98. CLCR: Cross-Level Semantic Collaborative Representation for Multimodal Learning

- **arXiv ID**: 2602.19605v1
- **作者**: Chunlei Meng, Guanhong Huang, Rong Fu, Runmin Jian, Zhongxue Gan 等 (共6位作者)
- **发布日期**: 2026-02-23
- **分类**: cs.CV, cs.AI, cs.MM
- **论文链接**: [http://arxiv.org/abs/2602.19605v1](http://arxiv.org/abs/2602.19605v1)
- **PDF**: [http://arxiv.org/pdf/2602.19605v1](http://arxiv.org/pdf/2602.19605v1)
- **摘要**: Multimodal learning aims to capture both shared and private information from multiple modalities. However, existing methods that project all modalities into a single latent space for fusion often overlook the asynchronous, multi-level semantic structure of multimodal data. This oversight induces sem...

---

## 99. Tri-Subspaces Disentanglement for Multimodal Sentiment Analysis

- **arXiv ID**: 2602.19585v1
- **作者**: Chunlei Meng, Jiabin Luo, Zhenglin Yan, Zhenyu Yu, Rong Fu 等 (共7位作者)
- **发布日期**: 2026-02-23
- **分类**: cs.MM, cs.AI
- **论文链接**: [http://arxiv.org/abs/2602.19585v1](http://arxiv.org/abs/2602.19585v1)
- **PDF**: [http://arxiv.org/pdf/2602.19585v1](http://arxiv.org/pdf/2602.19585v1)
- **摘要**: Multimodal Sentiment Analysis (MSA) integrates language, visual, and acoustic modalities to infer human sentiment. Most existing methods either focus on globally shared representations or modality-specific features, while overlooking signals that are shared only by certain modality pairs. This limit...

---

## 100. ConceptPrism: Concept Disentanglement in Personalized Diffusion Models via Residual Token Optimization

- **arXiv ID**: 2602.19575v1
- **作者**: Minseo Kim, Minchan Kwon, Dongyeun Lee, Yunho Jeon, Junmo Kim
- **发布日期**: 2026-02-23
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.19575v1](http://arxiv.org/abs/2602.19575v1)
- **PDF**: [http://arxiv.org/pdf/2602.19575v1](http://arxiv.org/pdf/2602.19575v1)
- **摘要**: Personalized text-to-image generation suffers from concept entanglement, where irrelevant residual information from reference images is captured, leading to a trade-off between concept fidelity and text alignment. Recent disentanglement approaches attempt to solve this utilizing manual guidance, suc...

---

## 101. Vinedresser3D: Agentic Text-guided 3D Editing

- **arXiv ID**: 2602.19542v1
- **作者**: Yankuan Chi, Xiang Li, Zixuan Huang, James M. Rehg
- **发布日期**: 2026-02-23
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.19542v1](http://arxiv.org/abs/2602.19542v1)
- **PDF**: [http://arxiv.org/pdf/2602.19542v1](http://arxiv.org/pdf/2602.19542v1)
- **摘要**: Text-guided 3D editing aims to modify existing 3D assets using natural-language instructions. Current methods struggle to jointly understand complex prompts, automatically localize edits in 3D, and preserve unedited content. We introduce Vinedresser3D, an agentic framework for high-quality text-guid...

---

## 102. Model Merging in the Essential Subspace

- **arXiv ID**: 2602.20208v1
- **作者**: Longhua Li, Lei Qi, Qi Tian, Xin Geng
- **发布日期**: 2026-02-23
- **分类**: cs.LG, cs.AI
- **论文链接**: [http://arxiv.org/abs/2602.20208v1](http://arxiv.org/abs/2602.20208v1)
- **PDF**: [http://arxiv.org/pdf/2602.20208v1](http://arxiv.org/pdf/2602.20208v1)
- **摘要**: Model merging aims to integrate multiple task-specific fine-tuned models derived from a shared pre-trained checkpoint into a single multi-task model without additional training. Despite extensive research, task interference remains a major obstacle that often undermines the performance of merged mod...

---

## 103. QuantVLA: Scale-Calibrated Post-Training Quantization for Vision-Language-Action Models

- **arXiv ID**: 2602.20309v2
- **作者**: Jingxuan Zhang, Yunta Hsieh, Zhongwei Wan, Haokun Lin, Xin Wang 等 (共8位作者)
- **发布日期**: 2026-02-23
- **分类**: cs.LG
- **论文链接**: [http://arxiv.org/abs/2602.20309v2](http://arxiv.org/abs/2602.20309v2)
- **PDF**: [http://arxiv.org/pdf/2602.20309v2](http://arxiv.org/pdf/2602.20309v2)
- **摘要**: Vision-language-action (VLA) models unify perception, language, and control for embodied agents but face significant challenges in practical deployment due to rapidly increasing compute and memory demands, especially as models scale to longer horizons and larger backbones. To address these bottlenec...

---

## 104. ApET: Approximation-Error Guided Token Compression for Efficient VLMs

- **arXiv ID**: 2602.19870v1
- **作者**: Qiankun Ma, Ziyao Zhang, Haofei Wang, Jie Chen, Zhen Song 等 (共6位作者)
- **发布日期**: 2026-02-23
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.19870v1](http://arxiv.org/abs/2602.19870v1)
- **PDF**: [http://arxiv.org/pdf/2602.19870v1](http://arxiv.org/pdf/2602.19870v1)
- **摘要**: Recent Vision-Language Models (VLMs) have demonstrated remarkable multimodal understanding capabilities, yet the redundant visual tokens incur prohibitive computational overhead and degrade inference efficiency. Prior studies typically relies on [CLS] attention or text-vision cross-attention to iden...

---

## 105. Pixel2Phys: Distilling Governing Laws from Visual Dynamics

- **arXiv ID**: 2602.19516v1
- **作者**: Ruikun Li, Jun Yao, Yingfan Hua, Shixiang Tang, Biqing Qi 等 (共8位作者)
- **发布日期**: 2026-02-23
- **分类**: cs.CE
- **论文链接**: [http://arxiv.org/abs/2602.19516v1](http://arxiv.org/abs/2602.19516v1)
- **PDF**: [http://arxiv.org/pdf/2602.19516v1](http://arxiv.org/pdf/2602.19516v1)
- **摘要**: Discovering physical laws directly from high-dimensional visual data is a long-standing human pursuit but remains a formidable challenge for machines, representing a fundamental goal of scientific intelligence. This task is inherently difficult because physical knowledge is low-dimensional and struc...

---

## 106. MICON-Bench: Benchmarking and Enhancing Multi-Image Context Image Generation in Unified Multimodal Models

- **arXiv ID**: 2602.19497v1
- **作者**: Mingrui Wu, Hang Liu, Jiayi Ji, Xiaoshuai Sun, Rongrong Ji
- **发布日期**: 2026-02-23
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.19497v1](http://arxiv.org/abs/2602.19497v1)
- **PDF**: [http://arxiv.org/pdf/2602.19497v1](http://arxiv.org/pdf/2602.19497v1)
- **摘要**: Recent advancements in Unified Multimodal Models (UMMs) have enabled remarkable image understanding and generation capabilities. However, while models like Gemini-2.5-Flash-Image show emerging abilities to reason over multiple related images, existing benchmarks rarely address the challenges of mult...

---

## 107. Decoupling Vision and Language: Codebook Anchored Visual Adaptation

- **arXiv ID**: 2602.19449v1
- **作者**: Jason Wu, Tianchen Zhao, Chang Liu, Jiarui Cai, Zheng Zhang 等 (共10位作者)
- **发布日期**: 2026-02-23
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.19449v1](http://arxiv.org/abs/2602.19449v1)
- **PDF**: [http://arxiv.org/pdf/2602.19449v1](http://arxiv.org/pdf/2602.19449v1)
- **摘要**: Large Vision-Language Models (LVLMs) use their vision encoders to translate images into representations for downstream reasoning, but the encoders often underperform in domain-specific visual tasks such as medical image diagnosis or fine-grained classification, where representation errors can cascad...

---

## 108. Learning Mutual View Information Graph for Adaptive Adversarial Collaborative Perception

- **arXiv ID**: 2602.19596v1
- **作者**: Yihang Tao, Senkang Hu, Haonan An, Zhengru Fang, Hangcheng Cao 等 (共6位作者)
- **发布日期**: 2026-02-23
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.19596v1](http://arxiv.org/abs/2602.19596v1)
- **PDF**: [http://arxiv.org/pdf/2602.19596v1](http://arxiv.org/pdf/2602.19596v1)
- **摘要**: Collaborative perception (CP) enables data sharing among connected and autonomous vehicles (CAVs) to enhance driving safety. However, CP systems are vulnerable to adversarial attacks where malicious agents forge false objects via feature-level perturbations. Current defensive systems use threshold-b...

---

## 109. GSNR: Graph Smooth Null-Space Representation for Inverse Problems

- **arXiv ID**: 2602.20328v1
- **作者**: Romario Gualdrón-Hurtado, Roman Jacome, Rafael S. Suarez, Henry Arguello
- **发布日期**: 2026-02-23
- **分类**: cs.CV, eess.IV, math.OC
- **论文链接**: [http://arxiv.org/abs/2602.20328v1](http://arxiv.org/abs/2602.20328v1)
- **PDF**: [http://arxiv.org/pdf/2602.20328v1](http://arxiv.org/pdf/2602.20328v1)
- **摘要**: Inverse problems in imaging are ill-posed, leading to infinitely many solutions consistent with the measurements due to the non-trivial null-space of the sensing matrix. Common image priors promote solutions on the general image manifold, such as sparsity, smoothness, or score function. However, as ...

---

## 110. MRI Contrast Enhancement Kinetics World Model

- **arXiv ID**: 2602.19285v1
- **作者**: Jindi Kong, Yuting He, Cong Xia, Rongjun Ge, Shuo Li
- **发布日期**: 2026-02-22
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.19285v1](http://arxiv.org/abs/2602.19285v1)
- **PDF**: [http://arxiv.org/pdf/2602.19285v1](http://arxiv.org/pdf/2602.19285v1)
- **摘要**: Clinical MRI contrast acquisition suffers from inefficient information yield, which presents as a mismatch between the risky and costly acquisition protocol and the fixed and sparse acquisition sequence. Applying world models to simulate the contrast enhancement kinetics in the human body enables co...

---

## 111. No Need For Real Anomaly: MLLM Empowered Zero-Shot Video Anomaly Detection

- **arXiv ID**: 2602.19248v1
- **作者**: Zunkai Dai, Ke Li, Jiajia Liu, Jie Yang, Yuanyuan Qiao
- **发布日期**: 2026-02-22
- **分类**: cs.CV, cs.AI
- **论文链接**: [http://arxiv.org/abs/2602.19248v1](http://arxiv.org/abs/2602.19248v1)
- **PDF**: [http://arxiv.org/pdf/2602.19248v1](http://arxiv.org/pdf/2602.19248v1)
- **摘要**: The collection and detection of video anomaly data has long been a challenging problem due to its rare occurrence and spatio-temporal scarcity. Existing video anomaly detection (VAD) methods under perform in open-world scenarios. Key contributing factors include limited dataset diversity, and inadeq...

---

## 112. GS-CLIP: Zero-shot 3D Anomaly Detection by Geometry-Aware Prompt and Synergistic View Representation Learning

- **arXiv ID**: 2602.19206v2
- **作者**: Zehao Deng, An Liu, Yan Wang
- **发布日期**: 2026-02-22
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.19206v2](http://arxiv.org/abs/2602.19206v2)
- **PDF**: [http://arxiv.org/pdf/2602.19206v2](http://arxiv.org/pdf/2602.19206v2)
- **摘要**: Zero-shot 3D Anomaly Detection is an emerging task that aims to detect anomalies in a target dataset without any target training data, which is particularly important in scenarios constrained by sample scarcity and data privacy concerns. While current methods adapt CLIP by projecting 3D point clouds...

---

## 113. VLM-Guided Group Preference Alignment for Diffusion-based Human Mesh Recovery

- **arXiv ID**: 2602.19180v1
- **作者**: Wenhao Shen, Hao Wang, Wanqi Yin, Fayao Liu, Xulei Yang 等 (共8位作者)
- **发布日期**: 2026-02-22
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.19180v1](http://arxiv.org/abs/2602.19180v1)
- **PDF**: [http://arxiv.org/pdf/2602.19180v1](http://arxiv.org/pdf/2602.19180v1)
- **摘要**: Human mesh recovery (HMR) from a single RGB image is inherently ambiguous, as multiple 3D poses can correspond to the same 2D observation. Recent diffusion-based methods tackle this by generating various hypotheses, but often sacrifice accuracy. They yield predictions that are either physically impl...

---

## 114. BriMA: Bridged Modality Adaptation for Multi-Modal Continual Action Quality Assessment

- **arXiv ID**: 2602.19170v1
- **作者**: Kanglei Zhou, Chang Li, Qingyi Pan, Liyuan Wang
- **发布日期**: 2026-02-22
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.19170v1](http://arxiv.org/abs/2602.19170v1)
- **PDF**: [http://arxiv.org/pdf/2602.19170v1](http://arxiv.org/pdf/2602.19170v1)
- **摘要**: Action Quality Assessment (AQA) aims to score how well an action is performed and is widely used in sports analysis, rehabilitation assessment, and human skill evaluation. Multi-modal AQA has recently achieved strong progress by leveraging complementary visual and kinematic cues, yet real-world depl...

---

## 115. CaReFlow: Cyclic Adaptive Rectified Flow for Multimodal Fusion

- **arXiv ID**: 2602.19140v1
- **作者**: Sijie Mai, Shiqin Han
- **发布日期**: 2026-02-22
- **分类**: cs.CV, cs.LG
- **论文链接**: [http://arxiv.org/abs/2602.19140v1](http://arxiv.org/abs/2602.19140v1)
- **PDF**: [http://arxiv.org/pdf/2602.19140v1](http://arxiv.org/pdf/2602.19140v1)
- **摘要**: Modality gap significantly restricts the effectiveness of multimodal fusion. Previous methods often use techniques such as diffusion models and adversarial learning to reduce the modality gap, but they typically focus on one-to-one alignment without exposing the data points of the source modality to...

---

## 116. Universal 3D Shape Matching via Coarse-to-Fine Language Guidance

- **arXiv ID**: 2602.19112v2
- **作者**: Qinfeng Xiao, Guofeng Mei, Bo Yang, Liying Zhang, Jian Zhang 等 (共6位作者)
- **发布日期**: 2026-02-22
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.19112v2](http://arxiv.org/abs/2602.19112v2)
- **PDF**: [http://arxiv.org/pdf/2602.19112v2](http://arxiv.org/pdf/2602.19112v2)
- **摘要**: Establishing dense correspondences between shapes is a crucial task in computer vision and graphics, while prior approaches depend on near-isometric assumptions and homogeneous subject types (i.e., only operate for human shapes). However, building semantic correspondences for cross-category objects ...

---

## 117. The Power of Decaying Steps: Enhancing Attack Stability and Transferability for Sign-based Optimizers

- **arXiv ID**: 2602.19096v1
- **作者**: Wei Tao, Yang Dai, Jincai Huang, Qing Tao
- **发布日期**: 2026-02-22
- **分类**: cs.LG
- **论文链接**: [http://arxiv.org/abs/2602.19096v1](http://arxiv.org/abs/2602.19096v1)
- **PDF**: [http://arxiv.org/pdf/2602.19096v1](http://arxiv.org/pdf/2602.19096v1)
- **摘要**: Crafting adversarial examples can be formulated as an optimization problem. While sign-based optimizers such as I-FGSM and MI-FGSM have become the de facto standard for the induced optimization problems, there still exist several unsolved problems in theoretical grounding and practical reliability e...

---

## 118. Ani3DHuman: Photorealistic 3D Human Animation with Self-guided Stochastic Sampling

- **arXiv ID**: 2602.19089v1
- **作者**: Qi Sun, Can Wang, Jiaxiang Shang, Yingchun Liu, Jing Liao
- **发布日期**: 2026-02-22
- **分类**: cs.CV, cs.GR, cs.LG
- **论文链接**: [http://arxiv.org/abs/2602.19089v1](http://arxiv.org/abs/2602.19089v1)
- **PDF**: [http://arxiv.org/pdf/2602.19089v1](http://arxiv.org/pdf/2602.19089v1)
- **摘要**: Current 3D human animation methods struggle to achieve photorealism: kinematics-based approaches lack non-rigid dynamics (e.g., clothing dynamics), while methods that leverage video diffusion priors can synthesize non-rigid motion but suffer from quality artifacts and identity loss. To overcome thes...

---

## 119. ChordEdit: One-Step Low-Energy Transport for Image Editing

- **arXiv ID**: 2602.19083v1
- **作者**: Liangsi Lu, Xuhang Chen, Minzhe Guo, Shichu Li, Jingchao Wang 等 (共6位作者)
- **发布日期**: 2026-02-22
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.19083v1](http://arxiv.org/abs/2602.19083v1)
- **PDF**: [http://arxiv.org/pdf/2602.19083v1](http://arxiv.org/pdf/2602.19083v1)
- **摘要**: The advent of one-step text-to-image (T2I) models offers unprecedented synthesis speed. However, their application to text-guided image editing remains severely hampered, as forcing existing training-free editors into a single inference step fails. This failure manifests as severe object distortion ...

---

## 120. L3DR: 3D-aware LiDAR Diffusion and Rectification

- **arXiv ID**: 2602.19064v1
- **作者**: Quan Liu, Xiaoqin Zhang, Ling Shao, Shijian Lu
- **发布日期**: 2026-02-22
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.19064v1](http://arxiv.org/abs/2602.19064v1)
- **PDF**: [http://arxiv.org/pdf/2602.19064v1](http://arxiv.org/pdf/2602.19064v1)
- **摘要**: Range-view (RV) based LiDAR diffusion has recently made huge strides towards 2D photo-realism. However, it neglects 3D geometry realism and often generates various RV artifacts such as depth bleeding and wavy surfaces. We design L3DR, a 3D-aware LiDAR Diffusion and Rectification framework that can r...

---

## 121. Direction-aware 3D Large Multimodal Models

- **arXiv ID**: 2602.19063v1
- **作者**: Quan Liu, Weihao Xuan, Junjue Wang, Naoto Yokoya, Ling Shao 等 (共6位作者)
- **发布日期**: 2026-02-22
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.19063v1](http://arxiv.org/abs/2602.19063v1)
- **PDF**: [http://arxiv.org/pdf/2602.19063v1](http://arxiv.org/pdf/2602.19063v1)
- **摘要**: 3D large multimodal models (3D LMMs) rely heavily on ego poses for enabling directional question-answering and spatial reasoning. However, most existing point cloud benchmarks contain rich directional queries but lack the corresponding ego poses, making them inherently ill-posed in 3D large multimod...

---

## 122. TeFlow: Enabling Multi-frame Supervision for Self-Supervised Feed-forward Scene Flow Estimation

- **arXiv ID**: 2602.19053v1
- **作者**: Qingwen Zhang, Chenhan Jiang, Xiaomeng Zhu, Yunqi Miao, Yushan Zhang 等 (共7位作者)
- **发布日期**: 2026-02-22
- **分类**: cs.CV, cs.RO
- **论文链接**: [http://arxiv.org/abs/2602.19053v1](http://arxiv.org/abs/2602.19053v1)
- **PDF**: [http://arxiv.org/pdf/2602.19053v1](http://arxiv.org/pdf/2602.19053v1)
- **摘要**: Self-supervised feed-forward methods for scene flow estimation offer real-time efficiency, but their supervision from two-frame point correspondences is unreliable and often breaks down under occlusions. Multi-frame supervision has the potential to provide more stable guidance by incorporating motio...

---

## 123. OpenVO: Open-World Visual Odometry with Temporal Dynamics Awareness

- **arXiv ID**: 2602.19035v1
- **作者**: Phuc D. A. Nguyen, Anh N. Nhu, Ming C. Lin
- **发布日期**: 2026-02-22
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.19035v1](http://arxiv.org/abs/2602.19035v1)
- **PDF**: [http://arxiv.org/pdf/2602.19035v1](http://arxiv.org/pdf/2602.19035v1)
- **摘要**: We introduce OpenVO, a novel framework for Open-world Visual Odometry (VO) with temporal awareness under limited input conditions. OpenVO effectively estimates real-world-scale ego-motion from monocular dashcam footage with varying observation rates and uncalibrated cameras, enabling robust trajecto...

---

## 124. Towards Calibrating Prompt Tuning of Vision-Language Models

- **arXiv ID**: 2602.19024v1
- **作者**: Ashshak Sharifdeen, Fahad Shamshad, Muhammad Akhtar Munir, Abhishek Basu, Mohamed Insaf Ismithdeen 等 (共9位作者)
- **发布日期**: 2026-02-22
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.19024v1](http://arxiv.org/abs/2602.19024v1)
- **PDF**: [http://arxiv.org/pdf/2602.19024v1](http://arxiv.org/pdf/2602.19024v1)
- **摘要**: Prompt tuning of large-scale vision-language models such as CLIP enables efficient task adaptation without updating model weights. However, it often leads to poor confidence calibration and unreliable predictive uncertainty. We address this problem by proposing a calibration framework that enhances ...

---

## 125. Learning Cross-View Object Correspondence via Cycle-Consistent Mask Prediction

- **arXiv ID**: 2602.18996v1
- **作者**: Shannan Yan, Leqi Zheng, Keyu Lv, Jingchen Ni, Hongyang Wei 等 (共10位作者)
- **发布日期**: 2026-02-22
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.18996v1](http://arxiv.org/abs/2602.18996v1)
- **PDF**: [http://arxiv.org/pdf/2602.18996v1](http://arxiv.org/pdf/2602.18996v1)
- **摘要**: We study the task of establishing object-level visual correspondence across different viewpoints in videos, focusing on the challenging egocentric-to-exocentric and exocentric-to-egocentric scenarios. We propose a simple yet effective framework based on conditional binary segmentation, where an obje...

---

## 126. SeaCache: Spectral-Evolution-Aware Cache for Accelerating Diffusion Models

- **arXiv ID**: 2602.18993v1
- **作者**: Jiwoo Chung, Sangeek Hyun, MinKyu Lee, Byeongju Han, Geonho Cha 等 (共8位作者)
- **发布日期**: 2026-02-22
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.18993v1](http://arxiv.org/abs/2602.18993v1)
- **PDF**: [http://arxiv.org/pdf/2602.18993v1](http://arxiv.org/pdf/2602.18993v1)
- **摘要**: Diffusion models are a strong backbone for visual generation, but their inherently sequential denoising process leads to slow inference. Previous methods accelerate sampling by caching and reusing intermediate outputs based on feature distances between adjacent timesteps. However, existing caching s...

---

## 127. OTPrune: Distribution-Aligned Visual Token Pruning via Optimal Transport

- **arXiv ID**: 2602.20205v2
- **作者**: Xiwen Chen, Wenhui Zhu, Gen Li, Xuanzhao Dong, Yujian Xiong 等 (共12位作者)
- **发布日期**: 2026-02-22
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.20205v2](http://arxiv.org/abs/2602.20205v2)
- **PDF**: [http://arxiv.org/pdf/2602.20205v2](http://arxiv.org/pdf/2602.20205v2)
- **摘要**: Multi-modal large language models (MLLMs) achieve strong visual-language reasoning but suffer from high inference cost due to redundant visual tokens. Recent work explores visual token pruning to accelerate inference, while existing pruning methods overlook the underlying distributional structure of...

---

## 128. MoBind: Motion Binding for Fine-Grained IMU-Video Pose Alignment

- **arXiv ID**: 2602.19004v1
- **作者**: Duc Duy Nguyen, Tat-Jun Chin, Minh Hoai
- **发布日期**: 2026-02-22
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.19004v1](http://arxiv.org/abs/2602.19004v1)
- **PDF**: [http://arxiv.org/pdf/2602.19004v1](http://arxiv.org/pdf/2602.19004v1)
- **摘要**: We aim to learn a joint representation between inertial measurement unit (IMU) signals and 2D pose sequences extracted from video, enabling accurate cross-modal retrieval, temporal synchronization, subject and body-part localization, and action recognition. To this end, we introduce MoBind, a hierar...

---

## 129. Frame2Freq: Spectral Adapters for Fine-Grained Video Understanding

- **arXiv ID**: 2602.18977v1
- **作者**: Thinesh Thiyakesan Ponbagavathi, Constantin Seibold, Alina Roitberg
- **发布日期**: 2026-02-21
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.18977v1](http://arxiv.org/abs/2602.18977v1)
- **PDF**: [http://arxiv.org/pdf/2602.18977v1](http://arxiv.org/pdf/2602.18977v1)
- **摘要**: Adapting image-pretrained backbones to video typically relies on time-domain adapters tuned to a single temporal scale. Our experiments show that these modules pick up static image cues and very fast flicker changes, while overlooking medium-speed motion. Capturing dynamics across multiple time-scal...

---

## 130. SafeDrive: Fine-Grained Safety Reasoning for End-to-End Driving in a Sparse World

- **arXiv ID**: 2602.18887v1
- **作者**: Jungho Kim, Jiyong Oh, Seunghoon Yu, Hongjae Shin, Donghyuk Kwak 等 (共6位作者)
- **发布日期**: 2026-02-21
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.18887v1](http://arxiv.org/abs/2602.18887v1)
- **PDF**: [http://arxiv.org/pdf/2602.18887v1](http://arxiv.org/pdf/2602.18887v1)
- **摘要**: The end-to-end (E2E) paradigm, which maps sensor inputs directly to driving decisions, has recently attracted significant attention due to its unified modeling capability and scalability. However, ensuring safety in this unified framework remains one of the most critical challenges. In this work, we...

---

## 131. BiMotion: B-spline Motion for Text-guided Dynamic 3D Character Generation

- **arXiv ID**: 2602.18873v1
- **作者**: Miaowei Wang, Qingxuan Yan, Zhi Cao, Yayuan Li, Oisin Mac Aodha 等 (共7位作者)
- **发布日期**: 2026-02-21
- **分类**: cs.CV, cs.AI
- **论文链接**: [http://arxiv.org/abs/2602.18873v1](http://arxiv.org/abs/2602.18873v1)
- **PDF**: [http://arxiv.org/pdf/2602.18873v1](http://arxiv.org/pdf/2602.18873v1)
- **摘要**: Text-guided dynamic 3D character generation has advanced rapidly, yet producing high-quality motion that faithfully reflects rich textual descriptions remains challenging. Existing methods tend to generate limited sub-actions or incoherent motion due to fixed-length temporal inputs and discrete fram...

---

## 132. Similarity-as-Evidence: Calibrating Overconfident VLMs for Interpretable and Label-Efficient Medical Active Learning

- **arXiv ID**: 2602.18867v1
- **作者**: Zhuofan Xie, Zishan Lin, Jinliang Lin, Jie Qi, Shaohua Hong 等 (共6位作者)
- **发布日期**: 2026-02-21
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.18867v1](http://arxiv.org/abs/2602.18867v1)
- **PDF**: [http://arxiv.org/pdf/2602.18867v1](http://arxiv.org/pdf/2602.18867v1)
- **摘要**: Active Learning (AL) reduces annotation costs in medical imaging by selecting only the most informative samples for labeling, but suffers from cold-start when labeled data are scarce. Vision-Language Models (VLMs) address the cold-start problem via zero-shot predictions, yet their temperature-scaled...

---

## 133. TIACam: Text-Anchored Invariant Feature Learning with Auto-Augmentation for Camera-Robust Zero-Watermarking

- **arXiv ID**: 2602.18863v1
- **作者**: Abdullah All Tanvir, Agnibh Dasgupta, Xin Zhong
- **发布日期**: 2026-02-21
- **分类**: eess.IV, cs.CV, cs.LG
- **论文链接**: [http://arxiv.org/abs/2602.18863v1](http://arxiv.org/abs/2602.18863v1)
- **PDF**: [http://arxiv.org/pdf/2602.18863v1](http://arxiv.org/pdf/2602.18863v1)
- **摘要**: Camera recapture introduces complex optical degradations, such as perspective warping, illumination shifts, and Moiré interference, that remain challenging for deep watermarking systems. We present TIACam, a text-anchored invariant feature learning framework with auto-augmentation for camera-robust ...

---

## 134. Hyperbolic Busemann Neural Networks

- **arXiv ID**: 2602.18858v2
- **作者**: Ziheng Chen, Bernhard Schölkopf, Nicu Sebe
- **发布日期**: 2026-02-21
- **分类**: cs.LG, cs.AI, cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.18858v2](http://arxiv.org/abs/2602.18858v2)
- **PDF**: [http://arxiv.org/pdf/2602.18858v2](http://arxiv.org/pdf/2602.18858v2)
- **摘要**: Hyperbolic spaces provide a natural geometry for representing hierarchical and tree-structured data due to their exponential volume growth. To leverage these benefits, neural networks require intrinsic and efficient components that operate directly in hyperbolic space. In this work, we lift two core...

---

## 135. DUET-VLM: Dual stage Unified Efficient Token reduction for VLM Training and Inference

- **arXiv ID**: 2602.18846v1
- **作者**: Aditya Kumar Singh, Hitesh Kandala, Pratik Prabhanjan Brahma, Zicheng Liu, Emad Barsoum
- **发布日期**: 2026-02-21
- **分类**: cs.CV, cs.AI
- **论文链接**: [http://arxiv.org/abs/2602.18846v1](http://arxiv.org/abs/2602.18846v1)
- **PDF**: [http://arxiv.org/pdf/2602.18846v1](http://arxiv.org/pdf/2602.18846v1)
- **摘要**: Vision-language models (VLMs) have achieved remarkable multimodal understanding and reasoning capabilities, yet remain computationally expensive due to dense visual tokenization. Existing efficiency approaches either merge redundant visual tokens or drop them progressively in language backbone, ofte...

---

## 136. Echoes of Ownership: Adversarial-Guided Dual Injection for Copyright Protection in MLLMs

- **arXiv ID**: 2602.18845v1
- **作者**: Chengwei Xia, Fan Ma, Ruijie Quan, Yunqiu Xu, Kun Zhan 等 (共6位作者)
- **发布日期**: 2026-02-21
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.18845v1](http://arxiv.org/abs/2602.18845v1)
- **PDF**: [http://arxiv.org/pdf/2602.18845v1](http://arxiv.org/pdf/2602.18845v1)
- **摘要**: With the rapid deployment and widespread adoption of multimodal large language models (MLLMs), disputes regarding model version attribution and ownership have become increasingly frequent, raising significant concerns about intellectual property protection. In this paper, we propose a framework for ...

---

## 137. Detecting AI-Generated Forgeries via Iterative Manifold Deviation Amplification

- **arXiv ID**: 2602.18842v1
- **作者**: Jiangling Zhang, Shuxuan Gao, Bofan Liu, Siqiang Feng, Jirui Huang 等 (共7位作者)
- **发布日期**: 2026-02-21
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.18842v1](http://arxiv.org/abs/2602.18842v1)
- **PDF**: [http://arxiv.org/pdf/2602.18842v1](http://arxiv.org/pdf/2602.18842v1)
- **摘要**: The proliferation of highly realistic AI-generated images poses critical challenges for digital forensics, demanding precise pixel-level localization of manipulated regions. Existing methods predominantly learn discriminative patterns of specific forgeries and often struggle with novel manipulations...

---

## 138. IDperturb: Enhancing Variation in Synthetic Face Generation via Angular Perturbation

- **arXiv ID**: 2602.18831v1
- **作者**: Fadi Boutros, Eduarda Caldeira, Tahar Chettaoui, Naser Damer
- **发布日期**: 2026-02-21
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.18831v1](http://arxiv.org/abs/2602.18831v1)
- **PDF**: [http://arxiv.org/pdf/2602.18831v1](http://arxiv.org/pdf/2602.18831v1)
- **摘要**: Synthetic data has emerged as a practical alternative to authentic face datasets for training face recognition (FR) systems, especially as privacy and legal concerns increasingly restrict the use of real biometric data. Recent advances in identity-conditional diffusion models have enabled the genera...

---

## 139. Learning Multi-Modal Prototypes for Cross-Domain Few-Shot Object Detection

- **arXiv ID**: 2602.18811v1
- **作者**: Wanqi Wang, Jingcai Guo, Yuxiang Cai, Zhi Chen
- **发布日期**: 2026-02-21
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.18811v1](http://arxiv.org/abs/2602.18811v1)
- **PDF**: [http://arxiv.org/pdf/2602.18811v1](http://arxiv.org/pdf/2602.18811v1)
- **摘要**: Cross-Domain Few-Shot Object Detection (CD-FSOD) aims to detect novel classes in unseen target domains given only a few labeled examples. While open-vocabulary detectors built on vision-language models (VLMs) transfer well, they depend almost entirely on text prompts, which encode domain-invariant s...

---

## 140. Open-Vocabulary Domain Generalization in Urban-Scene Segmentation

- **arXiv ID**: 2602.18853v1
- **作者**: Dong Zhao, Qi Zang, Nan Pu, Wenjing Li, Nicu Sebe 等 (共6位作者)
- **发布日期**: 2026-02-21
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.18853v1](http://arxiv.org/abs/2602.18853v1)
- **PDF**: [http://arxiv.org/pdf/2602.18853v1](http://arxiv.org/pdf/2602.18853v1)
- **摘要**: Domain Generalization in Semantic Segmentation (DG-SS) aims to enable segmentation models to perform robustly in unseen environments. However, conventional DG-SS methods are restricted to a fixed set of known categories, limiting their applicability in open-world scenarios. Recent progress in Vision...

---

## 141. MaskDiME: Adaptive Masked Diffusion for Precise and Efficient Visual Counterfactual Explanations

- **arXiv ID**: 2602.18792v1
- **作者**: Changlu Guo, Anders Nymark Christensen, Anders Bjorholm Dahl, Morten Rieger Hannemose
- **发布日期**: 2026-02-21
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.18792v1](http://arxiv.org/abs/2602.18792v1)
- **PDF**: [http://arxiv.org/pdf/2602.18792v1](http://arxiv.org/pdf/2602.18792v1)
- **摘要**: Visual counterfactual explanations aim to reveal the minimal semantic modifications that can alter a model's prediction, providing causal and interpretable insights into deep neural networks. However, existing diffusion-based counterfactual generation methods are often computationally expensive, slo...

---

## 142. LaS-Comp: Zero-shot 3D Completion with Latent-Spatial Consistency

- **arXiv ID**: 2602.18735v1
- **作者**: Weilong Yan, Haipeng Li, Hao Xu, Nianjin Ye, Yihao Ai 等 (共7位作者)
- **发布日期**: 2026-02-21
- **分类**: cs.CV, cs.RO
- **论文链接**: [http://arxiv.org/abs/2602.18735v1](http://arxiv.org/abs/2602.18735v1)
- **PDF**: [http://arxiv.org/pdf/2602.18735v1](http://arxiv.org/pdf/2602.18735v1)
- **摘要**: This paper introduces LaS-Comp, a zero-shot and category-agnostic approach that leverages the rich geometric priors of 3D foundation models to enable 3D shape completion across diverse types of partial observations. Our contributions are threefold: First, \ourname{} harnesses these powerful generati...

---

## 143. ReMoRa: Multimodal Large Language Model based on Refined Motion Representation for Long-Video Understanding

- **arXiv ID**: 2602.16412v2
- **作者**: Daichi Yashima, Shuhei Kurita, Yusuke Oda, Komei Sugiura
- **发布日期**: 2026-02-18
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2602.16412v2](http://arxiv.org/abs/2602.16412v2)
- **PDF**: [http://arxiv.org/pdf/2602.16412v2](http://arxiv.org/pdf/2602.16412v2)
- **摘要**: While multimodal large language models (MLLMs) have shown remarkable success across a wide range of tasks, long-form video understanding remains a significant challenge. In this study, we focus on video understanding by MLLMs. This task is challenging because processing a full stream of RGB frames i...

---

## 144. DisCa: Accelerating Video Diffusion Transformers with Distillation-Compatible Learnable Feature Caching

- **arXiv ID**: 2602.05449v2
- **作者**: Chang Zou, Changlin Li, Yang Li, Patrol Li, Jianbing Wu 等 (共10位作者)
- **发布日期**: 2026-02-05
- **分类**: cs.CV, cs.AI
- **论文链接**: [http://arxiv.org/abs/2602.05449v2](http://arxiv.org/abs/2602.05449v2)
- **PDF**: [http://arxiv.org/pdf/2602.05449v2](http://arxiv.org/pdf/2602.05449v2)
- **摘要**: While diffusion models have achieved great success in the field of video generation, this progress is accompanied by a rapidly escalating computational burden. Among the existing acceleration methods, Feature Caching is popular due to its training-free property and considerable speedup performance, ...

---

## 145. REL-SF4PASS: Panoramic Semantic Segmentation with REL Depth Representation and Spherical Fusion

- **arXiv ID**: 2601.16788v1
- **作者**: Xuewei Li, Xinghan Bao, Zhimin Chen, Xi Li
- **发布日期**: 2026-01-23
- **分类**: cs.CV, cs.AI
- **论文链接**: [http://arxiv.org/abs/2601.16788v1](http://arxiv.org/abs/2601.16788v1)
- **PDF**: [http://arxiv.org/pdf/2601.16788v1](http://arxiv.org/pdf/2601.16788v1)
- **摘要**: As an important and challenging problem in computer vision, Panoramic Semantic Segmentation (PASS) aims to give complete scene perception based on an ultra-wide angle of view. Most PASS methods often focus on spherical geometry with RGB input or using the depth information in original or HHA format,...

---

## 146. ReWeaver: Towards Simulation-Ready and Topology-Accurate Garment Reconstruction

- **arXiv ID**: 2601.16672v1
- **作者**: Ming Li, Hui Shan, Kai Zheng, Chentao Shen, Siyu Liu 等 (共8位作者)
- **发布日期**: 2026-01-23
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2601.16672v1](http://arxiv.org/abs/2601.16672v1)
- **PDF**: [http://arxiv.org/pdf/2601.16672v1](http://arxiv.org/pdf/2601.16672v1)
- **摘要**: High-quality 3D garment reconstruction plays a crucial role in mitigating the sim-to-real gap in applications such as digital avatars, virtual try-on and robotic manipulation. However, existing garment reconstruction methods typically rely on unstructured representations, such as 3D Gaussian Splats,...

---

## 147. Reasoning with Pixel-level Precision: QVLM Architecture and SQuID Dataset for Quantitative Geospatial Analytics

- **arXiv ID**: 2601.13401v1
- **作者**: Peter A. Massih, Eric Cosatto
- **发布日期**: 2026-01-19
- **分类**: cs.CV, cs.AI
- **论文链接**: [http://arxiv.org/abs/2601.13401v1](http://arxiv.org/abs/2601.13401v1)
- **PDF**: [http://arxiv.org/pdf/2601.13401v1](http://arxiv.org/pdf/2601.13401v1)
- **摘要**: Current Vision-Language Models (VLMs) fail at quantitative spatial reasoning because their architectures destroy pixel-level information required for counting and measurements. Vision encoders compress images through patch embeddings, reducing spatial indexing and losing the precise pixel-level trac...

---

## 148. NanoSD: Edge Efficient Foundation Model for Real Time Image Restoration

- **arXiv ID**: 2601.09823v2
- **作者**: Subhajit Sanyal, Srinivas Soumitri Miriyala, Akshay Janardan Bankar, Manjunath Arveti, Sowmya Vajrala 等 (共10位作者)
- **发布日期**: 2026-01-14
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2601.09823v2](http://arxiv.org/abs/2601.09823v2)
- **PDF**: [http://arxiv.org/pdf/2601.09823v2](http://arxiv.org/pdf/2601.09823v2)
- **摘要**: Latent diffusion models such as Stable Diffusion 1.5 offer strong generative priors that are highly valuable for image restoration, yet their full pipelines remain too computationally heavy for deployment on edge devices. Existing lightweight variants predominantly compress the denoising U-Net or re...

---

## 149. Fast-ThinkAct: Efficient Vision-Language-Action Reasoning via Verbalizable Latent Planning

- **arXiv ID**: 2601.09708v2
- **作者**: Chi-Pin Huang, Yunze Man, Zhiding Yu, Min-Hung Chen, Jan Kautz 等 (共7位作者)
- **发布日期**: 2026-01-14
- **分类**: cs.CV, cs.AI, cs.LG
- **论文链接**: [http://arxiv.org/abs/2601.09708v2](http://arxiv.org/abs/2601.09708v2)
- **PDF**: [http://arxiv.org/pdf/2601.09708v2](http://arxiv.org/pdf/2601.09708v2)
- **摘要**: Vision-Language-Action (VLA) tasks require reasoning over complex visual scenes and executing adaptive actions in dynamic environments. While recent studies on reasoning VLAs show that explicit chain-of-thought (CoT) can improve generalization, they suffer from high inference latency due to lengthy ...

---

## 150. Object-WIPER : Training-Free Object and Associated Effect Removal in Videos

- **arXiv ID**: 2601.06391v2
- **作者**: Saksham Singh Kushwaha, Sayan Nag, Yapeng Tian, Kuldeep Kulkarni
- **发布日期**: 2026-01-10
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2601.06391v2](http://arxiv.org/abs/2601.06391v2)
- **PDF**: [http://arxiv.org/pdf/2601.06391v2](http://arxiv.org/pdf/2601.06391v2)
- **摘要**: In this paper, we introduce Object-WIPER, a training-free framework for removing dynamic objects and their associated visual effects from videos, and inpainting them with semantically consistent and temporally coherent content. Our approach leverages a pre-trained text-to-video diffusion transformer...

---

## 151. Learnability-Driven Submodular Optimization for Active Roadside 3D Detection

- **arXiv ID**: 2601.01695v1
- **作者**: Ruiyu Mao, Baoming Zhang, Nicholas Ruozzi, Yunhui Guo
- **发布日期**: 2026-01-04
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2601.01695v1](http://arxiv.org/abs/2601.01695v1)
- **PDF**: [http://arxiv.org/pdf/2601.01695v1](http://arxiv.org/pdf/2601.01695v1)
- **摘要**: Roadside perception datasets are typically constructed via cooperative labeling between synchronized vehicle and roadside frame pairs. However, real deployment often requires annotation of roadside-only data due to hardware and privacy constraints. Even human experts struggle to produce accurate lab...

---

## 152. UnrealPose: Leveraging Game Engine Kinematics for Large-Scale Synthetic Human Pose Data

- **arXiv ID**: 2601.00991v1
- **作者**: Joshua Kawaguchi, Saad Manzur, Emily Gao Wang, Maitreyi Sinha, Bryan Vela 等 (共8位作者)
- **发布日期**: 2026-01-02
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2601.00991v1](http://arxiv.org/abs/2601.00991v1)
- **PDF**: [http://arxiv.org/pdf/2601.00991v1](http://arxiv.org/pdf/2601.00991v1)
- **摘要**: Diverse, accurately labeled 3D human pose data is expensive and studio-bound, while in-the-wild datasets lack known ground truth. We introduce UnrealPose-Gen, an Unreal Engine 5 pipeline built on Movie Render Queue for high-quality offline rendering. Our generated frames include: (i) 3D joints in wo...

---

## 153. Beyond Pixel Simulation: Pathology Image Generation via Diagnostic Semantic Tokens and Prototype Control

- **arXiv ID**: 2512.21058v2
- **作者**: Minghao Han, Yichen Liu, Yizhou Liu, Zizhi Chen, Jingqun Tang 等 (共8位作者)
- **发布日期**: 2025-12-24
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2512.21058v2](http://arxiv.org/abs/2512.21058v2)
- **PDF**: [http://arxiv.org/pdf/2512.21058v2](http://arxiv.org/pdf/2512.21058v2)
- **摘要**: In computational pathology, understanding and generation have evolved along disparate paths: advanced understanding models already exhibit diagnostic-level competence, whereas generative models largely simulate pixels. Progress remains hindered by three coupled factors: the scarcity of large, high-q...

---

## 154. OccuFly: A 3D Vision Benchmark for Semantic Scene Completion from the Aerial Perspective

- **arXiv ID**: 2512.20770v1
- **作者**: Markus Gross, Sai B. Matha, Aya Fahmy, Rui Song, Daniel Cremers 等 (共6位作者)
- **发布日期**: 2025-12-23
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2512.20770v1](http://arxiv.org/abs/2512.20770v1)
- **PDF**: [http://arxiv.org/pdf/2512.20770v1](http://arxiv.org/pdf/2512.20770v1)
- **摘要**: Semantic Scene Completion (SSC) is crucial for 3D perception in mobile robotics, as it enables holistic scene understanding by jointly estimating dense volumetric occupancy and per-voxel semantics. Although SSC has been widely studied in terrestrial domains such as autonomous driving, aerial scenari...

---

## 155. The devil is in the details: Enhancing Video Virtual Try-On via Keyframe-Driven Details Injection

- **arXiv ID**: 2512.20340v2
- **作者**: Qingdong He, Xueqin Chen, Yanjie Pan, Peng Tang, Pengcheng Xu 等 (共10位作者)
- **发布日期**: 2025-12-23
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2512.20340v2](http://arxiv.org/abs/2512.20340v2)
- **PDF**: [http://arxiv.org/pdf/2512.20340v2](http://arxiv.org/pdf/2512.20340v2)
- **摘要**: Although diffusion transformer (DiT)-based video virtual try-on (VVT) has made significant progress in synthesizing realistic videos, existing methods still struggle to capture fine-grained garment dynamics and preserve background integrity across video frames. They also incur high computational cos...

---

## 156. Foundation Model Priors Enhance Object Focus in Feature Space for Source-Free Object Detection

- **arXiv ID**: 2512.17514v3
- **作者**: Sairam VCR, Rishabh Lalla, Aveen Dayal, Tejal Kulkarni, Anuj Lalla 等 (共7位作者)
- **发布日期**: 2025-12-19
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2512.17514v3](http://arxiv.org/abs/2512.17514v3)
- **PDF**: [http://arxiv.org/pdf/2512.17514v3](http://arxiv.org/pdf/2512.17514v3)
- **摘要**: Current state-of-the-art approaches in Source-Free Object Detection (SFOD) typically rely on Mean-Teacher self-labeling. However, domain shift often reduces the detector's ability to maintain strong object-focused representations, causing high-confidence activations over background clutter. This wea...

---

## 157. Using Gaussian Splats to Create High-Fidelity Facial Geometry and Texture

- **arXiv ID**: 2512.16397v1
- **作者**: Haodi He, Jihun Yu, Ronald Fedkiw
- **发布日期**: 2025-12-18
- **分类**: cs.CV, cs.AI, cs.GR
- **论文链接**: [http://arxiv.org/abs/2512.16397v1](http://arxiv.org/abs/2512.16397v1)
- **PDF**: [http://arxiv.org/pdf/2512.16397v1](http://arxiv.org/pdf/2512.16397v1)
- **摘要**: We leverage increasingly popular three-dimensional neural representations in order to construct a unified and consistent explanation of a collection of uncalibrated images of the human face. Our approach utilizes Gaussian Splatting, since it is more explicit and thus more amenable to constraints tha...

---

## 158. Generative Neural Video Compression via Video Diffusion Prior

- **arXiv ID**: 2512.05016v2
- **作者**: Qi Mao, Hao Cheng, Tinghan Yang, Libiao Jin, Siwei Ma
- **发布日期**: 2025-12-04
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2512.05016v2](http://arxiv.org/abs/2512.05016v2)
- **PDF**: [http://arxiv.org/pdf/2512.05016v2](http://arxiv.org/pdf/2512.05016v2)
- **摘要**: We present GNVC-VD, the first DiT-based generative neural video compression framework built upon an advanced video generation foundation model, where spatio-temporal latent compression and sequence-level generative refinement are unified within a single codec. Existing perceptual codecs primarily re...

---

## 159. UTrice: Unifying Primitives in Differentiable Ray Tracing and Rasterization via Triangles for Particle-Based 3D Scenes

- **arXiv ID**: 2512.04421v1
- **作者**: Changhe Liu, Ehsan Javanmardi, Naren Bao, Alex Orsholits, Manabu Tsukada
- **发布日期**: 2025-12-04
- **分类**: cs.CV, cs.GR
- **论文链接**: [http://arxiv.org/abs/2512.04421v1](http://arxiv.org/abs/2512.04421v1)
- **PDF**: [http://arxiv.org/pdf/2512.04421v1](http://arxiv.org/pdf/2512.04421v1)
- **摘要**: Ray tracing 3D Gaussian particles enables realistic effects such as depth of field, refractions, and flexible camera modeling for novel-view synthesis. However, existing methods trace Gaussians through proxy geometry, which requires constructing complex intermediate meshes and performing costly inte...

---

## 160. Text-Only Training for Image Captioning with Retrieval Augmentation and Modality Gap Correction

- **arXiv ID**: 2512.04309v1
- **作者**: Rui Fonseca, Bruno Martins, Gil Rocha
- **发布日期**: 2025-12-03
- **分类**: cs.CV, cs.CL
- **论文链接**: [http://arxiv.org/abs/2512.04309v1](http://arxiv.org/abs/2512.04309v1)
- **PDF**: [http://arxiv.org/pdf/2512.04309v1](http://arxiv.org/pdf/2512.04309v1)
- **摘要**: Image captioning has drawn considerable attention from the natural language processing and computer vision fields. Aiming to reduce the reliance on curated data, several studies have explored image captioning without any humanly-annotated image-text pairs for training, although existing methods are ...

---

## 161. VLM-Pruner: Buffering for Spatial Sparsity in an Efficient VLM Centrifugal Token Pruning Paradigm

- **arXiv ID**: 2512.02700v4
- **作者**: Zhenkai Wu, Xiaowen Ma, Zhenliang Ni, Dengming Zhang, Han Shu 等 (共7位作者)
- **发布日期**: 2025-12-02
- **分类**: cs.CV, cs.LG
- **论文链接**: [http://arxiv.org/abs/2512.02700v4](http://arxiv.org/abs/2512.02700v4)
- **PDF**: [http://arxiv.org/pdf/2512.02700v4](http://arxiv.org/pdf/2512.02700v4)
- **摘要**: Vision-language models (VLMs) excel at image understanding tasks, but the large number of visual tokens imposes significant computational costs, hindering deployment on mobile devices. Many pruning methods rely solely on token importance and thus overlook inter-token redundancy, retaining numerous d...

---

## 162. ClimaOoD: Improving Anomaly Segmentation via Physically Realistic Synthetic Data

- **arXiv ID**: 2512.02686v2
- **作者**: Yuxing Liu, Zheng Li, Huanhuan Liang, Ji Zhang, Zeyu Sun 等 (共6位作者)
- **发布日期**: 2025-12-02
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2512.02686v2](http://arxiv.org/abs/2512.02686v2)
- **PDF**: [http://arxiv.org/pdf/2512.02686v2](http://arxiv.org/pdf/2512.02686v2)
- **摘要**: Anomaly segmentation seeks to detect and localize unknown or out-of-distribution (OoD) objects that fall outside predefined semantic classes a capability essential for safe autonomous driving. However, the scarcity and limited diversity of anomaly data severely constrain model generalization in open...

---

## 163. SplatSuRe: Selective Super-Resolution for Multi-view Consistent 3D Gaussian Splatting

- **arXiv ID**: 2512.02172v1
- **作者**: Pranav Asthana, Alex Hanson, Allen Tu, Tom Goldstein, Matthias Zwicker 等 (共6位作者)
- **发布日期**: 2025-12-01
- **分类**: cs.CV, cs.GR, cs.LG
- **论文链接**: [http://arxiv.org/abs/2512.02172v1](http://arxiv.org/abs/2512.02172v1)
- **PDF**: [http://arxiv.org/pdf/2512.02172v1](http://arxiv.org/pdf/2512.02172v1)
- **摘要**: 3D Gaussian Splatting (3DGS) enables high-quality novel view synthesis, motivating interest in generating higher-resolution renders than those available during training. A natural strategy is to apply super-resolution (SR) to low-resolution (LR) input views, but independently enhancing each image in...

---

## 164. MindPower: Enabling Theory-of-Mind Reasoning in VLM-based Embodied Agents

- **arXiv ID**: 2511.23055v2
- **作者**: Ruoxuan Zhang, Qiyun Zheng, Zhiyu Zhou, Ziqi Liao, Siyu Wu 等 (共10位作者)
- **发布日期**: 2025-11-28
- **分类**: cs.AI
- **论文链接**: [http://arxiv.org/abs/2511.23055v2](http://arxiv.org/abs/2511.23055v2)
- **PDF**: [http://arxiv.org/pdf/2511.23055v2](http://arxiv.org/pdf/2511.23055v2)
- **摘要**: Theory of Mind (ToM) refers to the ability to infer others' mental states, such as beliefs, desires, and intentions. Current vision-language embodied agents lack ToM-based decision-making, and existing benchmarks focus solely on human mental states while ignoring the agent's own perspective, hinderi...

---

## 165. MARVO: Marine-Adaptive Radiance-aware Visual Odometry

- **arXiv ID**: 2511.22860v1
- **作者**: Sacchin Sundar, Atman Kikani, Aaliya Alam, Sumukh Shrote, A. Nayeemulla Khan 等 (共6位作者)
- **发布日期**: 2025-11-28
- **分类**: cs.RO, cs.CV
- **论文链接**: [http://arxiv.org/abs/2511.22860v1](http://arxiv.org/abs/2511.22860v1)
- **PDF**: [http://arxiv.org/pdf/2511.22860v1](http://arxiv.org/pdf/2511.22860v1)
- **摘要**: Underwater visual localization remains challenging due to wavelength-dependent attenuation, poor texture, and non-Gaussian sensor noise. We introduce MARVO, a physics-aware, learning-integrated odometry framework that fuses underwater image formation modeling, differentiable matching, and reinforcem...

---

## 166. MapReduce LoRA: Advancing the Pareto Front in Multi-Preference Optimization for Generative Models

- **arXiv ID**: 2511.20629v4
- **作者**: Chieh-Yun Chen, Zhonghao Wang, Qi Chen, Zhifan Ye, Min Shi 等 (共13位作者)
- **发布日期**: 2025-11-25
- **分类**: cs.CV, cs.AI, cs.LG
- **论文链接**: [http://arxiv.org/abs/2511.20629v4](http://arxiv.org/abs/2511.20629v4)
- **PDF**: [http://arxiv.org/pdf/2511.20629v4](http://arxiv.org/pdf/2511.20629v4)
- **摘要**: Reinforcement learning from human feedback (RLHF) with reward models has advanced alignment of generative models to human aesthetic and perceptual preferences. However, jointly optimizing multiple rewards often incurs an alignment tax, improving one dimension while degrading others. To address this,...

---

## 167. PhysGS: Bayesian-Inferred Gaussian Splatting for Physical Property Estimation

- **arXiv ID**: 2511.18570v1
- **作者**: Samarth Chopra, Jing Liang, Gershom Seneviratne, Dinesh Manocha
- **发布日期**: 2025-11-23
- **分类**: cs.CV, cs.RO
- **论文链接**: [http://arxiv.org/abs/2511.18570v1](http://arxiv.org/abs/2511.18570v1)
- **PDF**: [http://arxiv.org/pdf/2511.18570v1](http://arxiv.org/pdf/2511.18570v1)
- **摘要**: Understanding physical properties such as friction, stiffness, hardness, and material composition is essential for enabling robots to interact safely and effectively with their surroundings. However, existing 3D reconstruction methods focus on geometry and appearance and cannot infer these underlyin...

---

## 168. Multimodal Continual Learning with MLLMs from Multi-scenario Perspectives

- **arXiv ID**: 2511.18507v2
- **作者**: Kai Jiang, Siqi Huang, Xiangyu Chen, Jiawei Shao, Hongyuan Zhang 等 (共6位作者)
- **发布日期**: 2025-11-23
- **分类**: cs.CV, cs.AI
- **论文链接**: [http://arxiv.org/abs/2511.18507v2](http://arxiv.org/abs/2511.18507v2)
- **PDF**: [http://arxiv.org/pdf/2511.18507v2](http://arxiv.org/pdf/2511.18507v2)
- **摘要**: Continual learning in visual understanding aims to deal with catastrophic forgetting in Multimodal Large Language Models (MLLMs). MLLMs deployed on devices have to continuously adapt to dynamic scenarios in downstream tasks, such as variations in background and perspective, to effectively perform co...

---

## 169. Uni-DAD: Unified Distillation and Adaptation of Diffusion Models for Few-step Few-shot Image Generation

- **arXiv ID**: 2511.18281v1
- **作者**: Yara Bahram, Melodie Desbos, Mohammadhadi Shateri, Eric Granger
- **发布日期**: 2025-11-23
- **分类**: cs.CV, cs.AI
- **论文链接**: [http://arxiv.org/abs/2511.18281v1](http://arxiv.org/abs/2511.18281v1)
- **PDF**: [http://arxiv.org/pdf/2511.18281v1](http://arxiv.org/pdf/2511.18281v1)
- **摘要**: Diffusion models (DMs) produce high-quality images, yet their sampling remains costly when adapted to new domains. Distilled DMs are faster but typically remain confined within their teacher's domain. Thus, fast and high-quality generation for novel domains relies on two-stage training pipelines: Ad...

---

## 170. Pluggable Pruning with Contiguous Layer Distillation for Diffusion Transformers

- **arXiv ID**: 2511.16156v2
- **作者**: Jian Ma, Qirong Peng, Xujie Zhu, Peixing Xie, Chen Chen 等 (共6位作者)
- **发布日期**: 2025-11-20
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2511.16156v2](http://arxiv.org/abs/2511.16156v2)
- **PDF**: [http://arxiv.org/pdf/2511.16156v2](http://arxiv.org/pdf/2511.16156v2)
- **摘要**: Diffusion Transformers (DiTs) have shown exceptional performance in image generation, yet their large parameter counts incur high computational costs, impeding deployment in resource-constrained settings. To address this, we propose Pluggable Pruning with Contiguous Layer Distillation (PPCL), a flex...

---

## 171. NTK-Guided Implicit Neural Teaching

- **arXiv ID**: 2511.15487v2
- **作者**: Chen Zhang, Wei Zuo, Bingyang Cheng, Yikun Wang, Wei-Bin Kou 等 (共7位作者)
- **发布日期**: 2025-11-19
- **分类**: cs.LG, cs.CV
- **论文链接**: [http://arxiv.org/abs/2511.15487v2](http://arxiv.org/abs/2511.15487v2)
- **PDF**: [http://arxiv.org/pdf/2511.15487v2](http://arxiv.org/pdf/2511.15487v2)
- **摘要**: Implicit Neural Representations (INRs) parameterize continuous signals via multilayer perceptrons (MLPs), enabling compact, resolution-independent modeling for tasks like image, audio, and 3D reconstruction. However, fitting high-resolution signals demands optimizing over millions of coordinates, in...

---

## 172. MedGEN-Bench: Contextually entangled benchmark for open-ended multimodal medical generation

- **arXiv ID**: 2511.13135v2
- **作者**: Junjie Yang, Yuhao Yan, Gang Wu, Yuxuan Wang, Ruoyu Liang 等 (共11位作者)
- **发布日期**: 2025-11-17
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2511.13135v2](http://arxiv.org/abs/2511.13135v2)
- **PDF**: [http://arxiv.org/pdf/2511.13135v2](http://arxiv.org/pdf/2511.13135v2)
- **摘要**: As Vision-Language Models (VLMs) increasingly gain traction in medical applications, clinicians are progressively expecting AI systems not only to generate textual diagnoses but also to produce corresponding medical images that integrate seamlessly into authentic clinical workflows. Despite the grow...

---

## 173. EmoVerse: A MLLMs-Driven Emotion Representation Dataset for Interpretable Visual Emotion Analysis

- **arXiv ID**: 2511.12554v1
- **作者**: Yijie Guo, Dexiang Hong, Weidong Chen, Zihan She, Cheng Ye 等 (共7位作者)
- **发布日期**: 2025-11-16
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2511.12554v1](http://arxiv.org/abs/2511.12554v1)
- **PDF**: [http://arxiv.org/pdf/2511.12554v1](http://arxiv.org/pdf/2511.12554v1)
- **摘要**: Visual Emotion Analysis (VEA) aims to bridge the affective gap between visual content and human emotional responses. Despite its promise, progress in this field remains limited by the lack of open-source and interpretable datasets. Most existing studies assign a single discrete emotion label to an e...

---

## 174. Changes in Real Time: Online Scene Change Detection with Multi-View Fusion

- **arXiv ID**: 2511.12370v3
- **作者**: Chamuditha Jayanga Galappaththige, Jason Lai, Lloyd Windrim, Donald Dansereau, Niko Sünderhauf 等 (共6位作者)
- **发布日期**: 2025-11-15
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2511.12370v3](http://arxiv.org/abs/2511.12370v3)
- **PDF**: [http://arxiv.org/pdf/2511.12370v3](http://arxiv.org/pdf/2511.12370v3)
- **摘要**: Online Scene Change Detection (SCD) is an extremely challenging problem that requires an agent to detect relevant changes on the fly while observing the scene from unconstrained viewpoints. Existing online SCD methods are significantly less accurate than offline approaches. We present the first onli...

---

## 175. Defending Unauthorized Model Merging via Dual-Stage Weight Protection

- **arXiv ID**: 2511.11851v2
- **作者**: Wei-Jia Chen, Min-Yen Tsai, Cheng-Yi Lee, Chia-Mu Yu
- **发布日期**: 2025-11-14
- **分类**: cs.CV, cs.CR
- **论文链接**: [http://arxiv.org/abs/2511.11851v2](http://arxiv.org/abs/2511.11851v2)
- **PDF**: [http://arxiv.org/pdf/2511.11851v2](http://arxiv.org/pdf/2511.11851v2)
- **摘要**: The rapid proliferation of pretrained models and open repositories has made model merging a convenient yet risky practice, allowing free-riders to combine fine-tuned models into a new multi-capability model without authorization. Such unauthorized model merging not only violates intellectual propert...

---

## 176. MSGNav: Unleashing the Power of Multi-modal 3D Scene Graph for Zero-Shot Embodied Navigation

- **arXiv ID**: 2511.10376v3
- **作者**: Xun Huang, Shijia Zhao, Yunxiang Wang, Xin Lu, Wanfa Zhang 等 (共9位作者)
- **发布日期**: 2025-11-13
- **分类**: cs.CV, cs.RO
- **论文链接**: [http://arxiv.org/abs/2511.10376v3](http://arxiv.org/abs/2511.10376v3)
- **PDF**: [http://arxiv.org/pdf/2511.10376v3](http://arxiv.org/pdf/2511.10376v3)
- **摘要**: Embodied navigation is a fundamental capability for robotic agents operating. Real-world deployment requires open vocabulary generalization and low training overhead, motivating zero-shot methods rather than task-specific RL training. However, existing zero-shot methods that build explicit 3D scene ...

---

## 177. Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis

- **arXiv ID**: 2511.01425v1
- **作者**: Yuhang Huang, Zekai Lin, Fan Zhong, Lei Liu
- **发布日期**: 2025-11-03
- **分类**: cs.AI, cs.CV
- **论文链接**: [http://arxiv.org/abs/2511.01425v1](http://arxiv.org/abs/2511.01425v1)
- **PDF**: [http://arxiv.org/pdf/2511.01425v1](http://arxiv.org/pdf/2511.01425v1)
- **摘要**: Explanations for AI models in high-stakes domains like medicine often lack verifiability, which can hinder trust. To address this, we propose an interactive agent that produces explanations through an auditable sequence of actions. The agent learns a policy to strategically seek external visual evid...

---

## 178. LinVideo: A Post-Training Framework towards O(n) Attention in Efficient Video Generation

- **arXiv ID**: 2510.08318v3
- **作者**: Yushi Huang, Xingtong Ge, Ruihao Gong, Chengtao Lv, Jun Zhang
- **发布日期**: 2025-10-09
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2510.08318v3](http://arxiv.org/abs/2510.08318v3)
- **PDF**: [http://arxiv.org/pdf/2510.08318v3](http://arxiv.org/pdf/2510.08318v3)
- **摘要**: Video diffusion models (DMs) have enabled high-quality video synthesis. However, their computation costs scale quadratically with sequence length because self-attention has quadratic complexity. While linear attention lowers the cost, fully replacing quadratic attention requires expensive pretrainin...

---

## 179. STCast: Adaptive Boundary Alignment for Global and Regional Weather Forecasting

- **arXiv ID**: 2509.25210v2
- **作者**: Hao Chen, Tao Han, Jie Zhang, Song Guo, Lei Bai
- **发布日期**: 2025-09-21
- **分类**: cs.LG, cs.AI, physics.ao-ph
- **论文链接**: [http://arxiv.org/abs/2509.25210v2](http://arxiv.org/abs/2509.25210v2)
- **PDF**: [http://arxiv.org/pdf/2509.25210v2](http://arxiv.org/pdf/2509.25210v2)
- **摘要**: To gain finer regional forecasts, many works have explored the regional integration from the global atmosphere, e.g., by solving boundary equations in physics-based methods or cropping regions from global forecasts in data-driven methods. However, the effectiveness of these methods is often constrai...

---

## 180. Association and Consolidation: Evolutionary Memory-Enhanced Incremental Multi-View Clustering

- **arXiv ID**: 2509.14544v2
- **作者**: Zisen Kong, Bo Zhong, Pengyuan Li, Dongxia Chang, Yiming Wang 等 (共6位作者)
- **发布日期**: 2025-09-18
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2509.14544v2](http://arxiv.org/abs/2509.14544v2)
- **PDF**: [http://arxiv.org/pdf/2509.14544v2](http://arxiv.org/pdf/2509.14544v2)
- **摘要**: Incremental multi-view clustering aims to achieve stable clustering results while addressing the stability-plasticity dilemma (SPD) in view-incremental scenarios. The core challenge is that the model must have enough plasticity to quickly adapt to new data, while maintaining sufficient stability to ...

---

## 181. Variation-aware Vision Token Dropping for Faster Large Vision-Language Models

- **arXiv ID**: 2509.01552v2
- **作者**: Junjie Chen, Xuyang Liu, Zichen Wen, Yiyu Wang, Siteng Huang 等 (共6位作者)
- **发布日期**: 2025-09-01
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2509.01552v2](http://arxiv.org/abs/2509.01552v2)
- **PDF**: [http://arxiv.org/pdf/2509.01552v2](http://arxiv.org/pdf/2509.01552v2)
- **摘要**: Large vision-language models (LVLMs) have demonstrated remarkable capabilities in multimodal understanding tasks. However, the increasing demand for high-resolution image and long-video understanding results in substantial token counts, consequently leading to reduced inference efficiency. Token com...

---

## 182. FAIR-Pruner: Leveraging Tolerance of Difference for Flexible Automatic Layer-Wise Neural Network Pruning

- **arXiv ID**: 2508.02291v2
- **作者**: Chenqing Lin, Mostafa Hussien, Chengyao Yu, Bingyi Jing, Mohamed Cheriet 等 (共7位作者)
- **发布日期**: 2025-08-04
- **分类**: cs.LG, cs.AI
- **论文链接**: [http://arxiv.org/abs/2508.02291v2](http://arxiv.org/abs/2508.02291v2)
- **PDF**: [http://arxiv.org/pdf/2508.02291v2](http://arxiv.org/pdf/2508.02291v2)
- **摘要**: Neural network pruning has been widely adopted to reduce the parameter scale of complex neural networks, enabling efficient deployment on resource-limited edge devices. Mainstream pruning methods typically adopt uniform pruning strategies, which tend to cause a substantial performance degradation un...

---

## 183. MoVieS: Motion-Aware 4D Dynamic View Synthesis in One Second

- **arXiv ID**: 2507.10065v2
- **作者**: Chenguo Lin, Yuchen Lin, Panwang Pan, Yifan Yu, Tao Hu 等 (共8位作者)
- **发布日期**: 2025-07-14
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2507.10065v2](http://arxiv.org/abs/2507.10065v2)
- **PDF**: [http://arxiv.org/pdf/2507.10065v2](http://arxiv.org/pdf/2507.10065v2)
- **摘要**: We present MoVieS, a Motion-aware View Synthesis model that reconstructs 4D dynamic scenes from monocular videos in one second. It represents dynamic 3D scenes with pixel-aligned Gaussian primitives and explicitly supervises their time-varying motions. This allows, for the first time, the unified mo...

---

## 184. Perception Characteristics Distance: Measuring Stability and Robustness of Perception System in Dynamic Conditions under a Certain Decision Rule

- **arXiv ID**: 2506.09217v2
- **作者**: Boyu Jiang, Liang Shi, Zhengzhi Lin, Lanxin Xiang, Loren Stowe 等 (共6位作者)
- **发布日期**: 2025-06-10
- **分类**: cs.RO, cs.CV, stat.AP
- **论文链接**: [http://arxiv.org/abs/2506.09217v2](http://arxiv.org/abs/2506.09217v2)
- **PDF**: [http://arxiv.org/pdf/2506.09217v2](http://arxiv.org/pdf/2506.09217v2)
- **摘要**: The safety of autonomous driving systems (ADS) depends on accurate perception across distance and driving conditions. The outputs of AI perception algorithms are stochastic, which have a major impact on decision making and safety outcomes, including time-to-collision estimation. However, current per...

---

## 185. SpeeDe3DGS: Speedy Deformable 3D Gaussian Splatting with Temporal Pruning and Motion Grouping

- **arXiv ID**: 2506.07917v3
- **作者**: Allen Tu, Haiyang Ying, Alex Hanson, Yonghan Lee, Tom Goldstein 等 (共6位作者)
- **发布日期**: 2025-06-09
- **分类**: cs.GR, cs.CV
- **论文链接**: [http://arxiv.org/abs/2506.07917v3](http://arxiv.org/abs/2506.07917v3)
- **PDF**: [http://arxiv.org/pdf/2506.07917v3](http://arxiv.org/pdf/2506.07917v3)
- **摘要**: Dynamic extensions of 3D Gaussian Splatting (3DGS) achieve high-quality reconstructions through neural motion fields, but per-Gaussian neural inference makes these models computationally expensive. Building on DeformableGS, we introduce Speedy Deformable 3D Gaussian Splatting (SpeeDe3DGS), which bri...

---

## 186. Harnessing Chain-of-Thought Reasoning in Multimodal Large Language Models for Face Anti-Spoofing

- **arXiv ID**: 2506.01783v2
- **作者**: Honglu Zhang, Zhiqin Fang, Ningning Zhao, Saihui Hou, Long Ma 等 (共7位作者)
- **发布日期**: 2025-06-02
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2506.01783v2](http://arxiv.org/abs/2506.01783v2)
- **PDF**: [http://arxiv.org/pdf/2506.01783v2](http://arxiv.org/pdf/2506.01783v2)
- **摘要**: Face Anti-Spoofing (FAS) typically depends on a single visual modality when defending against presentation attacks such as print attacks, screen replays, and 3D masks, resulting in limited generalization across devices, environments, and attack types. Meanwhile, Multimodal Large Language Models (MLL...

---

## 187. Learning What Matters: Prioritized Concept Learning via Relative Error-driven Sample Selection

- **arXiv ID**: 2506.01085v2
- **作者**: Shivam Chandhok, Qian Yang, Oscar Manas, Kanishk Jain, Leonid Sigal 等 (共6位作者)
- **发布日期**: 2025-06-01
- **分类**: cs.CV, cs.AI
- **论文链接**: [http://arxiv.org/abs/2506.01085v2](http://arxiv.org/abs/2506.01085v2)
- **PDF**: [http://arxiv.org/pdf/2506.01085v2](http://arxiv.org/pdf/2506.01085v2)
- **摘要**: Instruction tuning has been central to the success of recent vision-language models (VLMs), but it remains expensive-requiring large-scale datasets, high-quality annotations, and large compute budgets. We propose PRioritized cOncept learninG via Relative Error-driven Sample Selection (PROGRESS), a d...

---

## 188. SABER: Spatially Consistent 3D Universal Adversarial Objects for BEV Detectors

- **arXiv ID**: 2505.22499v3
- **作者**: Aixuan Li, Mochu Xiang, Bosen Hou, Zhexiong Wan, Jing Zhang 等 (共6位作者)
- **发布日期**: 2025-05-28
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2505.22499v3](http://arxiv.org/abs/2505.22499v3)
- **PDF**: [http://arxiv.org/pdf/2505.22499v3](http://arxiv.org/pdf/2505.22499v3)
- **摘要**: Adversarial robustness of BEV 3D object detectors is critical for autonomous driving (AD). Existing invasive attacks require altering the target vehicle itself (e.g. attaching patches), making them unrealistic and impractical for real-world evaluation. While non-invasive attacks that place adversari...

---

## 189. RaPA: Enhancing Transferable Targeted Attacks via Random Parameter Pruning

- **arXiv ID**: 2504.18594v2
- **作者**: Tongrui Su, Qingbin Li, Shengyu Zhu, Wei Chen, Xueqi Cheng
- **发布日期**: 2025-04-24
- **分类**: cs.LG, cs.AI
- **论文链接**: [http://arxiv.org/abs/2504.18594v2](http://arxiv.org/abs/2504.18594v2)
- **PDF**: [http://arxiv.org/pdf/2504.18594v2](http://arxiv.org/pdf/2504.18594v2)
- **摘要**: Compared to untargeted attacks, targeted transfer-based attack is still suffering from much lower Attack Success Rates (ASRs), although significant improvements have been achieved by kinds of methods, such as diversifying input, stabilizing the gradient, and re-training surrogate models. In this pap...

---

## 190. Enhancing Out-of-Distribution Detection with Extended Logit Normalization

- **arXiv ID**: 2504.11434v2
- **作者**: Yifan Ding, Xixi Liu, Jonas Unger, Gabriel Eilertsen
- **发布日期**: 2025-04-15
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2504.11434v2](http://arxiv.org/abs/2504.11434v2)
- **PDF**: [http://arxiv.org/pdf/2504.11434v2](http://arxiv.org/pdf/2504.11434v2)
- **摘要**: \noindent Out-of-distribution (OOD) detection is essential for the safe deployment of machine learning models. Extensive work has focused on devising various scoring functions for detecting OOD samples, while only a few studies focus on training neural networks using certain model calibration object...

---

## 191. CLIP-Free, Label Free, Unsupervised Concept Bottleneck Models

- **arXiv ID**: 2503.10981v4
- **作者**: Fawaz Sammani, Jonas Fischer, Nikos Deligiannis
- **发布日期**: 2025-03-14
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2503.10981v4](http://arxiv.org/abs/2503.10981v4)
- **PDF**: [http://arxiv.org/pdf/2503.10981v4](http://arxiv.org/pdf/2503.10981v4)
- **摘要**: Concept Bottleneck Models (CBMs) map dense feature representations into human-interpretable concepts which are then combined linearly to make a prediction. However, modern CBMs rely on the CLIP model to obtain image-concept annotations, and it remains unclear how to design CBMs without the CLIP bott...

---

## 192. SphOR: A Representation Learning Perspective on Open-set Recognition for Identifying Unknown Classes in Deep Learning Models

- **arXiv ID**: 2503.08049v3
- **作者**: Nadarasar Bahavan, Sachith Seneviratne, Saman Halgamuge
- **发布日期**: 2025-03-11
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2503.08049v3](http://arxiv.org/abs/2503.08049v3)
- **PDF**: [http://arxiv.org/pdf/2503.08049v3](http://arxiv.org/pdf/2503.08049v3)
- **摘要**: The reliance on Deep Neural Network (DNN)-based classifiers in safety-critical and real-world applications necessitates Open-Set Recognition (OSR). OSR enables the identification of input data from classes unknown during training as unknown, as opposed to misclassifying them as belonging to a known ...

---

## 193. Hier-COS: Making Deep Features Hierarchy-aware via Composition of Orthogonal Subspaces

- **arXiv ID**: 2503.07853v2
- **作者**: Depanshu Sani, Saket Anand
- **发布日期**: 2025-03-10
- **分类**: cs.CV, cs.LG
- **论文链接**: [http://arxiv.org/abs/2503.07853v2](http://arxiv.org/abs/2503.07853v2)
- **PDF**: [http://arxiv.org/pdf/2503.07853v2](http://arxiv.org/pdf/2503.07853v2)
- **摘要**: Traditional classifiers treat all labels as mutually independent, thereby considering all negative classes to be equally incorrect. This approach fails severely in many real-world scenarios, where a known semantic hierarchy defines a partial order of preferences over negative classes. While hierarch...

---

## 194. Motion-Aware Animatable Gaussian Avatars Deblurring

- **arXiv ID**: 2411.16758v2
- **作者**: Muyao Niu, Yifan Zhan, Qingtian Zhu, Zhuoxiao Li, Wei Wang 等 (共8位作者)
- **发布日期**: 2024-11-24
- **分类**: cs.CV
- **论文链接**: [http://arxiv.org/abs/2411.16758v2](http://arxiv.org/abs/2411.16758v2)
- **PDF**: [http://arxiv.org/pdf/2411.16758v2](http://arxiv.org/pdf/2411.16758v2)
- **摘要**: The creation of 3D human avatars from multi-view videos is a significant yet challenging task in computer vision. However, existing techniques rely on high-quality, sharp images as input, which are often impractical to obtain in real-world scenarios due to variations in human motion speed and intens...

---

